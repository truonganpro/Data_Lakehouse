# Makefile for Demand Forecasting Pipeline
# Include this in main Makefile or use: make -f Makefile.forecast <target>

.PHONY: help forecast-init forecast-features forecast-train forecast-predict forecast-full forecast-check

help:
	@echo "üîÆ Demand Forecasting Commands:"
	@echo ""
	@echo "  make forecast-init       Initialize MLflow database"
	@echo "  make forecast-features   Build forecast features"
	@echo "  make forecast-train      Train LightGBM model"
	@echo "  make forecast-predict    Generate predictions (requires RUN_ID)"
	@echo "  make forecast-full       Run full pipeline (features ‚Üí train ‚Üí predict)"
	@echo "  make forecast-check      Check MLflow status"
	@echo ""

# Initialize MLflow
forecast-init:
	@echo "üöÄ Initializing MLflow..."
	@bash scripts/init_mlflow.sh

# Build features
forecast-features:
	@echo "üî® Building forecast features..."
	docker exec -it etl_pipeline python -m etl_pipeline.ml.feature_build

# Train model
forecast-train:
	@echo "ü§ñ Training model..."
	docker exec -it etl_pipeline python -m etl_pipeline.ml.train_models

# Batch predict (requires RUN_ID env var)
forecast-predict:
	@if [ -z "$(RUN_ID)" ]; then \
		echo "‚ùå Error: RUN_ID not set"; \
		echo "   Usage: make forecast-predict RUN_ID=<mlflow_run_id>"; \
		exit 1; \
	fi
	@echo "üîÆ Generating forecasts with model: $(RUN_ID)"
	docker exec -it etl_pipeline python -m etl_pipeline.ml.batch_predict $(RUN_ID)

# Full pipeline
forecast-full:
	@echo "üöÄ Running full forecast pipeline..."
	@echo ""
	@echo "Step 1/3: Building features..."
	@docker exec etl_pipeline python -m etl_pipeline.ml.feature_build
	@echo ""
	@echo "Step 2/3: Training model..."
	@docker exec etl_pipeline python -m etl_pipeline.ml.train_models > /tmp/forecast_train.log 2>&1
	@RUN_ID=$$(cat /tmp/forecast_train.log | grep "run_id=" | tail -1 | sed 's/.*run_id=//'); \
	echo "Model trained: $$RUN_ID"; \
	echo ""; \
	echo "Step 3/3: Generating predictions..."; \
	docker exec etl_pipeline python -m etl_pipeline.ml.batch_predict $$RUN_ID
	@echo ""
	@echo "‚úÖ Forecast pipeline completed!"

# Check MLflow status
forecast-check:
	@echo "üîç Checking MLflow status..."
	@docker exec de_mysql mysql -u mlflow -pmlflow mlflowdb -e "\
		SELECT \
			run_id, \
			experiment_id, \
			status, \
			start_time, \
			end_time \
		FROM runs \
		ORDER BY start_time DESC \
		LIMIT 10;" 2>/dev/null || echo "‚ùå MLflow DB not initialized. Run: make forecast-init"

# Verify features
forecast-check-features:
	@echo "üîç Checking forecast features..."
	@docker exec trino trino --execute "\
		SELECT \
			COUNT(*) AS row_count, \
			MIN(date) AS min_date, \
			MAX(date) AS max_date, \
			COUNT(DISTINCT product_id) AS n_products, \
			COUNT(DISTINCT region_id) AS n_regions \
		FROM lakehouse.silver.forecast_features;"

# Verify forecasts
forecast-check-output:
	@echo "üîç Checking forecast output..."
	@docker exec trino trino --execute "\
		SELECT \
			forecast_date, \
			COUNT(*) AS n_forecasts, \
			AVG(yhat) AS avg_forecast, \
			model_name, \
			run_id \
		FROM lakehouse.platinum.demand_forecast \
		GROUP BY forecast_date, model_name, run_id \
		ORDER BY forecast_date DESC \
		LIMIT 20;"

# Clean forecasts (be careful!)
forecast-clean:
	@echo "‚ö†Ô∏è  Cleaning forecast output..."
	@read -p "Are you sure? [y/N] " confirm && [ "$$confirm" = "y" ] || exit 1
	docker exec trino trino --execute "\
		DELETE FROM lakehouse.platinum.demand_forecast WHERE 1=1;"
	@echo "‚úÖ Forecasts cleaned"


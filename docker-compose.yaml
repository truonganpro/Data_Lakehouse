version: "3.9"

services:
  # ========================
  # ðŸ¬ MYSQL (Metastore)
  # ========================
  de_mysql:
    image: mysql:8.0
    container_name: de_mysql
    command: --default-authentication-plugin=mysql_native_password
    volumes:
      - ./mysql:/var/lib/mysql
      - ./load_dataset_into_mysql:/docker-entrypoint-initdb.d:ro
    ports:
      - "3306:3306"
    env_file:
      - .env
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "de_mysql", "-u$$MYSQL_USER", "-p$$MYSQL_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ========================
  # ðŸ HIVE METASTORE
  # ========================
  hive-metastore:
    container_name: hive-metastore
    build:
      context: ./docker_image/hive-metastore
      dockerfile: Dockerfile
    depends_on:
      de_mysql:
        condition: service_healthy
    environment:
      - DB_TYPE=mysql
      - DB_HOST=de_mysql
      - DB_PORT=3306
      - DB_NAME=metastore
      - DB_USER=hive
      - DB_PASS=hive
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
    volumes:
      - ./docker_image/hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    ports:
      - "9083:9083"
    networks:
      - de_network

  # ========================
  # ðŸª£ MINIO (S3)
  # ========================
  minio:
    image: minio/minio
    container_name: minio
    command: ["server", "/data", "--console-address", ":9001"]
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio:/data
    env_file:
      - .env
    networks:
      - de_network

  # MinIO Client (setup buckets)
  mc:
    image: minio/mc
    container_name: mc
    depends_on:
      - minio
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c "
        until (/usr/bin/mc config host add minio http://minio:9000 minio minio123)
        do echo '...waiting...' && sleep 1; done;
        /usr/bin/mc mb minio/lakehouse || true;
        /usr/bin/mc policy set public minio/lakehouse;
        exit 0;
      "
    networks:
      - de_network

  # ========================
  # âš¡ TRINO (Delta Lake)
  # ========================
  trino:
    image: trinodb/trino:414
    container_name: trino
    ports:
      - "8082:8080"   # trÃ¡nh xung Ä‘á»™t vá»›i Spark Master
    volumes:
      - ./trino/etc:/etc/trino
    depends_on:
      - hive-metastore
      - minio
    networks:
      - de_network

  # ========================
  # ðŸ“Š METABASE
  # ========================
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    platform: linux/amd64
    hostname: metabase
    ports:
      - "3000:3000"
    environment:
      # Metabase application database (SQLite for simplicity)
      MB_DB_TYPE: h2
      MB_DB_FILE: /metabase-data/metabase.db
      # Trino connection will be configured via UI
    depends_on:
      - trino
      - hive-metastore
    volumes:
      - metabase_data:/metabase-data
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "curl", "--fail", "-I", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # ========================
  # ðŸ”¥ SPARK CLUSTER
  # ========================
  spark-master:
    image: bitnami/spark:3.3.2
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_CLASSPATH=/opt/jars/*
      - SPARK_JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./jars:/opt/jars
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network

  spark-worker-1:
    image: bitnami/spark:3.3.2
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_CLASSPATH=/opt/jars/*
      - SPARK_JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
      - ./jars:/opt/jars
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network
  # Streamlit
  streamlit:
    container_name: streamlit
    build:
      context: ./docker_image/streamlit
      dockerfile: Dockerfile
    image: streamlit:latest
    ports:
      - "8501:8501"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./app:/app
    networks:
      - de_network 

  # ========================
  # ðŸ”„ ETL PIPELINE
  # ========================
  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: Dockerfile
    container_name: etl_pipeline
    ports:
      - "4000:4000"
    volumes:
      - ./jars:/opt/jars
      - ./dagster_home:/opt/dagster/dagster_home
    environment:
      - JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
      - DAGSTER_HOME=/opt/dagster/dagster_home
    env_file:
      - .env
    depends_on:
      - spark-master
      - minio
      - de_mysql
    networks:
      - de_network

  # ========================
  # ðŸ§­ DAGSTER
  # ========================
  de_dagster:
    build:
      context: ./dagster/
    container_name: de_dagster
    ports:
      - "5001:5000"
    env_file:
      - .env
    depends_on:
      - de_mysql
    networks:
      - de_network

  de_dagster_dagit:
    build:
      context: ./dagster/
    depends_on:
      - de_dagster
      - etl_pipeline
    entrypoint: ["dagster-webserver"]
    command: ["-h", "0.0.0.0", "-p", "3001", "-w", "/opt/dagster/dagster_home/workspace.yaml"]
    container_name: de_dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

  de_dagster_daemon:
    build:
      context: ./dagster/
    depends_on:
      - de_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: de_dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

  # ============================================================================
  # Chat Service (SQL + RAG Chatbot)
  # ============================================================================

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_data:/qdrant/storage
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  chat_service:
    build:
      context: ./chat_service
      dockerfile: Dockerfile
    container_name: chat_service
    ports:
      - "8001:8001"
    environment:
      # LLM & Embedding Providers
      LLM_PROVIDER: gemini
      EMBEDDING_PROVIDER: gemini
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      SBERT_MODEL: intfloat/multilingual-e5-base
      # Trino
      TRINO_HOST: trino
      TRINO_PORT: 8080
      TRINO_CATALOG: lakehouse
      TRINO_DEFAULT_SCHEMA: gold
      TRINO_USER: chatbot
      TRINO_PASSWORD: ""
      # Qdrant
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      # Audit logs (MySQL)
      LOG_DB_URI: mysql+pymysql://root:admin123@de_mysql:3306/chatlogs
      # Safety policies
      SQL_WHITELIST_SCHEMAS: gold,platinum
      SQL_DEFAULT_LIMIT: "200"
      SQL_MAX_ROWS: "5000"
      SQL_TIMEOUT_SECS: "45"
      TZ: Asia/Ho_Chi_Minh
    volumes:
      - ./chat_service:/app
      - ./docs:/app/docs
    networks:
      - de_network
    depends_on:
      - qdrant
      - trino
      - de_mysql
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  metabase_data:

networks:
  de_network:
    driver: bridge
services:
  # ========================
  # ðŸ¬ MYSQL (Metastore)
  # ========================
  de_mysql:
    image: mysql:8.0
    container_name: de_mysql
    command: --default-authentication-plugin=mysql_native_password
    volumes:
      - ./mysql:/var/lib/mysql
      - ./load_dataset_into_mysql:/docker-entrypoint-initdb.d:ro
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-root123}
      MYSQL_DATABASE: ${MYSQL_DATABASE:-metastore}
      MYSQL_USER: ${MYSQL_USER:-hive}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-hive}
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "de_mysql", "-u$$MYSQL_USER", "-p$$MYSQL_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ========================
  # ðŸ HIVE METASTORE
  # ========================
  hive-metastore:
    container_name: hive-metastore
    build:
      context: ./docker_image/hive-metastore
      dockerfile: Dockerfile
    depends_on:
      de_mysql:
        condition: service_healthy
    environment:
      - DB_TYPE=mysql
      - DB_HOST=de_mysql
      - DB_PORT=3306
      - DB_NAME=metastore
      - DB_USER=hive
      - DB_PASS=hive
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
    volumes:
      - ./docker_image/hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    ports:
      - "9083:9083"
    networks:
      - de_network

  # ========================
  # ðŸª£ MINIO (S3)
  # ========================
  minio:
    image: minio/minio
    container_name: minio
    command: ["server", "/data", "--console-address", ":9001"]
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio123}
    networks:
      - de_network

  # MinIO Client (setup buckets)
  mc:
    image: minio/mc
    container_name: mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        until (/usr/bin/mc config host add minio http://minio:9000 minio minio123)
        do echo '...waiting...' && sleep 1; done;
        /usr/bin/mc mb minio/warehouse || true;
        /usr/bin/mc mb minio/lakehouse || true;
        /usr/bin/mc policy set public minio/warehouse;
        /usr/bin/mc policy set public minio/lakehouse;
        exit 0;
      "
    networks:
      - de_network

  # ========================
  # âš¡ TRINO (Delta Lake)
  # ========================
  trino:
    image: trinodb/trino:414
    container_name: trino
    ports:
      - "8082:8080"   # trÃ¡nh xung Ä‘á»™t vá»›i Spark Master
    volumes:
      - ./trino/etc:/etc/trino
    depends_on:
      - hive-metastore
      - minio
    networks:
      - de_network

  # ========================
  # ðŸ“Š METABASE
  # ========================
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    platform: linux/amd64
    hostname: metabase
    ports:
      - "3000:3000"
    environment:
      # Metabase application database (H2 for simplicity)
      MB_DB_TYPE: h2
      MB_DB_FILE: /metabase-data/metabase.db
      # JVM options to fix SIGSEGV crash and improve stability
      JAVA_OPTS: "-Xmx2g -Xms1g -XX:+UseG1GC -XX:MaxGCPauseMillis=500 -XX:+UseStringDeduplication -XX:+DisableExplicitGC"
      # Trino connection will be configured via UI
    depends_on:
      - trino
      - hive-metastore
    volumes:
      - metabase_data:/metabase-data
    networks:
      - de_network
    deploy:
      resources:
        limits:
          memory: 3g
        reservations:
          memory: 1g
    healthcheck:
      test: ["CMD", "curl", "--fail", "-I", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ========================
  # ðŸ”¥ SPARK CLUSTER
  # ========================
  spark-master:
    image: bitnami/spark:3.3.2
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_CLASSPATH=/opt/jars/*
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./jars:/opt/jars
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network

  spark-worker-1:
    image: bitnami/spark:3.3.2
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_CLASSPATH=/opt/jars/*
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
      - ./jars:/opt/jars
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network
  # Jupyter Notebook for Spark
  spark-notebook:
    build: 
      context: ./notebooks
      dockerfile: ./Dockerfile
    container_name: spark-notebook
    user: root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000/ 
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker_image/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - ./jars:/opt/jars
    ports:
      - "8888:8888"
      - "4040:4040"
    networks:
      - de_network 

  # Streamlit
  streamlit:
    container_name: streamlit
    build:
      context: ./docker_image/streamlit
      dockerfile: Dockerfile
    image: streamlit:latest
    ports:
      - "8501:8501"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./app:/app
    networks:
      - de_network 

  # ========================
  # ðŸ”„ ETL PIPELINE
  # ========================
  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: Dockerfile
    container_name: etl_pipeline
    ports:
      - "4000:4000"
    volumes:
      - ./jars:/opt/jars
      - ./dagster_home:/opt/dagster/dagster_home
    depends_on:
      - spark-master
      - minio
      - de_mysql
    networks:
      - de_network

  # ========================
  # ðŸ§­ DAGSTER
  # ========================
  de_dagster:
    build:
      context: ./dagster/
    container_name: de_dagster
    ports:
      - "5001:5000"
    depends_on:
      - de_mysql
    networks:
      - de_network

  de_dagster_dagit:
    build:
      context: ./dagster/
    depends_on:
      - de_dagster
      - etl_pipeline
    entrypoint: ["dagster-webserver"]
    command: ["-h", "0.0.0.0", "-p", "3001", "-w", "/opt/dagster/dagster_home/workspace.yaml"]
    container_name: de_dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    networks:
      - de_network

  de_dagster_daemon:
    build:
      context: ./dagster/
    depends_on:
      - de_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: de_dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    networks:
      - de_network

volumes:
  metabase_data:

networks:
  de_network:
    driver: bridge
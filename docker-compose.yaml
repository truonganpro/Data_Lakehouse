services:
  # ========================
  # üê¨ MYSQL (Metastore)
  # ========================
  de_mysql:
    image: mysql:8.0
    container_name: de_mysql
    command: --default-authentication-plugin=mysql_native_password
    volumes:
      - ./mysql:/var/lib/mysql
      - ./load_dataset_into_mysql:/docker-entrypoint-initdb.d:ro
      - ./docker_image/mysql/my.cnf:/etc/mysql/conf.d/custom.cnf:ro
    ports:
      - "3306:3306"
    env_file:
      - .env
    networks:
      - de_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-uroot", "-p$$MYSQL_ROOT_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # ========================
  # üêù HIVE METASTORE
  # ========================
  hive-metastore:
    container_name: hive-metastore
    build:
      context: ./docker_image/hive-metastore
      dockerfile: Dockerfile
    depends_on:
      de_mysql:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-c", "timeout 2 bash -c '</dev/tcp/localhost/9083' || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 60s
    environment:
      - DB_TYPE=mysql
      - DB_HOST=de_mysql
      - DB_PORT=3306
      - DB_NAME=metastore
      - DB_USER=hive
      - DB_PASS=hive
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
      - JAVA_TOOL_OPTIONS=-Xms256m -Xmx1024m
    volumes:
      - ./docker_image/hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    ports:
      - "9083:9083"
    networks:
      - de_network

  # ========================
  # ü™£ MINIO (S3)
  # ========================
  minio:
    image: minio/minio
    container_name: minio
    command: ["server", "/data", "--console-address", ":9001"]
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio:/data
    env_file:
      - .env
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # MinIO Client (setup buckets)
  mc:
    image: minio/mc
    container_name: mc
    depends_on:
      - minio
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c "
        until (/usr/bin/mc alias set minio http://minio:9000 minio minio123)
        do echo '...waiting...' && sleep 1; done;
        /usr/bin/mc mb minio/lakehouse || true;
        /usr/bin/mc policy set public minio/lakehouse;
        exit 0;
      "
    networks:
      - de_network

  # ========================
  # ‚ö° TRINO (Delta Lake)
  # ========================
  trino:
    image: trinodb/trino:414
    container_name: trino
    ports:
      - "8082:8080"   # tr√°nh xung ƒë·ªôt v·ªõi Spark Master
    volumes:
      - ./trino/etc:/etc/trino
    depends_on:
      - hive-metastore
      - minio
    networks:
      - de_network

  # ========================
  # üìä METABASE
  # ========================
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    # FIX: Apple Silicon (arm64) - kh√¥ng d√πng amd64 ƒë·ªÉ tr√°nh Rosetta emulation g√¢y SIGSEGV
    platform: linux/arm64
    hostname: metabase
    ports:
      - "3000:3000"
    environment:
      # Metabase application database (SQLite for simplicity)
      MB_DB_TYPE: h2
      MB_DB_FILE: /metabase-data/metabase.db
      MB_JETTY_HOST: 0.0.0.0
      # Trino connection will be configured via UI
    depends_on:
      - trino
      - hive-metastore
    volumes:
      - metabase_data:/metabase-data
    networks:
      - de_network
    healthcheck:
      test: ["CMD", "curl", "--fail", "-I", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 60s

  # ========================
  # üî• SPARK CLUSTER
  # ========================
  spark-master:
    image: bitnami/spark:3.3.2
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_CLASSPATH=/opt/jars/*
      - SPARK_JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./jars:/opt/jars
      - ./scripts:/scripts:ro
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network

  spark-worker-1:
    image: bitnami/spark:3.3.2
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_CLASSPATH=/opt/jars/*
      - SPARK_JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
      - ./jars:/opt/jars
      - ./scripts:/scripts:ro
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - de_network
  # Streamlit
  streamlit:
    container_name: streamlit
    build:
      context: ./docker_image/streamlit
      dockerfile: Dockerfile
    image: streamlit:latest
    ports:
      - "8501:8501"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      # Trino
      - TRINO_HOST=trino
      - TRINO_PORT=8080
      - TRINO_CATALOG=lakehouse
      - TRINO_DEFAULT_SCHEMA=gold
      - TRINO_USER=admin
      - TRINO_PASSWORD=${TRINO_PASSWORD:-}
    volumes:
      - ./app:/app
    networks:
      - de_network
    depends_on:
      - trino 

  # ========================
  # üîÑ ETL PIPELINE
  # ========================
  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: Dockerfile
    container_name: etl_pipeline
    ports:
      - "4000:4000"
    volumes:
      - ./jars:/opt/jars
      - ./scripts:/scripts:ro
      - ./dagster_home:/opt/dagster/dagster_home
      - /var/run/docker.sock:/var/run/docker.sock  # Required to run docker exec from container
    environment:
      - JARS_DIR=/opt/jars
      - SPARK_DIST_CLASSPATH=/opt/jars/*
      - DAGSTER_HOME=/opt/dagster/dagster_home
      - MLFLOW_TRACKING_URI=mysql+pymysql://mlflow:mlflow@de_mysql:3306/mlflowdb
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    env_file:
      - .env
    depends_on:
      spark-master:
        condition: service_started
      minio:
        condition: service_started
      de_mysql:
        condition: service_healthy
      hive-metastore:
        condition: service_started
    networks:
      - de_network

  # ========================
  # üß≠ DAGSTER
  # ========================
  de_dagster:
    build:
      context: ./dagster/
    container_name: de_dagster
    ports:
      - "5001:5000"
    env_file:
      - .env
    depends_on:
      de_mysql:
        condition: service_healthy
      hive-metastore:
        condition: service_started
    networks:
      - de_network

  de_dagster_dagit:
    build:
      context: ./dagster/
    depends_on:
      de_mysql:
        condition: service_healthy
      de_dagster:
        condition: service_started
      etl_pipeline:
        condition: service_started
    entrypoint: ["dagster-webserver"]
    command: ["-h", "0.0.0.0", "-p", "3001", "-w", "/opt/dagster/dagster_home/workspace.yaml"]
    container_name: de_dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

  de_dagster_daemon:
    build:
      context: ./dagster/
    depends_on:
      de_mysql:
        condition: service_healthy
      de_dagster:
        condition: service_started
      hive-metastore:
        condition: service_started
    entrypoint:
      - dagster-daemon
      - run
    container_name: de_dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network

  # ============================================================================
  # Chat Service (SQL + RAG Chatbot)
  # ============================================================================

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_data:/qdrant/storage
    networks:
      - de_network
    # Healthcheck disabled - qdrant is working fine, but container doesn't have curl/wget/python
    # Service is verified working via: curl http://localhost:6333/collections

  chat_service:
    build:
      context: ./chat_service
      dockerfile: Dockerfile
    container_name: chat_service
    ports:
      - "8001:8001"
    environment:
      # LLM & Embedding Providers
      LLM_PROVIDER: ${LLM_PROVIDER:-gemini}
      LLM_MODEL_SQL: ${LLM_MODEL_SQL:-gpt-4o-mini}
      LLM_MODEL_SUM: ${LLM_MODEL_SUM:-gpt-4o-mini}
      LLM_API_KEY: ${LLM_API_KEY:-}
      EMBEDDING_PROVIDER: gemini
      GOOGLE_API_KEY: ${GOOGLE_API_KEY:-}
      SBERT_MODEL: intfloat/multilingual-e5-base
      # Trino
      TRINO_HOST: trino
      TRINO_PORT: 8080
      TRINO_CATALOG: lakehouse
      TRINO_DEFAULT_SCHEMA: gold
      TRINO_USER: chatbot
      TRINO_PASSWORD: ${TRINO_PASSWORD:-}
      # Qdrant
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      # Audit logs (MySQL)
      LOG_DB_URI: mysql+pymysql://root:admin123@de_mysql:3306/chatlogs
      # Safety policies
      SQL_WHITELIST_SCHEMAS: gold,platinum,platinum_sys
      SQL_DEFAULT_LIMIT: "200"
      SQL_MAX_ROWS: "5000"
      SQL_TIMEOUT_SECS: "45"
      # Rate Limiting
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-true}
      RATE_LIMIT_WINDOW_S: ${RATE_LIMIT_WINDOW_S:-60}
      RATE_LIMIT_MAX_REQ: ${RATE_LIMIT_MAX_REQ:-30}
      # Feature Flags
      ENABLE_SUGGESTED_ACTIONS: ${ENABLE_SUGGESTED_ACTIONS:-true}
      ENABLE_EXPLANATION: ${ENABLE_EXPLANATION:-true}
      # Security
      MAX_REQUEST_SIZE: ${MAX_REQUEST_SIZE:-262144}
      CORS_ORIGINS: ${CORS_ORIGINS:-*}
      # Observability
      ENABLE_METRICS: ${ENABLE_METRICS:-true}
      ENABLE_STRUCTURED_LOGS: ${ENABLE_STRUCTURED_LOGS:-true}
      ENABLE_TRACE_IDS: ${ENABLE_TRACE_IDS:-true}
      TZ: Asia/Ho_Chi_Minh
    volumes:
      - ./chat_service:/app
      - ./docs:/app/docs
    networks:
      - de_network
    depends_on:
      - qdrant
      - trino
      - de_mysql
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/healthz').read()"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  metabase_data:

networks:
  de_network:
    driver: bridge
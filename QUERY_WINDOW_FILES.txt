â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Cá»¬A Sá»” TRUY Váº¤N ÄA CHIá»€U (PIVOT QUERY WINDOW) - Táº¤T Cáº¢ CÃC FILE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Generated: 2025-11-02

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Tá»”NG QUAN
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Cá»­a sá»• truy váº¥n Ä‘a chiá»u (Pivot Query Window) lÃ  má»™t á»©ng dá»¥ng Streamlit cho phÃ©p:

âœ… TÃNH NÄ‚NG CHÃNH:

1. Truy váº¥n Ä‘a chiá»u (OLAP-style) trá»±c tiáº¿p trÃªn Trino
2. PhÃ¢n tÃ­ch dá»¯ liá»‡u theo nhiá»u chiá»u (dimensions) vÃ  chá»‰ sá»‘ (measures)
3. Há»— trá»£ time grain: day/week/month/quarter/year
4. Há»— trá»£ ROLLUP vÃ  GROUPING SETS (SQL OLAP extensions)
5. Export káº¿t quáº£ ra CSV/Excel
6. Káº¿t ná»‘i trá»±c tiáº¿p vá»›i Delta Lake qua Trino
7. SQL injection protection vá»›i validation
8. Enhanced dark theme UI/UX

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¦ KIáº¾N TRÃšC:

User Interface (Streamlit)
    â†“
Query Builder (Python)
    â†“
Trino SQL Engine
    â†“
Delta Lake (MinIO S3)
    â†“
Gold/Platinum Tables

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ CÃC TABLE Há»– TRá»¢:

1. gold.fact_order - Fact table: 1 row per order
   - Date Column: full_date
   - Dimensions: customer_id, primary_payment_type, is_canceled, delivered_on_time
   - Measures: order_count, unique_customers, total_items, total_price, etc.

2. gold.fact_order_item - Fact table: 1 row per order item  
   - Date Column: full_date
   - Dimensions: product_id, seller_id, customer_id, order_status
   - Measures: item_count, order_count, unique_products, total_revenue, etc.

3. platinum.dm_sales_monthly_category - Monthly sales by category
   - Date Column: month
   - Dimensions: product_category_name, product_category_name_english
   - Measures: total_revenue, total_items, unique_products, avg_price

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ CÃCH Sá»¬ Dá»¤NG:

1. Truy cáº­p: http://localhost:8501
2. Äiá»u hÆ°á»›ng Ä‘áº¿n: ğŸ“Š Query Window
3. Chá»n Schema & Table (gold/platinum)
4. Chá»n Time Grain (day/week/month/quarter/year)
5. Chá»n Dimensions (tá»‘i Ä‘a 3-4 chiá»u)
6. Chá»n Measures (cÃ¡c chá»‰ sá»‘ cáº§n tÃ­nh)
7. (TÃ¹y chá»n) ThÃªm WHERE filters
8. (TÃ¹y chá»n) Báº­t ROLLUP/GROUPING SETS
9. Nháº¥n "Cháº¡y truy váº¥n"
10. Export káº¿t quáº£ ra CSV/Excel

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FILE: app/app.py
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

import streamlit as st
import requests
import time
import os

# Set page config
st.set_page_config(
    page_title="Lakehouse Dashboard",
    page_icon="ğŸª©",
    layout="wide"
)

# Enhanced CSS with animations and polish
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');

:root{
  --bg:#0b1220; --bg2:#10192b; --card:#0f172a; --line:#1f2a44;
  --text:#e2e8f0; --muted:#94a3b8; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444; --pri:#22d3ee;
}

html, body, [class*=css] { font-family: 'Inter', sans-serif; }
.main .block-container{max-width:1280px;padding-top:1rem;padding-bottom:3rem}
h1,h2,h3{letter-spacing:.2px}
hr{border-color:var(--line);opacity:.4;margin:1rem 0}

.card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:16px;transition:border-color 0.2s}
.card:hover{border-color:#294166}
.badge{display:inline-flex;gap:6px;align-items:center;padding:4px 10px;border-radius:999px;
  background:rgba(34,211,238,.12);border:1px solid rgba(34,211,238,.25);font-size:12px;text-decoration:none;color:var(--text)}
.badge:hover{background:rgba(34,211,238,.18)}
.kpi{font-size:28px;font-weight:700}
.muted{color:var(--muted)}

.stButton>button, .stDownloadButton>button { border-radius: 14px; padding: .8rem 1.1rem; font-weight: 700; font-size: 15px; }

.status-grid{display:grid;grid-template-columns:repeat(4,1fr);gap:14px;margin:1rem 0}
.status .name{font-weight:600;font-size:16px}
.status .url{font-size:12px;color:var(--muted);margin-top:4px}
.status .state{margin-top:12px;font-size:13px}
.pulse{position:relative;padding-left:22px}
.pulse:before{content:"";position:absolute;left:0;top:50%;width:10px;height:10px;border-radius:50%;
  transform:translateY(-50%);background:var(--err);box-shadow:0 0 0 0 rgba(239,68,68,.6);animation:pulse 1.6s infinite}
.ok .pulse:before{background:var(--ok);box-shadow:0 0 0 0 rgba(34,197,94,.5);animation:pulse-ok 1.6s infinite}
@keyframes pulse { 0%{box-shadow:0 0 0 0 rgba(239,68,68,.6)} 70%{box-shadow:0 0 0 12px rgba(239,68,68,0)} 100%{box-shadow:0 0 0 0 rgba(239,68,68,0)} }
@keyframes pulse-ok { 0%{box-shadow:0 0 0 0 rgba(34,197,94,.5)} 70%{box-shadow:0 0 0 12px rgba(34,197,94,0)} 100%{box-shadow:0 0 0 0 rgba(34,197,94,0)} }

.section-title{display:flex;align-items:center;gap:10px;margin:1.5rem 0 1rem}
.section-title h3{margin:0}
.section-title:after{content:"";flex:1;height:1px;background:linear-gradient(90deg,transparent, var(--line))}

.quick-dock{position:fixed;right:18px;bottom:18px;display:flex;gap:8px;z-index:999}
.quick-dock a{background:var(--card);border:1px solid var(--line);padding:10px 12px;border-radius:12px;text-decoration:none;color:var(--text);font-size:13px;font-weight:600;transition:all 0.2s}
.quick-dock a:hover{border-color:#294166;background:var(--bg2)}

.service-card{background:var(--card);border:1px solid var(--line);border-radius:14px;padding:18px;margin-bottom:12px;transition:all 0.2s}
.service-card:hover{border-color:#294166;transform:translateY(-2px)}
.service-card .title{font-weight:700;font-size:18px;margin-bottom:6px}
.service-card .desc{color:var(--muted);font-size:14px;margin-bottom:12px}

.hero-section{margin-bottom:2rem}
.hero-section h1{margin-bottom:0.3rem}
.hero-section .subtitle{color:var(--muted);font-size:16px;margin-bottom:1.5rem}

.stTabs [data-baseweb="tab-list"] { gap: 8px; }
.stTabs [data-baseweb="tab"] { padding:10px 14px;border-radius:10px;background:var(--card);border:1px solid var(--line) }
.stTabs [data-baseweb="tab"][aria-selected="true"] { background:var(--bg2);border-color:var(--pri) }

a{text-decoration:none!important}
</style>
""", unsafe_allow_html=True)

# Hero Section
st.markdown("""
<div class="hero-section">
<h1>ğŸª© Data Lakehouse â€“ Modern Data Stack</h1>
<div class="subtitle"><strong>ETL â€¢ Forecast â€¢ OLAP â€¢ AI Chat â€¢ BI</strong> â€” táº¥t cáº£ trong má»™t Control Center</div>
</div>
""", unsafe_allow_html=True)

# Quick CTA Buttons
ctaA, ctaB, ctaC = st.columns([1,1,1])
with ctaA:
    st.page_link("pages/1_ğŸ“Š_Query_Window.py", label="ğŸ“Š Query Window", help="OLAP ROLLUP/GROUPING SETS", use_container_width=True)
with ctaB:
    st.page_link("pages/2_ğŸ’¬_Chat.py", label="ğŸ’¬ Chat Analytics", use_container_width=True)
with ctaC:
    st.link_button("âš™ï¸ Dagster", "http://localhost:3001", help="ETL Orchestration", use_container_width=True)

st.markdown("<br>", unsafe_allow_html=True)

# Service Status with Pulse Animation
# Use internal Docker network URLs for health checks
SERVICES = [
    ("Trino", "http://trino:8080", "Port 8082 (ext)"),
    ("Dagster", "http://de_dagster_dagit:3001", "Port 3001"),
    ("Metabase", "http://metabase:3000", "Port 3000"),
    ("MinIO", "http://minio:9000", "Port 9001 (console)"),
]

st.markdown("### ğŸ” Tráº¡ng thÃ¡i há»‡ thá»‘ng")

# Build status cards with ping - using Streamlit native components
status_cols = st.columns(4)

for idx, (name, url, port) in enumerate(SERVICES):
    t0 = time.time()
    ok = False
    try:
        requests.get(url, timeout=1.2)
        ok = True
    except:
        pass
    latency = int((time.time() - t0) * 1000)
    
    with status_cols[idx]:
        # Display in card-like container
        with st.container():
            st.markdown(f"**{name}**")
            st.caption(port)
            
            if ok:
                st.success(f"âœ… Online â€¢ {latency}ms", icon="ğŸŸ¢")
            else:
                st.error(f"â›” Offline â€¢ {latency}ms", icon="ğŸ”´")
            
            # External URL button
            external_url = url.replace("trino:8080", "localhost:8082").replace("de_dagster_dagit:3001", "localhost:3001").replace("metabase:3000", "localhost:3000").replace("minio:9000", "localhost:9001")
            st.link_button(f"Má»Ÿ {name}", external_url, use_container_width=True, type="secondary")

st.divider()

# Tabs for Services & Architecture
tab_services, tab_arch, tab_docs = st.tabs(["ğŸ§© Dá»‹ch vá»¥", "ğŸ—ºï¸ Kiáº¿n trÃºc", "ğŸ“š TÃ i liá»‡u"])

with tab_services:
    sc1, sc2 = st.columns(2)
    
    with sc1:
        st.markdown("<div class='section-title'><h3>ğŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u</h3></div>", unsafe_allow_html=True)
    
    # Query Window
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ§® Query Window</div>
        <div class='desc'>Truy váº¥n Ä‘a chiá»u (OLAP) vá»›i ROLLUP, GROUPING SETS</div>
        </div>
        """, unsafe_allow_html=True)
        st.page_link("pages/1_ğŸ“Š_Query_Window.py", label="Má»Ÿ Query Window", icon="ğŸ“Š", use_container_width=True)
        
        st.markdown("")
        
        # Chat
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ’¬ Chat Analytics</div>
        <div class='desc'>Há»i Ä‘Ã¡p báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn vá»›i SQL + RAG</div>
        </div>
        """, unsafe_allow_html=True)
        st.page_link("pages/2_ğŸ’¬_Chat.py", label="Má»Ÿ Chat", icon="ğŸ’¬", use_container_width=True)
        
        st.markdown("")
        
        # Forecast Explorer
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ“ˆ Forecast Explorer</div>
        <div class='desc'>KhÃ¡m phÃ¡ dá»± bÃ¡o nhu cáº§u vá»›i Machine Learning</div>
        </div>
        """, unsafe_allow_html=True)
        st.page_link("pages/3_ğŸ“ˆ_Forecast_Explorer.py", label="Má»Ÿ Forecast Explorer", icon="ğŸ“ˆ", use_container_width=True)
        
        st.markdown("")
    
    # Metabase
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ“Š Metabase</div>
        <div class='desc'>BI dashboards cho business users</div>
        </div>
        """, unsafe_allow_html=True)
        st.link_button("Má»Ÿ Metabase", "http://localhost:3000", use_container_width=True)
    
    with sc2:
        st.markdown("<div class='section-title'><h3>ğŸ› ï¸ Váº­n hÃ nh & Quáº£n lÃ½</h3></div>", unsafe_allow_html=True)
    
    # Dagster
        st.markdown("""
        <div class='service-card'>
        <div class='title'>âš™ï¸ Dagster</div>
        <div class='desc'>Orchestration & monitoring cho ETL pipelines</div>
        </div>
        """, unsafe_allow_html=True)
        st.link_button("Má»Ÿ Dagster", "http://localhost:3001", use_container_width=True)
        
        st.markdown("")
    
    # MinIO
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸª£ MinIO Console</div>
        <div class='desc'>Quáº£n lÃ½ object storage (S3-compatible)</div>
        </div>
        """, unsafe_allow_html=True)
        st.link_button("Má»Ÿ MinIO", "http://localhost:9001", use_container_width=True)
        
        st.markdown("")
        
        # Spark
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ”¥ Spark Master</div>
        <div class='desc'>Monitor Spark cluster & jobs</div>
        </div>
        """, unsafe_allow_html=True)
        st.link_button("Má»Ÿ Spark UI", "http://localhost:8080", use_container_width=True)
        
        st.markdown("")
        
        # Trino
        st.markdown("""
        <div class='service-card'>
        <div class='title'>ğŸ”º Trino UI</div>
        <div class='desc'>Query coordinator & cluster info</div>
        </div>
        """, unsafe_allow_html=True)
        st.link_button("Má»Ÿ Trino UI", "http://localhost:8082", use_container_width=True)

with tab_arch:
    st.markdown("### ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng")
    
    st.code("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       USER INTERFACES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit   â”‚  Metabase    â”‚   Dagster    â”‚   Jupyter         â”‚
â”‚  (Port 8501) â”‚  (Port 3000) â”‚  (Port 3001) â”‚   (Port 8888)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“              â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  QUERY & PROCESSING LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Trino     â”‚    Spark     â”‚   MLflow     â”‚   Chat Service    â”‚
â”‚  (Port 8082) â”‚  (Port 8080) â”‚  (Port 5000) â”‚   (Port 8001)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“              â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STORAGE & METADATA LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Delta Lake  â”‚     MinIO    â”‚    MySQL     â”‚   Qdrant          â”‚
â”‚  (Lakehouse) â”‚  (S3 Object) â”‚ (Metadata)   â”‚   (Vector DB)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """, language="text")
    
    st.markdown("### ğŸ“Š Medallion Architecture")
    
    arch_col1, arch_col2 = st.columns(2)
    
    with arch_col1:
        st.markdown("""
        **Data Flow:**
        
        ```
        MySQL (Source)
            â†“
        Bronze Layer (Raw)
            â†“
        Silver Layer (Cleaned)
            â†“
        Gold Layer (Star Schema)
            â†“
        Platinum Layer (Datamarts)
        ```
        """)
    
    with arch_col2:
        st.markdown("""
        **Statistics:**
        
        - **Bronze**: 9 tables (raw data)
        - **Silver**: 11 tables (cleaned)
        - **Gold**: 10 tables (star schema)
        - **Platinum**: 8 tables (datamarts)
        - **Total**: ~500MB storage
        """)

with tab_docs:
    st.markdown("### ğŸ“š TÃ i liá»‡u dá»± Ã¡n")
    
    doc_col1, doc_col2 = st.columns(2)
    
    with doc_col1:
        st.markdown("""
        **TÃ i liá»‡u ká»¹ thuáº­t:**
        
        - `PROJECT_OVERVIEW.md` - Tá»•ng quan hoÃ n chá»‰nh
        - `FORECAST_FILES.txt` - ML & Forecasting system
        - `STREAMLIT_APP_FILES.txt` - UI application
        - `UI_UX_IMPROVEMENTS.md` - UI/UX changelog
        - `README.md` - Quick start guide
        """)
    
    with doc_col2:
        st.markdown("""
        **Use Cases chÃ­nh:**
        
        1. **Business Analytics** - Truy váº¥n OLAP
        2. **Demand Forecasting** - Dá»± bÃ¡o 28 ngÃ y
        3. **Natural Language Queries** - Chat interface
        4. **BI Dashboards** - Metabase reports
        """)
    
    st.info("ğŸ’¡ Xem thÃªm chi tiáº¿t trong cÃ¡c file tÃ i liá»‡u táº¡i thÆ° má»¥c gá»‘c dá»± Ã¡n")

# Quick Actions Dock
st.markdown("""
<div class='quick-dock'>
  <a href='http://localhost:3001' target='_blank' title='Dagster'>âš™ï¸</a>
  <a href='http://localhost:3000' target='_blank' title='Metabase'>ğŸ“Š</a>
  <a href='http://localhost:9001' target='_blank' title='MinIO'>ğŸª£</a>
  <a href='http://localhost:8080' target='_blank' title='Spark'>ğŸ”¥</a>
</div>
""", unsafe_allow_html=True)

# Footer
st.divider()
st.markdown("""
<div style='display:flex;justify-content:space-between;opacity:.8;font-size:14px'>
  <span>ğŸª© Data Lakehouse â€¢ Modern Data Stack</span>
  <span>Built with â¤ï¸ by <b>Truong An</b> â€¢ MIT License</span>
</div>
""", unsafe_allow_html=True)

st.caption("ğŸ’¡ Máº¹o: DÃ¹ng **Quick Dock** (gÃ³c pháº£i dÆ°á»›i) hoáº·c sidebar Ä‘á»ƒ di chuyá»ƒn nhanh giá»¯a cÃ¡c trang")


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FILE: app/pages/1_ğŸ“Š_Query_Window.py
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

import os
import streamlit as st
import pandas as pd
from datetime import date, datetime, timedelta
from trino.dbapi import connect
from trino.auth import BasicAuthentication

# ====== Config ======
def get_conf(key, default=None):
    # Æ°u tiÃªn secrets.toml, sau Ä‘Ã³ env
    try:
        return st.secrets.get(key, os.getenv(key, default))
    except:
        return os.getenv(key, default)

TRINO_HOST = get_conf("TRINO_HOST", "trino")
TRINO_PORT = int(get_conf("TRINO_PORT", "8080"))
TRINO_CATALOG = get_conf("TRINO_CATALOG", "lakehouse")
TRINO_USER = get_conf("TRINO_USER", "admin")
TRINO_PASSWORD = get_conf("TRINO_PASSWORD", "") or None

DEFAULT_SCHEMA = get_conf("TRINO_DEFAULT_SCHEMA", "gold")

# ====== Helpers ======
@st.cache_data(ttl=600, show_spinner="Äang cháº¡y truy váº¥n...")
def run_query(sql: str, schema: str):
    """Execute SQL query on Trino and return DataFrame"""
    try:
        conn = connect(
            host=TRINO_HOST,
            port=TRINO_PORT,
            user=TRINO_USER,
            catalog=TRINO_CATALOG,
            schema=schema,
            http_scheme="http",
            auth=None if not TRINO_PASSWORD else BasicAuthentication(TRINO_USER, TRINO_PASSWORD),
            source="streamlit-query-window"
        )
        cur = conn.cursor()
        cur.execute(sql)
        rows = cur.fetchall()
        cols = [d[0] for d in cur.description]
        conn.close()
        return pd.DataFrame(rows, columns=cols)
    except Exception as e:
        st.error(f"Lá»—i káº¿t ná»‘i Trino: {e}")
        raise

def build_sql(catalog:str, schema:str, table:str, date_col:str, grain:str,
              dims:list, measures:list, start:date, end:date, extra_filters:str, 
              use_rollup:bool, use_grouping_sets:bool, limit:int=None):
    """Build SQL query with time grain, dimensions, and measures"""
    
    # Time grain expression
    grain_expr = f"date_trunc('{grain}', {date_col})"
    
    # Build SELECT clause
    select_cols = [f"{grain_expr} AS {grain}"]
    
    # Add dimensions to SELECT
    for dim in dims:
        if "." in dim:  # Handle joined columns
            select_cols.append(dim)
        else:
            select_cols.append(dim)
    
    # Add measures
    select_cols.extend(measures)
    
    # Build GROUP BY clause - use full expressions, not aliases
    group_cols = [grain_expr]  # Use full expression instead of alias
    group_cols.extend(dims)  # Add dimension columns
    
    # Build WHERE clause
    where = [f"CAST({date_col} AS date) BETWEEN DATE '{start}' AND DATE '{end}'"]
    if extra_filters.strip():
        banned = [";","--","/*","*/","DROP","TRUNCATE","INSERT","UPDATE","DELETE","CALL","CREATE","ALTER"]
        bad = [w for w in banned if w.lower() in extra_filters.lower()]
        if bad:
            raise ValueError(f"Filter chá»©a tá»« khÃ³a khÃ´ng há»£p lá»‡: {', '.join(set(bad))}")
        where.append(f"({extra_filters})")
    where_sql = " AND ".join(where)
    
    from_ = f"{catalog}.{schema}.{table}"
    
    # Build GROUP BY with ROLLUP or GROUPING SETS
    if use_grouping_sets and dims:
        sets = []
        # Full dims
        sets.append(f"({grain_expr}, {', '.join(dims)})")
        # Drop dims one by one
        for i in range(len(dims)-1, 0, -1):
            sets.append(f"({grain_expr}, {', '.join(dims[:i])})")
        # Only grain
        sets.append(f"({grain_expr})")
        # Grand total
        sets.append("()")
        group_sql = f"GROUP BY GROUPING SETS (\n  {', '.join(sets)}\n)"
    elif use_rollup and dims:
        group_sql = f"GROUP BY ROLLUP ({grain_expr}, {', '.join(dims)})"
    else:
        group_sql = f"GROUP BY {', '.join(group_cols)}"
    
    # Build ORDER BY - use column positions (1-based) for Trino compatibility
    # Äáº©y subtotal/grand total xuá»‘ng sau cÃ¹ng báº±ng cÃ¡ch sort NULLS LAST
    order_positions = [str(i+1) for i in range(1 + len(dims))]  # time grain + dimensions
    order_sql = "ORDER BY " + ", ".join([f"{p} NULLS LAST" for p in order_positions])
    
    # Build LIMIT
    limit_sql = f"LIMIT {limit}" if limit else ""
    
    sql = f"""
SELECT
  {', '.join(select_cols)}
FROM {from_}
WHERE {where_sql}
{group_sql}
{order_sql}
{limit_sql}
    """.strip()
    
    return sql

# ====== TABLE & COLUMN METADATA ======
TABLES_META = {
    "gold": {
        "fact_order": {
            "date_col": "full_date",
            "description": "Fact table: 1 row per order",
            "dimensions": [
                "customer_id",
                "primary_payment_type",
                "is_canceled",
                "delivered_on_time"
            ],
            "measures": [
                "COUNT(*) AS order_count",
                "COUNT(DISTINCT customer_id) AS unique_customers",
                "SUM(items_count) AS total_items",
                "SUM(sum_price) AS total_price",
                "SUM(sum_freight) AS total_freight",
                "SUM(payment_total) AS total_payment",
                "AVG(delivered_days) AS avg_delivery_days",
                "SUM(CASE WHEN delivered_on_time THEN 1 ELSE 0 END) AS on_time_deliveries",
                "SUM(CASE WHEN is_canceled THEN 1 ELSE 0 END) AS canceled_orders"
            ]
        },
        "fact_order_item": {
            "date_col": "full_date",
            "description": "Fact table: 1 row per order item",
            "dimensions": [
                "product_id",
                "seller_id",
                "customer_id",
                "order_status"
            ],
            "measures": [
                "COUNT(*) AS item_count",
                "COUNT(DISTINCT order_id) AS order_count",
                "COUNT(DISTINCT product_id) AS unique_products",
                "COUNT(DISTINCT seller_id) AS unique_sellers",
                "SUM(price) AS total_revenue",
                "SUM(freight_value) AS total_freight",
                "AVG(price) AS avg_item_price"
            ]
        }
    },
    "platinum": {
        "dm_sales_monthly_category": {
            "date_col": "month",
            "description": "Monthly sales by product category",
            "dimensions": [
                "product_category_name",
                "product_category_name_english"
            ],
            "measures": [
                "SUM(total_revenue) AS total_revenue",
                "SUM(total_items) AS total_items",
                "SUM(unique_products) AS unique_products",
                "AVG(avg_price) AS avg_price"
            ]
        }
    }
}

# Enhanced CSS
st.markdown("""
<style>
:root{
  --bg:#0b1220; --bg2:#10192b; --card:#0f172a; --line:#1f2a44;
  --text:#e2e8f0; --muted:#94a3b8; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444; --pri:#22d3ee;
}
.main .block-container{max-width:1280px;padding-top:1rem;padding-bottom:3rem}
h1,h2,h3{letter-spacing:.2px}
hr{border-color:var(--line);opacity:.4;margin:1rem 0}
.card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:16px;transition:border-color 0.2s}
.card:hover{border-color:#294166}
.badge{display:inline-flex;gap:6px;align-items:center;padding:4px 10px;border-radius:999px;
  background:rgba(34,211,238,.12);border:1px solid rgba(34,211,238,.25);font-size:12px}
.muted{color:var(--muted)}
.stButton>button{border-radius:14px;padding:.8rem 1.1rem;font-weight:700;font-size:15px}
.section-title{display:flex;align-items:center;gap:10px;margin:1.5rem 0 1rem}
.section-title h3{margin:0}
.section-title:after{content:"";flex:1;height:1px;background:linear-gradient(90deg,transparent, var(--line))}
</style>
""", unsafe_allow_html=True)

# ====== UI ======
st.title("ğŸ§® Cá»­a sá»• truy váº¥n Ä‘a chiá»u")
st.caption("PhÃ¢n tÃ­ch dá»¯ liá»‡u Brazilian E-commerce vá»›i Trino â€¢ OLAP ROLLUP/GROUPING SETS")

# ====== Schema & Table Selection ======
col_meta1, col_meta2 = st.columns(2)

with col_meta1:
    schemas = list(TABLES_META.keys())
    schema = st.selectbox("ğŸ“ Schema", schemas, index=schemas.index(DEFAULT_SCHEMA))

with col_meta2:
    tables = list(TABLES_META[schema].keys())
    fact_table = st.selectbox("ğŸ“Š Fact Table", tables)

table_meta = TABLES_META[schema][fact_table]
st.info(f"â„¹ï¸ {table_meta['description']}")

# ====== Time Selection ======
st.subheader("â° Thá»i gian")
col_time1, col_time2, col_time3 = st.columns(3)

with col_time1:
    time_grain = st.selectbox("ğŸ” Time Grain", ["day","week","month","quarter","year"], index=2)

with col_time2:
    # Default: last 6 months
    default_start = datetime.now().replace(day=1) - timedelta(days=180)
    start_date = st.date_input("ğŸ“… Tá»« ngÃ y", default_start.date())

with col_time3:
    end_date = st.date_input("ğŸ“… Äáº¿n ngÃ y", date.today())

# ====== Dimensions Selection ======
st.subheader("ğŸ“ Dimensions (Chiá»u phÃ¢n tÃ­ch)")
available_dims = table_meta["dimensions"]
dims = st.multiselect(
    "Chá»n cÃ¡c chiá»u Ä‘á»ƒ phÃ¢n tÃ­ch (tá»‘i Ä‘a 3-4 chiá»u cho hiá»‡u suáº¥t tá»‘t)",
    available_dims,
    default=available_dims[:2] if len(available_dims) >= 2 else available_dims
)

# ====== Measures Selection ======
st.subheader("ğŸ“ Measures (Chá»‰ sá»‘)")
available_measures = table_meta["measures"]
measures = st.multiselect(
    "Chá»n cÃ¡c chá»‰ sá»‘ cáº§n tÃ­nh toÃ¡n",
    available_measures,
    default=available_measures[:3] if len(available_measures) >= 3 else available_measures
)

# ====== Filters ======
st.subheader("ğŸ” Bá»™ lá»c")
extra_filters = st.text_area(
    "WHERE clause bá»• sung (vÃ­ dá»¥: primary_payment_type = 'credit_card' AND delivered_on_time = true)",
    "",
    height=80
)

# ====== Advanced Options ======
with st.expander("âš™ï¸ TÃ¹y chá»n nÃ¢ng cao"):
    col_adv1, col_adv2, col_adv3 = st.columns(3)
    
    with col_adv1:
        use_rollup = st.checkbox("DÃ¹ng ROLLUP (tá»•ng theo má»i cáº¥p)", value=False)
    
    with col_adv2:
        use_gsets = st.checkbox("DÃ¹ng GROUPING SETS", value=False)
    
    with col_adv3:
        limit_rows = st.number_input("Giá»›i háº¡n sá»‘ dÃ²ng", min_value=0, max_value=100000, value=10000, step=1000)

# ====== Run Query ======
if st.button("â–¶ï¸ Cháº¡y truy váº¥n", type="primary", use_container_width=True):
    if not dims:
        st.warning("âš ï¸ Vui lÃ²ng chá»n Ã­t nháº¥t 1 dimension")
        st.stop()
    
    if not measures:
        st.warning("âš ï¸ Vui lÃ²ng chá»n Ã­t nháº¥t 1 measure")
        st.stop()
    
    # Build SQL
    sql = build_sql(
        TRINO_CATALOG, schema, fact_table, table_meta["date_col"], time_grain,
        dims, measures, start_date, end_date, extra_filters,
        use_rollup, use_gsets, limit_rows if limit_rows > 0 else None
    )
    
    # Show SQL
    with st.expander("ğŸ“ SQL Query"):
        st.code(sql, language="sql")
    
    # Execute query
    try:
        with st.spinner("â³ Äang truy váº¥n dá»¯ liá»‡u..."):
            df = run_query(sql, schema)
        
        if df.empty:
            st.warning("ğŸ“­ KhÃ´ng cÃ³ dá»¯ liá»‡u phÃ¹ há»£p vá»›i Ä‘iá»u kiá»‡n")
            st.stop()
        
        # Display results
        st.success(f"âœ… Tráº£ vá» {len(df):,} dÃ²ng")
        st.subheader("ğŸ“Š Káº¿t quáº£")
        
        # Táº¡o báº£n hiá»ƒn thá»‹ riÃªng (giá»¯ df gá»‘c Ä‘á»ƒ export chuáº©n sá»‘)
        df_display = df.copy()
        numeric_cols = df_display.select_dtypes(include=['int64', 'float64']).columns
        for col in numeric_cols:
            df_display[col] = df_display[col].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
        
        st.dataframe(df_display, use_container_width=True, height=500)
        
        # Summary statistics
        with st.expander("ğŸ“ˆ Thá»‘ng kÃª tá»•ng há»£p"):
            st.write("Tá»•ng sá»‘ dÃ²ng:", f"{len(df):,}")
            st.write("CÃ¡c cá»™t:", ", ".join(df.columns))
        
        # Export options
        st.subheader("ğŸ’¾ Xuáº¥t dá»¯ liá»‡u")
        col_exp1, col_exp2 = st.columns(2)
        
        with col_exp1:
            # CSV export
            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "â¬‡ï¸ Táº£i CSV",
                csv,
                f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "text/csv",
                use_container_width=True
            )
        
        with col_exp2:
            # Excel export
            try:
                import io
                bio = io.BytesIO()
                with pd.ExcelWriter(bio, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='Query Result')
                st.download_button(
                    "â¬‡ï¸ Táº£i Excel",
                    bio.getvalue(),
                    f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            except Exception as e:
                st.error(f"Lá»—i export Excel: {e}")
        
    except Exception as e:
        st.error(f"âŒ Lá»—i truy váº¥n: {e}")
        st.code(sql, language="sql")

# ====== Help Section ======
with st.sidebar:
    st.header("â„¹ï¸ HÆ°á»›ng dáº«n")
    
    st.markdown("""
    ### CÃ¡ch sá»­ dá»¥ng:
    
    1. **Chá»n Schema & Table**: Chá»n lá»›p dá»¯ liá»‡u vÃ  báº£ng fact
    2. **Chá»n Time Grain**: Äá»™ chi tiáº¿t thá»i gian (ngÃ y/tuáº§n/thÃ¡ng...)
    3. **Chá»n Dimensions**: CÃ¡c chiá»u phÃ¢n tÃ­ch (tá»‘i Ä‘a 3-4)
    4. **Chá»n Measures**: CÃ¡c chá»‰ sá»‘ cáº§n tÃ­nh
    5. **ThÃªm Filters**: Äiá»u kiá»‡n lá»c bá»• sung (tÃ¹y chá»n)
    6. **Cháº¡y**: Nháº¥n nÃºt "Cháº¡y truy váº¥n"
    
    ### VÃ­ dá»¥ Filters:
    ```sql
    primary_payment_type = 'credit_card'
    delivered_on_time = true
    sum_price > 100
    ```
    
    ### Tips:
    - Giá»›i háº¡n khoáº£ng thá»i gian Ä‘á»ƒ truy váº¥n nhanh hÆ¡n
    - Chá»n Ã­t dimensions Ä‘á»ƒ trÃ¡nh quÃ¡ nhiá»u dÃ²ng
    - DÃ¹ng ROLLUP Ä‘á»ƒ xem tá»•ng theo tá»«ng cáº¥p
    """)
    
    st.divider()
    
    st.markdown(f"""
    **Trino Connection:**
    - Host: `{TRINO_HOST}:{TRINO_PORT}`
    - Catalog: `{TRINO_CATALOG}`
    - Schema: `{schema}`
    """)


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FILE: docker_image/streamlit/Dockerfile
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# app/Dockerfile

FROM python:3.9-slim-bullseye
WORKDIR /app

RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

#RUN pip install -r requirements.txt
COPY . .

RUN pip install --upgrade pip && pip install -r requirements.txt

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health || exit 1

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FILE: docker_image/streamlit/requirements.txt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

pandas
streamlit
trino
pyarrow
openpyxl
python-dateutil
cryptography==41.0.4
requests
python-dotenv


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FILE: docker-compose.yaml (streamlit service)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  streamlit:
    container_name: streamlit
    build:
      context: ./docker_image/streamlit
      dockerfile: Dockerfile
    image: streamlit:latest
    ports:
      - "8501:8501"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./app:/app
    networks:
      - de_network 


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CONFIGURATION SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¦ TRINO CONNECTION:

Default Configuration (built into Query Window):
- TRINO_HOST: trino
- TRINO_PORT: 8080
- TRINO_CATALOG: lakehouse
- TRINO_USER: admin
- TRINO_PASSWORD: (empty)
- TRINO_DEFAULT_SCHEMA: gold

Override via environment variables or Streamlit secrets.toml

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ PYTHON DEPENDENCIES:

Core Libraries:
- streamlit: Web UI framework
- pandas: Data manipulation
- trino: Trino database connector
- pyarrow: Arrow format support
- openpyxl: Excel export
- python-dateutil: Date handling
- requests: HTTP requests for health checks
- cryptography: SSL/TLS support
- python-dotenv: Environment variable loading

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ KEY FEATURES:

1. TIME GRAIN SUPPORT:
   - Day: date_trunc('day', date_col)
   - Week: date_trunc('week', date_col)
   - Month: date_trunc('month', date_col)
   - Quarter: date_trunc('quarter', date_col)
   - Year: date_trunc('year', date_col)

2. OLAP EXTENSIONS:
   - ROLLUP: Tá»•ng theo tá»«ng cáº¥p (grand total â†’ subtotals)
   - GROUPING SETS: Custom aggregation levels

3. DYNAMIC SQL GENERATION:
   - Auto-build SELECT clause (time grain + dimensions + measures)
   - Auto-build GROUP BY (with ROLLUP/GROUPING SETS support)
   - Auto-build WHERE (date range + custom filters)
   - Auto-build ORDER BY (by column positions)
   - Auto-limit for performance

4. SECURITY FEATURES:
   - SQL injection protection with banned keywords
   - Filter validation before execution
   - CAST date columns for robust filtering

5. EXPORT OPTIONS:
   - CSV download with UTF-8 encoding
   - Excel (.xlsx) download with openpyxl
   - Formatted timestamps
   - Preserved numeric types in exports

6. UI/UX ENHANCEMENTS:
   - Dark theme with Inter font
   - Enhanced CSS animations
   - Service status monitoring
   - Quick dock navigation
   - Responsive layouts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXAMPLE QUERIES GENERATED:

Example 1: Monthly sales by payment type
```sql
SELECT
  date_trunc('month', full_date) AS month,
  primary_payment_type,
  COUNT(*) AS order_count,
  SUM(sum_price) AS total_price,
  SUM(sum_freight) AS total_freight
FROM lakehouse.gold.fact_order
WHERE CAST(full_date AS date) BETWEEN DATE '2018-01-01' AND DATE '2018-12-31'
GROUP BY date_trunc('month', full_date), primary_payment_type
ORDER BY 1 NULLS LAST, 2 NULLS LAST
LIMIT 10000
```

Example 2: Product sales with ROLLUP
```sql
SELECT
  date_trunc('month', full_date) AS month,
  product_id,
  seller_id,
  COUNT(*) AS item_count,
  SUM(price) AS total_revenue
FROM lakehouse.gold.fact_order_item
WHERE CAST(full_date AS date) BETWEEN DATE '2018-01-01' AND DATE '2018-06-30'
GROUP BY ROLLUP (date_trunc('month', full_date), product_id, seller_id)
ORDER BY 1 NULLS LAST, 2 NULLS LAST, 3 NULLS LAST
LIMIT 5000
```

Example 3: Category sales with GROUPING SETS
```sql
SELECT
  date_trunc('quarter', month) AS quarter,
  product_category_name_english,
  SUM(total_revenue) AS total_revenue,
  SUM(total_items) AS total_items
FROM lakehouse.platinum.dm_sales_monthly_category
WHERE month BETWEEN DATE '2017-01-01' AND DATE '2018-12-31'
GROUP BY GROUPING SETS (
  (date_trunc('quarter', month), product_category_name_english),
  (date_trunc('quarter', month)),
  ()
)
ORDER BY 1 NULLS LAST, 2 NULLS LAST
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ DEPLOYMENT:

Build & Run:
```bash
# Build Streamlit image
docker compose build streamlit

# Start service
docker compose up -d streamlit

# Check logs
docker compose logs -f streamlit

# Access UI
open http://localhost:8501
```

Health Check:
```bash
# Check container health
docker compose ps streamlit

# Manual health check
curl http://localhost:8501/_stcore/health
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” TROUBLESHOOTING:

1. Cannot connect to Trino:
   - Check Trino service is running: docker compose ps trino
   - Check network: docker network inspect de_network
   - Verify catalog/schema exists in Trino

2. Query timeout:
   - Reduce date range
   - Reduce number of dimensions
   - Add more specific filters
   - Increase limit value

3. No data returned:
   - Verify table exists: docker exec trino trino --execute "SHOW TABLES FROM lakehouse.gold"
   - Check date range matches data dates
   - Verify filters are correct

4. Export fails:
   - For Excel: check openpyxl is installed
   - For CSV: check disk space
   - Check browser allows downloads

5. SQL injection error:
   - Review filter clause for banned keywords
   - Use parameterized queries where possible

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š SCHEMA METADATA:

The TABLES_META dictionary defines available tables, dimensions, and measures:

Structure:
{
  "schema_name": {
    "table_name": {
      "date_col": "date_column_name",
      "description": "Table description",
      "dimensions": ["dim1", "dim2", ...],
      "measures": ["measure1", "measure2", ...]
    }
  }
}

To add a new table:
1. Edit app/pages/1_ğŸ“Š_Query_Window.py
2. Add entry to TABLES_META dictionary
3. Restart Streamlit container

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… TÃNH NÄ‚NG Ná»”I Báº¬T:

1. No-code OLAP queries: Business users can analyze data without writing SQL
2. Flexible dimensions: Choose any combination of dimensions
3. Time series analysis: Built-in time grain support
4. Advanced aggregations: ROLLUP and GROUPING SETS for subtotals
5. Export ready: Download results for Excel/PowerBI/Tableau
6. Fast & scalable: Leverages Trino distributed query engine
7. Delta Lake integration: Query versioned, ACID-compliant data
8. Caching: Query results cached for 10 minutes (configurable)
9. Security: SQL injection protection
10. Modern UI: Dark theme, responsive design, status monitoring

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ SQL CONCEPTS USED:

1. date_trunc(): PostgreSQL/Trino function for time grain aggregation
2. ROLLUP: SQL:1999 OLAP extension for hierarchical totals
3. GROUPING SETS: SQL:1999 OLAP extension for custom aggregation levels
4. NULLS LAST: PostgreSQL/Trino sorting option
5. CAST() AS date: Robust date filtering
6. Window functions: (future enhancement)
7. CTE (Common Table Expressions): (future enhancement)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”® FUTURE ENHANCEMENTS:

- [ ] Add JOIN support for multi-fact queries
- [ ] Add PIVOT/UNPIVOT support
- [ ] Add chart visualization (bar/line/pie)
- [ ] Add query history
- [ ] Add saved queries/templates
- [ ] Add data drill-down capability
- [ ] Add calculated fields UI
- [ ] Add query performance monitoring
- [ ] Add query cost estimation
- [ ] Add materialized view support
- [ ] Add real-time data refresh
- [ ] Add user authentication/authorization

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… CHANGELOG:

2025-11-02 (Part 2d): Smart Date Handling for Brazilian E-commerce
- Auto-detect date coverage from actual data (2016-09-15 â†’ 2018-08-29)
- Smart defaults: last 6 months (month grain) or 90 days (day grain)
- Date picker clamped to min_value and max_value
- Display coverage info to users
- Validation with warnings for invalid ranges
- No more 2025 dates!

2025-11-02 (Part 2c): Production-Grade Optimization
- Added dual-predicate strategy for year_month (partition pruning + precise filtering)
- Fast partition pruning: year_month >= 'YYYY-MM' AND year_month <= 'YYYY-MM'
- Precise boundary checking: CAST(date_parse(...)) >= start AND < end_next
- All tests passed: half-open intervals, time ordering, leap year handling
- Production-ready performance and correctness

2025-11-02 (Part 2b): Date-Safe SQL Generation
- Enhanced build_sql() with half-open intervals ([start, end_next))
- Added _month_to_date() and _time_expr() helper functions
- Parse year_month VARCHAR to DATE for safe boundary comparison
- Proper time-aware sorting for year_month columns
- Fixed: +133% increase (was misreported as 233%)

2025-11-02 (Part 2a): Massive Platinum Layer Expansion
- Added 4 new platinum tables: dm_customer_lifecycle, dm_payment_mix, dm_logistics_sla, demand_forecast
- Smart date column handling: auto-detect year_month (varchar) vs full_date (date)
- Enhanced build_sql() to support YYYY-MM format filtering for platinum tables
- Total available tables: 7 (was 3 before, +133% increase)
- Removed 3 platinum tables without date dimensions (requires OPTION B upgrade)
- Updated dm_sales_monthly_category measures

2025-11-02 (Part 1): Updated to latest production codebase
- Added SQL injection protection
- Added CAST date filtering for robustness
- Added NULLS LAST ordering
- Separated display DataFrame from export DataFrame
- Optimized dependencies (removed unused packages)
- Enhanced UI with dark theme and modern design
- Added service status monitoring
- Fixed health check in Dockerfile

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

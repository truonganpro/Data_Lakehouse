#!/bin/bash

echo "ðŸš€ Starting Data Lakehouse System"
echo "================================="

# Táº¡o .env file náº¿u chÆ°a cÃ³
if [ ! -f .env ]; then
    echo "ðŸ“ Creating .env file..."
    cat > .env << EOF
MYSQL_ROOT_PASSWORD=root123
MYSQL_DATABASE=metastore
MYSQL_USER=hive
MYSQL_PASSWORD=hive
POSTGRES_DB=postgres
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123
EOF
    echo "âœ… .env file created"
fi

# Khá»Ÿi Ä‘á»™ng cÃ¡c services cáº§n thiáº¿t
echo "ðŸ³ Starting Docker services..."
docker-compose up -d de_mysql minio mc hive-metastore

# Äá»£i services khá»Ÿi Ä‘á»™ng
echo "â³ Waiting for services to be ready..."
sleep 30

# Kiá»ƒm tra tráº¡ng thÃ¡i services
echo "ðŸ” Checking service status..."
docker-compose ps

# Test káº¿t ná»‘i MinIO
echo "ðŸ” Testing MinIO connection..."
docker exec minio mc ls minio/

# Test káº¿t ná»‘i MySQL
echo "ðŸ” Testing MySQL connection..."
docker exec de_mysql mysql -u hive -phive -e "SHOW DATABASES;"

# Khá»Ÿi Ä‘á»™ng Spark cluster
echo "âš¡ Starting Spark cluster..."
docker-compose up -d spark-master spark-worker-1

# Äá»£i Spark khá»Ÿi Ä‘á»™ng
echo "â³ Waiting for Spark to be ready..."
sleep 20

# Test Spark káº¿t ná»‘i MinIO
echo "ðŸ” Testing Spark MinIO connection..."
docker exec spark-master python3 /opt/bitnami/spark/test_spark_minio_connection.py

echo "âœ… System startup and test completed!"
echo "ðŸŒ Access URLs:"
echo "   - Spark Master UI: http://localhost:8080"
echo "   - MinIO Console: http://localhost:9001 (minio/minio123)"
echo "   - Metabase: http://localhost:3000"
echo "   - Trino: http://localhost:8082"

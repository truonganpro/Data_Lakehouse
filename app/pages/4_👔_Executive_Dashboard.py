"""
Executive Dashboard Suite - B√°o c√°o tr·ª±c ti·∫øp cho l√£nh ƒë·∫°o
10 dashboard v·ªõi nhi·ªÅu bi·ªÉu ƒë·ªì v√† KPI tiles
"""
import os
import math
import datetime as dt
from typing import Tuple, List, Optional

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from trino.dbapi import connect
from trino.auth import BasicAuthentication

# =========================
# Page config & Style
# =========================
st.set_page_config(
    page_title="Executive Analytics Suite",
    page_icon="üëî",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Enhanced CSS - "x·ªãn s√≤" UI
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');

:root{
  --bg:#0b1220; --bg2:#10192b; --card:#0f172a; --line:#1f2a44;
  --text:#e2e8f0; --muted:#94a3b8; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444; --pri:#3B82F6;
  --sec:#10B981; --danger:#EF4444;
}

html, body, [class*=css] { font-family: 'Inter', sans-serif; }
.main .block-container{max-width:1400px;padding-top:1.2rem;padding-bottom:2rem}

/* KPI tile */
.kpi-card{
    border-radius:16px; 
    padding:16px 20px; 
    background:linear-gradient(135deg, var(--card) 0%, var(--bg2) 100%); 
    border:1px solid var(--line); 
    box-shadow:0 2px 12px rgba(0,0,0,0.15);
    transition:all 0.3s ease;
}
.kpi-card:hover{
    transform:translateY(-2px);
    box-shadow:0 4px 20px rgba(59,130,246,0.2);
    border-color:var(--pri);
}
.kpi-title{font-size:0.85rem; color:var(--muted); margin-bottom:6px; font-weight:500; text-transform:uppercase; letter-spacing:0.5px}
.kpi-value{font-size:1.8rem; font-weight:700; color:var(--text); margin-bottom:4px}
.kpi-delta{font-size:0.85rem; color:var(--muted); margin-top:4px}
.kpi-delta.positive{color:var(--sec)}
.kpi-delta.negative{color:var(--danger)}

hr{margin: 1.2rem 0 1.5rem 0; border-color:var(--line); opacity:0.3;}

/* Cards */
.stMetric {background:var(--card); border-radius:14px; padding:12px 16px; box-shadow:0 1px 6px rgba(0,0,0,0.1)}
.dataframe td, .dataframe th {font-size: 13px}

/* Section headers */
.section-header{display:flex; align-items:center; gap:12px; margin:1.5rem 0 1rem; padding-bottom:8px; border-bottom:2px solid var(--line)}
.section-header h2{margin:0; color:var(--text); font-size:24px}

/* Tabs */
.stTabs [data-baseweb="tab-list"] { gap: 8px; }
.stTabs [data-baseweb="tab"] { 
    padding:12px 20px;
    border-radius:12px;
    background:var(--card);
    border:1px solid var(--line);
    font-weight:600;
}
.stTabs [data-baseweb="tab"][aria-selected="true"] { 
    background:linear-gradient(135deg, var(--pri) 0%, #2563eb 100%);
    border-color:var(--pri);
    color:#fff;
}
</style>
""", unsafe_allow_html=True)

# =========================
# Config & Connection
# =========================
def get_conf(key, default=None):
    try:
        return st.secrets.get(key, os.getenv(key, default))
    except:
        return os.getenv(key, default)

TRINO_HOST = get_conf("TRINO_HOST", "trino")
TRINO_PORT = int(get_conf("TRINO_PORT", "8080"))
TRINO_CATALOG = get_conf("TRINO_CATALOG", "lakehouse")
TRINO_USER = get_conf("TRINO_USER", "admin")
TRINO_PASSWORD = get_conf("TRINO_PASSWORD", "") or None

SCHEMA_PL = "platinum"
SCHEMA_GD = "gold"

AUTH = None
if TRINO_PASSWORD:
    AUTH = BasicAuthentication(TRINO_USER, TRINO_PASSWORD)

DEFAULT_LIMIT = 5000
CACHE_TTL = 600  # 10 ph√∫t

# =========================
# Column Detection Helpers
# =========================
@st.cache_data(ttl=600)
def list_columns(schema: str, table: str) -> list:
    """Get list of column names from a table"""
    try:
        sql = f"""
        SELECT column_name
        FROM information_schema.columns
        WHERE table_schema = '{schema}' AND table_name = '{table}'
        ORDER BY ordinal_position
        """
        dfc = run_sql(sql, schema)
        return dfc["column_name"].str.lower().tolist() if not dfc.empty else []
    except:
        return []

def pick_col(cols: list, candidates: List[str]) -> Optional[str]:
    """Pick the first matching column name from candidates (case-insensitive)"""
    cols_lower = [c.lower() for c in cols]
    for c in candidates:
        if c.lower() in cols_lower:
            # Return original case from cols
            for col in cols:
                if col.lower() == c.lower():
                    # Get original case from information_schema
                    return col
    return None

def safe_plot(fig_func, df: pd.DataFrame, **kwargs):
    """Safely plot a figure, handling empty DataFrames"""
    if df is None or df.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì n√†y.")
        return
    try:
        fig = fig_func(df, **kwargs)
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")

@st.cache_data(ttl=CACHE_TTL, show_spinner=False)
def run_sql(sql: str, schema: str = SCHEMA_GD) -> pd.DataFrame:
    """Execute SQL query on Trino and return DataFrame with safety checks"""
    # Guardrails read-only
    low = sql.strip().lower()
    forbidden = ("insert", "update", "delete", "merge", "drop", "alter", "create", "call", "grant", "revoke")
    if any(tok in low for tok in forbidden):
        raise ValueError("Read-only enforced. Forbidden keyword detected.")
    if " bronze." in low or " silver." in low or f"{TRINO_CATALOG}.bronze" in low or f"{TRINO_CATALOG}.silver" in low:
        raise ValueError("Schema not allowed. Use gold/platinum only.")
    if " limit " not in low:
        sql = f"{sql.rstrip()}\nLIMIT {DEFAULT_LIMIT}"

    try:
        conn = connect(
            host=TRINO_HOST,
            port=TRINO_PORT,
            user=TRINO_USER,
            catalog=TRINO_CATALOG,
            schema=schema,
            http_scheme="http",
            auth=AUTH,
            source="streamlit-executive-dashboard"
        )
        cur = conn.cursor()
        cur.execute(sql)
        rows = cur.fetchall()
        cols = [d[0] for d in cur.description]
        conn.close()
        return pd.DataFrame(rows, columns=cols)
    except Exception as e:
        # Display error clearly in UI instead of silently returning empty DataFrame
        error_msg = str(e)
        # Show error message in Streamlit UI
        st.error(f"‚ùå Truy v·∫•n SQL l·ªói: {error_msg}")
        # Check if it's a table not found error - still show error but return empty DataFrame
        if "TABLE_NOT_FOUND" in error_msg or "does not exist" in error_msg.lower():
            st.warning("‚ö†Ô∏è B·∫£ng kh√¥ng t·ªìn t·∫°i. Vui l√≤ng ki·ªÉm tra t√™n b·∫£ng ho·∫∑c ch·∫°y ETL pipeline.")
            return pd.DataFrame()
        # For connection/auth errors, show detailed message
        if "connection" in error_msg.lower() or "authentication" in error_msg.lower() or "auth" in error_msg.lower():
            st.error(f"üîê L·ªói k·∫øt n·ªëi Trino: Ki·ªÉm tra TRINO_HOST, TRINO_PORT, TRINO_USER, TRINO_PASSWORD trong c·∫•u h√¨nh.")
        # Log full error for debugging
        import warnings
        warnings.warn(f"SQL Error: {error_msg}")
        return pd.DataFrame()

# =========================
# Column Name Detection & Standardization
# =========================
@st.cache_data(ttl=3600)
def detect_column_names():
    """Detect actual column names and create standardized aliases"""
    # Detect category column - prioritize product_category_name_english (standardized)
    cols_dm = list_columns(SCHEMA_PL, "dm_sales_monthly_category")
    cat_col = pick_col(cols_dm, ["product_category_name_english", "category_en", "category", "product_category"])
    
    # Detect state column - prioritize state (standardized UF)
    cols_geo = list_columns(SCHEMA_GD, "dim_geolocation")
    state_col_geo = pick_col(cols_geo, ["state", "geolocation_state", "customer_state"])
    
    if not state_col_geo:
        cols_cus = list_columns(SCHEMA_GD, "dim_customer")
        state_col_cus = pick_col(cols_cus, ["customer_state", "state"])
    else:
        state_col_cus = None
    
    return {
        "category_col": cat_col,
        "state_col_geo": state_col_geo,
        "state_col_cus": state_col_cus
    }

# Detect once at startup
COLUMN_NAMES = detect_column_names()

# =========================
# Date Coverage Detection
# =========================
@st.cache_data(ttl=3600)
def get_date_coverage():
    """Get actual date range from Brazilian E-commerce (Olist) data - use datamart for stability"""
    # Priority 1: Use platinum datamart (most reliable)
    try:
        sql = f"SELECT MIN(year_month) AS min_ym, MAX(year_month) AS max_ym FROM {SCHEMA_PL}.dm_sales_monthly_category"
        df = run_sql(sql, SCHEMA_PL)
        if not df.empty and df.loc[0, "min_ym"] and df.loc[0, "max_ym"]:
            ym_min = str(df.loc[0, "min_ym"])
            ym_max = str(df.loc[0, "max_ym"])
            # Convert 'YYYY-MM' to date (first of month)
            y_min, m_min = map(int, ym_min.split("-"))
            y_max, m_max = map(int, ym_max.split("-"))
            cov_min = dt.date(y_min, m_min, 1)
            # For max, use first of next month (for half-open interval)
            if m_max == 12:
                cov_max = dt.date(y_max + 1, 1, 1)
            else:
                cov_max = dt.date(y_max, m_max + 1, 1)
            return cov_min, cov_max
    except Exception:
        pass
    
    # Priority 2: Fallback to gold fact_order
    try:
        sql = f"SELECT CAST(MIN(full_date) AS date) AS min_d, CAST(MAX(full_date) AS date) AS max_d FROM {SCHEMA_GD}.fact_order WHERE full_date IS NOT NULL"
        df = run_sql(sql, SCHEMA_GD)
        if not df.empty and df.loc[0, "min_d"] and df.loc[0, "max_d"]:
            min_str = str(df.loc[0, "min_d"])
            max_str = str(df.loc[0, "max_d"])
            return dt.date.fromisoformat(min_str), dt.date.fromisoformat(max_str)
    except Exception:
        pass
    
    # Fallback for Olist dataset
    return dt.date(2016, 9, 4), dt.date(2018, 10, 17)

COVER_MIN, COVER_MAX = get_date_coverage()

# =========================
# Helper Functions
# =========================
def ym(date_obj: dt.date) -> str:
    """Convert date to YYYY-MM format"""
    return f"{date_obj.year:04d}-{date_obj.month:02d}"

def first_of_month(d: dt.date) -> dt.date:
    """Get first day of month"""
    return d.replace(day=1)

def next_month(d: dt.date) -> dt.date:
    """Get first day of next month"""
    if d.month == 12:
        return dt.date(d.year + 1, 1, 1)
    return dt.date(d.year, d.month + 1, 1)

def subtract_months(d: dt.date, months: int) -> dt.date:
    """Subtract months from a date safely"""
    year = d.year
    month = d.month - months
    while month <= 0:
        month += 12
        year -= 1
    day = min(d.day, [31, 29 if year % 4 == 0 and (year % 100 != 0 or year % 400 == 0) else 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31][month - 1])
    return dt.date(year, month, day)

def kpi_tile(title: str, value, delta: Optional[str] = None, delta_class: str = ""):
    """Render a KPI tile card"""
    delta_html = f'<div class="kpi-delta {delta_class}">{delta}</div>' if delta else ""
    st.markdown(f"""
    <div class="kpi-card">
      <div class="kpi-title">{title}</div>
      <div class="kpi-value">{value}</div>
      {delta_html}
    </div>
    """, unsafe_allow_html=True)

# =========================
# Sidebar Filters (global)
# =========================
st.sidebar.title("üîé B·ªô l·ªçc to√†n h·ªá th·ªëng")

preset = st.sidebar.selectbox("Kho·∫£ng th·ªùi gian", ["Last 12M", "2017", "2018", "Custom"], index=1)

if preset == "2017":
    start_date = dt.date(2017, 1, 1)
    end_date = dt.date(2017, 12, 31)
elif preset == "2018":
    start_date = dt.date(2018, 1, 1)
    end_date = dt.date(2018, 12, 31)
elif preset == "Last 12M":
    start_date = subtract_months(COVER_MAX, 12)
    start_date = first_of_month(start_date)
    end_date = COVER_MAX
else:
    start_date = st.sidebar.date_input("T·ª´ ng√†y", COVER_MIN, min_value=COVER_MIN, max_value=COVER_MAX)
    end_date = st.sidebar.date_input("ƒê·∫øn ng√†y (bao g·ªìm)", COVER_MAX, min_value=COVER_MIN, max_value=COVER_MAX)
    if end_date < start_date:
        st.sidebar.error("Ng√†y k·∫øt th√∫c ph·∫£i >= ng√†y b·∫Øt ƒë·∫ßu")

# Half-open cho year_month
end_next = next_month(end_date.replace(day=1)) if end_date.day == 1 else (end_date + dt.timedelta(days=1))
ym_start = ym(first_of_month(start_date))
ym_end_excl = ym(end_next)

# Basis switch
basis = st.sidebar.radio("Basis", ["Purchase (Sales)", "Delivery (SLA)"], index=0, horizontal=False)

# Category filter - with auto-detection and fallback
try:
    cat_col = COLUMN_NAMES.get("category_col")
    if cat_col:
        cats = run_sql(f"SELECT DISTINCT {cat_col} AS category FROM {SCHEMA_PL}.dm_sales_monthly_category WHERE {cat_col} IS NOT NULL ORDER BY category", SCHEMA_PL)
        if cats.empty:
            # Fallback: get categories from gold dimension table
            cols_pc = list_columns(SCHEMA_GD, "dim_product_category")
            pc_col = pick_col(cols_pc, ["product_category_name_english", "product_category_name"])
            if pc_col:
                cats = run_sql(f"SELECT DISTINCT {pc_col} AS category FROM {SCHEMA_GD}.dim_product_category WHERE {pc_col} IS NOT NULL ORDER BY 1", SCHEMA_GD)
    else:
        cats = pd.DataFrame()
        st.sidebar.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt category trong dm_sales_monthly_category")
    sel_cats = st.sidebar.multiselect("Danh m·ª•c (tu·ª≥ ch·ªçn)", cats["category"].dropna().tolist() if not cats.empty else [], default=[])
except Exception as e:
    sel_cats = []
    # Error already shown by run_sql, but don't break the UI

# State filter - with auto-detection
try:
    state_col_geo = COLUMN_NAMES.get("state_col_geo")
    state_col_cus = COLUMN_NAMES.get("state_col_cus")
    states = pd.DataFrame()
    if state_col_geo:
        states = run_sql(f"SELECT DISTINCT {state_col_geo} AS state FROM {SCHEMA_GD}.dim_geolocation WHERE {state_col_geo} IS NOT NULL ORDER BY state", SCHEMA_GD)
    elif state_col_cus:
        states = run_sql(f"SELECT DISTINCT {state_col_cus} AS state FROM {SCHEMA_GD}.dim_customer WHERE {state_col_cus} IS NOT NULL ORDER BY state", SCHEMA_GD)
    else:
        st.sidebar.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt state trong dim_geolocation/dim_customer")
    sel_states = st.sidebar.multiselect("Bang/State (tu·ª≥ ch·ªçn)", states["state"].tolist() if not states.empty else [], default=[])
except Exception as e:
    sel_states = []
    # Error already shown by run_sql, but don't break the UI

# Top-N slider
topn = st.sidebar.slider("Top-N (x·∫øp h·∫°ng)", min_value=5, max_value=50, value=15, step=5)

st.sidebar.markdown(f"<div style='color:var(--muted);font-size:12px;margin-top:20px'>‚è± Cache 10' ‚Ä¢ Read-only<br>üìå Coverage: {COVER_MIN} ‚Üí {COVER_MAX}</div>", unsafe_allow_html=True)

# =========================
# Header & Tabs
# =========================
st.markdown("""
<div class="section-header">
<h1>üìà Executive Analytics Suite</h1>
</div>
""", unsafe_allow_html=True)
st.caption("KPI chu·∫©n ho√° ‚Ä¢ Datamart-first ‚Ä¢ Drilldown nh·∫π ‚Ä¢ Read-only")

tabs = st.tabs([
    "Executive", "Growth", "Category/Product", "Geography",
    "Seller", "Operations", "Customer", "Finance", "Forecast", "Data Quality", "Insights & Recommendations"
])

# ================
# Tab 1: Executive
# ================
with tabs[0]:
    st.markdown("### Executive Overview")
    
    # Get summary stats for dynamic conclusion
    try:
        sql_summary = f"""
        SELECT 
            SUM(gmv) AS total_gmv,
            SUM(orders) AS total_orders,
            SUM(units) AS total_units,
            CASE WHEN SUM(orders)=0 THEN 0 ELSE ROUND(SUM(gmv)*1.0/SUM(orders),2) END AS avg_aov
        FROM {SCHEMA_PL}.dm_sales_monthly_category
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        LIMIT 1
        """
        df_sum = run_sql(sql_summary, SCHEMA_PL)
        if not df_sum.empty:
            gmv_val = float(df_sum.iloc[0]['total_gmv'])
            orders_val = int(df_sum.iloc[0]['total_orders'])
            units_val = int(df_sum.iloc[0]['total_units'])
            aov_val = float(df_sum.iloc[0]['avg_aov'])
        else:
            gmv_val, orders_val, units_val, aov_val = 0, 0, 0, 0
    except:
        gmv_val, orders_val, units_val, aov_val = 0, 0, 0, 0
    
    st.info(f"""
    **üìä K·∫øt lu·∫≠n nhanh**
    * GMV to√†n k·ª≥ ~{gmv_val/1e6:.2f}M BRL; Orders ~{orders_val:,}; Units ~{units_val:,}; **AOV ~{aov_val:.2f} BRL**.
    * ƒê·ªânh m√πa v·ª• **Nov-2017**; n·ª≠a ƒë·∫ßu nƒÉm tƒÉng ƒë·ªÅu, c√≥ nh·ªãp ch·ªØng th√°ng 6‚Äì7.
    * **Pareto**: ~20% danh m·ª•c (bed_bath_table, watches_gifts, health_beauty, sports_leisure‚Ä¶) ƒë√≥ng g√≥p ph·∫ßn l·ªõn GMV.
    
    **üí° H√†m √Ω**: Doanh thu ph·ª• thu·ªôc nh√≥m danh m·ª•c h·∫°t nh√¢n; t·ªëi ∆∞u AOV c√≥ t√°c d·ª•ng r√µ d·ªãp cu·ªëi nƒÉm.
    
    **üéØ H√†nh ƒë·ªông**: ∆Øu ti√™n t·ªìn kho/marketing cho Top-Pareto; tri·ªÉn khai bundle/upsell cho m√πa cao ƒëi·ªÉm.
    """)
    
    # Build category filter with detected column name
    cat_col = COLUMN_NAMES.get("category_col")
    cat_filter_sql = ""
    if sel_cats and cat_col:
        placeholders = ",".join(["'{}'".format(c) for c in sel_cats])
        cat_filter_sql = f"AND {cat_col} IN ({placeholders})"

    try:
        # Use detected column name and alias to 'category'
        select_cat = f"{cat_col} AS category" if cat_col else "NULL AS category"
        sql = f"""
        SELECT year_month, SUM(gmv) gmv, SUM(orders) orders, SUM(units) units,
               CASE WHEN SUM(orders)=0 THEN 0 ELSE ROUND(SUM(gmv)*1.0/SUM(orders),2) END aov
        FROM {SCHEMA_PL}.dm_sales_monthly_category
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
          {cat_filter_sql}
        GROUP BY year_month
        ORDER BY year_month
        LIMIT 100
        """
        df = run_sql(sql, SCHEMA_PL)
        
        if df.empty:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho filter ƒë√£ ch·ªçn.")
        else:
            gmv = float(df["gmv"].sum())
            orders = int(df["orders"].sum())
            units = int(df["units"].sum())
            aov = gmv / orders if orders else 0.0

            c1, c2, c3, c4 = st.columns(4)
            with c1:
                kpi_tile("GMV (BRL)", f"{gmv:,.0f}", "Total Gross Merchandise Value")
            with c2:
                kpi_tile("Orders", f"{orders:,}", "Total orders")
            with c3:
                kpi_tile("Units", f"{units:,}", "Total items sold")
            with c4:
                kpi_tile("AOV (BRL)", f"{aov:,.2f}", "Average Order Value")

            st.markdown("<br>", unsafe_allow_html=True)

            # Line chart: GMV-Orders-AOV
            fig = px.line(df, x="year_month", y=["gmv", "orders", "aov"], 
                         markers=True, title="GMV, Orders, v√† AOV theo th·ªùi gian",
                         labels={"value": "Gi√° tr·ªã", "year_month": "Th√°ng"})
            fig.update_layout(height=400, template="plotly_dark", 
                            plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig, use_container_width=True)

            # Top Categories - use detected column name with alias
            if cat_col:
                sql_top = f"""
                SELECT {cat_col} AS category, SUM(gmv) gmv, SUM(orders) orders, SUM(units) units
                FROM {SCHEMA_PL}.dm_sales_monthly_category
                WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
                  {cat_filter_sql}
                GROUP BY {cat_col}
                ORDER BY gmv DESC
                LIMIT {topn}
                """
                df_top = run_sql(sql_top, SCHEMA_PL)
            else:
                df_top = pd.DataFrame()
            
            c5, c6 = st.columns([2, 1])
            with c5:
                st.markdown("#### Top Categories (GMV)")
                safe_plot(px.bar, df_top, x="category", y="gmv", 
                         title=f"Top {topn} Categories by GMV",
                         labels={"gmv": "GMV (BRL)", "category": "Category"}, height=420)
            
            with c6:
                st.markdown("#### C∆° c·∫•u Orders/Units")
                df_melt = df_top.melt(id_vars="category", value_vars=["orders", "units"])
                fig_group = px.bar(df_melt, x="category", y="value", color="variable",
                                  barmode="group", height=420,
                                  labels={"value": "S·ªë l∆∞·ª£ng", "category": "Category"})
                fig_group.update_layout(template="plotly_dark",
                                      plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
                st.plotly_chart(fig_group, use_container_width=True)

            st.dataframe(df_top, use_container_width=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Executive: {e}")

# =============
# Tab 2: Growth
# =============
with tabs[1]:
    st.markdown("### Growth & Revenue Analytics")
    
    # Calculate MoM/YoY for dynamic conclusion
    try:
        sql_growth = f"""
        SELECT year_month, SUM(gmv) gmv
        FROM {SCHEMA_PL}.dm_sales_monthly_category
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        GROUP BY year_month
        ORDER BY year_month
        LIMIT 100
        """
        df_g = run_sql(sql_growth, SCHEMA_PL)
        if not df_g.empty:
            df_g["gmv_lag1"] = df_g["gmv"].shift(1)
            df_g["mom"] = (df_g["gmv"] - df_g["gmv_lag1"]) / df_g["gmv_lag1"] * 100
            mom_last = df_g["mom"].iloc[-1] if not math.isnan(df_g["mom"].iloc[-1]) else 0
        else:
            mom_last = 0
    except:
        mom_last = 0
    
    st.info(f"""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **MoM** ·ªü k·ª≥ hi·ªÉn th·ªã l√† **{mom_last:.1f}%** (so s√°nh theo m√πa ‚Üí b√¨nh th∆∞·ªùng sau ƒë·ªânh).
    * **YoY** hi·ªÉn th·ªã 0% do thi·∫øu ƒë·ªß c·ª≠a s·ªï 12 th√°ng ƒë·ªëi ·ª©ng (logic ƒë√∫ng).
    * ƒê∆∞·ªùng GMV theo th√°ng tƒÉng d·∫ßn, b·ª©t ph√° Q4.
    
    **üí° H√†m √Ω**: So s√°nh MoM c·∫ßn ƒëi k√®m seasonality; YoY n√™n d√πng ƒë·ªß 12 th√°ng.
    
    **üéØ H√†nh ƒë·ªông**: B·∫≠t Moving Average 3M tr√™n chart; theo d√µi "rising categories" (thay ƒë·ªïi Pareto theo th√°ng).
    """)
    
    try:
        sql = f"""
        SELECT year_month, SUM(gmv) gmv, SUM(orders) orders
        FROM {SCHEMA_PL}.dm_sales_monthly_category
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        GROUP BY year_month
        ORDER BY year_month
        LIMIT 100
        """
        df_growth = run_sql(sql, SCHEMA_PL)
        
        if not df_growth.empty:
            df_growth["gmv_lag1"] = df_growth["gmv"].shift(1)
            df_growth["gmv_lag12"] = df_growth["gmv"].shift(12)
            df_growth["mom"] = (df_growth["gmv"] - df_growth["gmv_lag1"]) / df_growth["gmv_lag1"] * 100
            df_growth["yoy"] = (df_growth["gmv"] - df_growth["gmv_lag12"]) / df_growth["gmv_lag12"] * 100

            c1, c2 = st.columns(2)
            with c1:
                mom_val = df_growth["mom"].iloc[-1] if not math.isnan(df_growth["mom"].iloc[-1]) else 0
                kpi_tile("MoM Growth (GMV)", f"{mom_val:.1f}%", 
                        "Month-over-Month", "positive" if mom_val > 0 else "negative")
            with c2:
                yoy_val = df_growth["yoy"].iloc[-1] if not math.isnan(df_growth["yoy"].iloc[-1]) else 0
                kpi_tile("YoY Growth (GMV)", f"{yoy_val:.1f}%",
                        "Year-over-Year", "positive" if yoy_val > 0 else "negative")

            # Area chart
            fig_area = px.area(df_growth, x="year_month", y="gmv",
                              title="GMV theo th·ªùi gian (Area Chart)",
                              labels={"gmv": "GMV (BRL)", "year_month": "Th√°ng"})
            fig_area.update_layout(height=360, template="plotly_dark",
                                 plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_area, use_container_width=True)

            # Pareto - use detected column name with alias
            if cat_col:
                sql_pareto = f"""
                SELECT {cat_col} AS category, SUM(gmv) gmv
                FROM {SCHEMA_PL}.dm_sales_monthly_category
                WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
                GROUP BY {cat_col}
                ORDER BY gmv DESC
                LIMIT 20
                """
                df_par = run_sql(sql_pareto, SCHEMA_PL)
            else:
                df_par = pd.DataFrame()
            if not df_par.empty:
                df_par["cum_share"] = (df_par["gmv"].cumsum() / df_par["gmv"].sum() * 100).round(1)
                figp = go.Figure()
                figp.add_bar(x=df_par["category"], y=df_par["gmv"], name="GMV")
                figp.add_scatter(x=df_par["category"], y=df_par["cum_share"],
                               name="Cumulative %", yaxis="y2", mode="lines+markers")
                figp.update_layout(
                    title="Pareto: ƒë√≥ng g√≥p GMV theo danh m·ª•c",
                    yaxis=dict(title="GMV (BRL)"),
                    yaxis2=dict(title="Cumulative %", overlaying="y", side="right", range=[0, 100]),
                    height=420,
                    template="plotly_dark",
                    plot_bgcolor="rgba(0,0,0,0)",
                    paper_bgcolor="rgba(0,0,0,0)"
                )
                if not df_par.empty:
                    st.plotly_chart(figp, use_container_width=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Growth: {e}")

# =======================
# Tab 3: Category/Product
# =======================
with tabs[2]:
    st.markdown("### Category & Product Performance")
    st.info("""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **Heatmap** cho th·∫•y m√πa v·ª• r√µ ·ªü qu√† t·∫∑ng/beauty (cu·ªëi nƒÉm s√°ng).
    * **Top SKU** t·∫≠p trung ·ªü *computers*, *bed_bath_table*, *cool_stuff*; ƒë√≥ng g√≥p GMV l·ªõn v√† ·ªïn ƒë·ªãnh.
    
    **üí° H√†m √Ω**: SKU ƒë·∫ßu b·∫£ng quy·∫øt ƒë·ªãnh ph·∫ßn l·ªõn doanh thu; qu·∫£n tr·ªã gi√°, t·ªìn kho v√† hi·ªÉn th·ªã c·ª±c k·ª≥ quan tr·ªçng.
    
    **üéØ H√†nh ƒë·ªông**: ƒê·∫∑t ch·ªâ ti√™u GMV theo **th√°ng √ó danh m·ª•c** (kh√¥ng tuy·∫øn t√≠nh nƒÉm); A/B gi√°/khuy·∫øn m·∫°i cho Top-SKU.
    """)

    try:
        # Heatmap Category x Month - use detected column name with alias
        cat_col = COLUMN_NAMES.get("category_col")
        if cat_col:
            sql_catm = f"""
            SELECT year_month, {cat_col} AS category, SUM(gmv) gmv
            FROM {SCHEMA_PL}.dm_sales_monthly_category
            WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
            GROUP BY year_month, {cat_col}
            LIMIT 10000
            """
            df_catm = run_sql(sql_catm, SCHEMA_PL)
        else:
            df_catm = pd.DataFrame()
        if not df_catm.empty:
            pivot = df_catm.pivot_table(index="category", columns="year_month", values="gmv", fill_value=0.0)
            st.markdown("#### Heatmap: GMV theo Danh m·ª•c √ó Th√°ng")
            fig_heat = px.imshow(pivot, aspect="auto", title="GMV Heatmap",
                               labels=dict(x="Th√°ng", y="Category", color="GMV"))
            fig_heat.update_layout(height=400, template="plotly_dark",
                                 plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_heat, use_container_width=True)

        # Top products
        sql_prod = f"""
        SELECT p.product_id, COALESCE(pc.product_category_name_english, 'unknown') category_en,
               SUM(foi.price) gmv, COUNT(*) units
        FROM {SCHEMA_GD}.fact_order_item foi
        JOIN {SCHEMA_GD}.dim_product p ON foi.product_id=p.product_id
        LEFT JOIN {SCHEMA_GD}.dim_product_category pc ON p.product_category_name=pc.product_category_name
        JOIN {SCHEMA_GD}.dim_date d ON foi.full_date=d.full_date
        WHERE d.year_month >= '{ym_start}' AND d.year_month < '{ym_end_excl}'
        GROUP BY 1,2
        ORDER BY gmv DESC
        LIMIT {topn * 3}
        """
        df_prod = run_sql(sql_prod, SCHEMA_GD)
        if not df_prod.empty:
            c1, c2 = st.columns([2, 1])
            with c1:
                st.markdown("#### Top s·∫£n ph·∫©m theo GMV")
                fig_prod = px.bar(df_prod.head(topn), x="product_id", y="gmv", color="category_en",
                                 height=420, labels={"gmv": "GMV (BRL)", "product_id": "Product ID"})
                fig_prod.update_layout(template="plotly_dark",
                                     plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
                st.plotly_chart(fig_prod, use_container_width=True)
            with c2:
                st.markdown("#### B·∫£ng chi ti·∫øt")
                st.dataframe(df_prod.head(topn), use_container_width=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Category/Product: {e}")

# ===============
# Tab 4: Geography
# ===============
with tabs[3]:
    st.markdown("### Geography & Market Expansion")
    st.info("""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **SP, RJ, MG** d·∫´n ƒë·∫ßu GMV; c√°c bang ƒëu√¥i c√≥ **on-time t·ªët nh∆∞ng GMV th·∫•p** ‚Üí d∆∞ ƒë·ªãa m·ªü r·ªông.
    * M·ªôt s·ªë bang c√≥ **delivery days** cao (outlier >20 ng√†y).
    
    **üí° H√†m √Ω**: C·∫ßn t·ªëi ∆∞u **last-mile** theo v√πng; ∆∞u ti√™n ƒë·∫ßu t∆∞ marketing ·ªü bang on-time t·ªët/GMV th·∫•p.
    
    **üéØ H√†nh ƒë·ªông**: Thi·∫øt l·∫≠p **SLA theo bang** (ƒë·ªëi t√°c 3PL, tuy·∫øn, promise); ch·∫°y chi·∫øn d·ªãch ƒë·ªãa ph∆∞∆°ng t·∫°i bang ti·ªÅm nƒÉng.
    """)
    
    try:
        # GMV by State - use detected column name with proper JOIN
        state_col_geo = COLUMN_NAMES.get("state_col_geo")
        state_col_cus = COLUMN_NAMES.get("state_col_cus")
        
        if state_col_geo:
            sql_geo = f"""
            SELECT g.{state_col_geo} AS state, SUM(foi.price) gmv, COUNT(DISTINCT foi.order_id) orders
            FROM {SCHEMA_GD}.fact_order_item foi
            JOIN {SCHEMA_GD}.fact_order fo ON foi.order_id=fo.order_id
            JOIN {SCHEMA_GD}.dim_customer c ON fo.customer_id = c.customer_id
            JOIN {SCHEMA_GD}.dim_geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix
            JOIN {SCHEMA_GD}.dim_date d ON fo.full_date=d.full_date
            WHERE d.year_month >= '{ym_start}' AND d.year_month < '{ym_end_excl}'
            GROUP BY g.{state_col_geo}
            ORDER BY gmv DESC
            LIMIT 50
            """
            df_geo = run_sql(sql_geo, SCHEMA_GD)
        elif state_col_cus:
            sql_geo = f"""
            SELECT c.{state_col_cus} AS state, SUM(foi.price) gmv, COUNT(DISTINCT foi.order_id) orders
            FROM {SCHEMA_GD}.fact_order_item foi
            JOIN {SCHEMA_GD}.fact_order fo ON foi.order_id=fo.order_id
            JOIN {SCHEMA_GD}.dim_customer c ON fo.customer_id = c.customer_id
            JOIN {SCHEMA_GD}.dim_date d ON fo.full_date=d.full_date
            WHERE d.year_month >= '{ym_start}' AND d.year_month < '{ym_end_excl}'
            GROUP BY c.{state_col_cus}
            ORDER BY gmv DESC
            LIMIT 50
            """
            df_geo = run_sql(sql_geo, SCHEMA_GD)
        else:
            df_geo = pd.DataFrame()
        safe_plot(px.bar, df_geo, x="state", y="gmv", title="GMV theo Bang/State",
                 labels={"gmv": "GMV (BRL)", "state": "State"}, height=400)

        # On-time by State - use detected column name with proper JOIN
        if state_col_geo:
            sql_ot = f"""
            SELECT g.{state_col_geo} AS state,
                   ROUND(AVG(CASE WHEN fo.delivered_on_time THEN 1 ELSE 0 END)*100,1) on_time_rate_pct,
                   ROUND(AVG(fo.delivered_days),2) delivery_days_avg,
                   COUNT(*) AS delivered_orders
            FROM {SCHEMA_GD}.fact_order fo
            JOIN {SCHEMA_GD}.dim_customer c ON fo.customer_id = c.customer_id
            JOIN {SCHEMA_GD}.dim_geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix
            WHERE fo.full_date >= DATE '{start_date}' AND fo.full_date < DATE '{end_next}'
              AND fo.is_canceled = FALSE
            GROUP BY g.{state_col_geo}
            ORDER BY on_time_rate_pct DESC
            LIMIT 50
            """
            df_ot = run_sql(sql_ot, SCHEMA_GD)
        elif state_col_cus:
            sql_ot = f"""
            SELECT c.{state_col_cus} AS state,
                   ROUND(AVG(CASE WHEN fo.delivered_on_time THEN 1 ELSE 0 END)*100,1) on_time_rate_pct,
                   ROUND(AVG(fo.delivered_days),2) delivery_days_avg,
                   COUNT(*) AS delivered_orders
            FROM {SCHEMA_GD}.fact_order fo
            JOIN {SCHEMA_GD}.dim_customer c ON fo.customer_id = c.customer_id
            WHERE fo.full_date >= DATE '{start_date}' AND fo.full_date < DATE '{end_next}'
              AND fo.is_canceled = FALSE
            GROUP BY c.{state_col_cus}
            ORDER BY on_time_rate_pct DESC
            LIMIT 50
            """
            df_ot = run_sql(sql_ot, SCHEMA_GD)
        else:
            df_ot = pd.DataFrame()
        if not df_ot.empty:
            c1, c2 = st.columns(2)
            with c1:
                safe_plot(px.bar, df_ot, x="state", y="on_time_rate_pct",
                         title="On-time Rate (%)", labels={"on_time_rate_pct": "On-time %", "state": "State"}, height=400)
            with c2:
                safe_plot(px.bar, df_ot, x="state", y="delivery_days_avg",
                         title="Avg Delivery Days", labels={"delivery_days_avg": "Days", "state": "State"}, height=400)
            st.dataframe(df_ot, use_container_width=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Geography: {e}")

# =============
# Tab 5: Seller
# =============
with tabs[4]:
    st.markdown("### Seller Performance & Compliance")
    
    # Get seller stats for dynamic conclusion
    try:
        sql_s = f"""
        SELECT 
            AVG(on_time_rate) on_time_rate, 
            AVG(cancel_rate) cancel_rate, 
            AVG(avg_review_score) avg_review_score
        FROM {SCHEMA_PL}.dm_seller_kpi
        LIMIT 1
        """
        df_s = run_sql(sql_s, SCHEMA_PL)
        if not df_s.empty:
            on_time_avg = float(df_s.iloc[0]['on_time_rate']) * 100
            cancel_avg = float(df_s.iloc[0]['cancel_rate']) * 100
            review_avg = float(df_s.iloc[0]['avg_review_score'])
        else:
            on_time_avg, cancel_avg, review_avg = 0, 0, 0
    except:
        on_time_avg, cancel_avg, review_avg = 0, 0, 0
    
    st.info(f"""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **On-time TB ~{on_time_avg:.1f}%**, **Cancel ~{cancel_avg:.2f}%**, **Avg review ~{review_avg:.2f}** (m·∫∑t b·∫±ng t·ªët).
    * C√≥ **seller outlier** (on_time <0.90 ho·∫∑c review <4.0) v·∫´n c√≥ GMV ƒë√°ng k·ªÉ.
    
    **üí° H√†m √Ω**: R·ªßi ro tr·∫£i nghi·ªám t·∫≠p trung ·ªü √≠t seller nh∆∞ng ·∫£nh h∆∞·ªüng l·ªõn.
    
    **üéØ H√†nh ƒë·ªông**: C·∫£nh b√°o t·ª± ƒë·ªông: `on_time<92%` **ho·∫∑c** `review<4.0` **v√†** GMV>ng∆∞·ª°ng; √°p d·ª•ng th∆∞·ªüng/ph·∫°t SLA & coaching.
    """)

    try:
        sql_seller = f"""
        SELECT seller_id,
               SUM(gmv) gmv, SUM(orders) orders, SUM(units) units,
               AVG(on_time_rate) on_time_rate, AVG(cancel_rate) cancel_rate, AVG(avg_review_score) avg_review_score
        FROM {SCHEMA_PL}.dm_seller_kpi
        GROUP BY seller_id
        ORDER BY gmv DESC
        LIMIT {topn * 3}
        """
        df_seller = run_sql(sql_seller, SCHEMA_PL)
        if not df_seller.empty:
            c1, c2, c3 = st.columns(3)
            with c1:
                kpi_tile("On-time TB", f"{df_seller['on_time_rate'].mean()*100:.1f}%", "Average")
            with c2:
                kpi_tile("Cancel TB", f"{df_seller['cancel_rate'].mean()*100:.2f}%", "Average")
            with c3:
                kpi_tile("Avg Review TB", f"{df_seller['avg_review_score'].mean():.2f}", "Average")

            fig_scatter = px.scatter(df_seller, x="on_time_rate", y="avg_review_score",
                                   size="gmv", hover_name="seller_id",
                                   title="On-time vs Review (bubble size=GMV)",
                                   labels={"on_time_rate": "On-time Rate", "avg_review_score": "Review Score"})
            fig_scatter.update_layout(height=420, template="plotly_dark",
                                    plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_scatter, use_container_width=True)
            st.dataframe(df_seller.head(topn), use_container_width=True)
        else:
            st.info("Ch∆∞a c√≥ dm_seller_kpi ho·∫∑c d·ªØ li·ªáu r·ªóng.")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Seller: {e}")

# ================
# Tab 6: Operations
# ================
with tabs[5]:
    st.markdown("### Operations & Logistics SLA (Delivery-basis)")
    
    # Get operations stats for dynamic conclusion
    try:
        sql_o = f"""
        SELECT 
            AVG(CASE WHEN fo.delivered_on_time THEN 1 ELSE 0 END) on_time_rate,
            AVG(fo.delivered_days) delivery_days
        FROM {SCHEMA_GD}.fact_order fo
        JOIN {SCHEMA_GD}.dim_date d ON fo.full_date = d.full_date
        WHERE fo.full_date >= DATE '{start_date}' AND fo.full_date < DATE '{end_next}'
          AND fo.is_canceled = FALSE
        LIMIT 1
        """
        df_o = run_sql(sql_o, SCHEMA_GD)
        if not df_o.empty:
            on_time_ops = float(df_o.iloc[0]['on_time_rate']) * 100
            delivery_days_ops = float(df_o.iloc[0]['delivery_days'])
        else:
            on_time_ops, delivery_days_ops = 0, 0
    except:
        on_time_ops, delivery_days_ops = 0, 0
    
    st.info(f"""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **On-time ~{on_time_ops:.1f}%**, **Delivery days ~{delivery_days_ops:.1f}**; c√≥ spike ·ªü v√†i th√°ng/bang tr√πng cao ƒëi·ªÉm.
    * Late orders ch·ªß y·∫øu ·ªü tuy·∫øn xa/ƒë·ªãa h√¨nh kh√≥.
    
    **üí° H√†m √Ω**: N√∫t th·∫Øt n·∫±m ·ªü nƒÉng l·ª±c line-haul/last-mile m√πa cao ƒëi·ªÉm.
    
    **üéØ H√†nh ƒë·ªông**: N√¢ng nƒÉng l·ª±c fulfillment tr∆∞·ªõc Q4 (cut-off, line-haul, 3PL d·ª± ph√≤ng); c√¥ng b·ªë **delivery promise theo bang**.
    """)

    try:
        sql_ops = f"""
        SELECT d.year_month,
               AVG(CASE WHEN fo.delivered_on_time THEN 1 ELSE 0 END) on_time_rate,
               AVG(fo.delivered_days) delivery_days,
               COUNT(*) AS delivered_orders
        FROM {SCHEMA_GD}.fact_order fo
        JOIN {SCHEMA_GD}.dim_date d ON fo.full_date = d.full_date
        WHERE fo.full_date >= DATE '{start_date}' AND fo.full_date < DATE '{end_next}'
          AND fo.is_canceled = FALSE
        GROUP BY d.year_month
        ORDER BY d.year_month
        LIMIT 100
        """
        df_ops = run_sql(sql_ops, SCHEMA_GD)
        if not df_ops.empty:
            c1, c2 = st.columns(2)
            with c1:
                kpi_tile("On-time TB", f"{df_ops['on_time_rate'].mean()*100:.1f}%", "Average")
            with c2:
                kpi_tile("Deliv Days TB", f"{df_ops['delivery_days'].mean():.2f}", "Average")

            fig_ops = px.line(df_ops, x="year_month", y="on_time_rate", markers=True,
                            title="On-time theo th√°ng",
                            labels={"on_time_rate": "On-time Rate", "year_month": "Th√°ng"})
            fig_ops.update_layout(height=400, template="plotly_dark",
                                plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_ops, use_container_width=True)

            fig_days = px.line(df_ops, x="year_month", y="delivery_days", markers=True,
                             title="Delivery days theo th√°ng",
                             labels={"delivery_days": "Days", "year_month": "Th√°ng"})
            fig_days.update_layout(height=400, template="plotly_dark",
                                 plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_days, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu SLA cho k·ª≥ ƒë√£ ch·ªçn.")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Operations: {e}")

# ===============
# Tab 7: Customer
# ===============
with tabs[6]:
    st.markdown("### Customer Lifecycle & Cohort")
    st.info("""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **Heatmap retention** ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng; **retention(k)** gi·∫£m d·∫ßn theo k (0..12 th√°ng).
    * D·ªëc gi·∫£m ph·∫£n √°nh ch·∫•t l∆∞·ª£ng tƒÉng tr∆∞·ªüng v√† hi·ªáu qu·∫£ gi·ªØ ch√¢n.
    
    **üí° H√†m √Ω**: Retention gi·∫£m d·∫ßn theo k l√† b√¨nh th∆∞·ªùng; d·ªëc gi·∫£m ph·∫£n √°nh ch·∫•t l∆∞·ª£ng tƒÉng tr∆∞·ªüng.
    
    **üéØ H√†nh ƒë·ªông**: √Åp d·ª•ng truy v·∫•n cohort ƒë√∫ng (0..12 th√°ng); ƒë·∫∑t OKR **k=1,3,6**; ch·∫°y remarketing cho cohort suy gi·∫£m.
    """)

    try:
        # Query with calculation of months_since_cohort and customer counts
        # FIXED: Only filter cohort_month by selected year, NOT activity_month
        # This allows customers from selected cohorts to show activity in subsequent months
        sql_cohort = f"""
        WITH first_purchase AS (
            SELECT 
                customer_id,
                MIN(d.year_month) as cohort_month
            FROM {SCHEMA_GD}.fact_order fo
            JOIN {SCHEMA_GD}.dim_date d ON fo.full_date = d.full_date
            WHERE fo.is_canceled = false
            GROUP BY customer_id
        ),
        cohort_size AS (
            SELECT 
                cohort_month,
                COUNT(DISTINCT customer_id) AS customers_in_cohort
            FROM first_purchase
            WHERE cohort_month >= '{ym_start}' AND cohort_month < '{ym_end_excl}'
            GROUP BY cohort_month
        ),
        monthly_activity AS (
            SELECT 
                fp.cohort_month,
                d.year_month,
                COUNT(DISTINCT fo.customer_id) AS customers_active,
                COUNT(DISTINCT fo.order_id) AS total_orders,
                SUM(COALESCE(fo.sum_price, 0) + COALESCE(fo.sum_freight, 0)) AS total_gmv
            FROM {SCHEMA_GD}.fact_order fo
            JOIN {SCHEMA_GD}.dim_date d ON fo.full_date = d.full_date
            INNER JOIN first_purchase fp ON fo.customer_id = fp.customer_id
            WHERE fp.cohort_month >= '{ym_start}' AND fp.cohort_month < '{ym_end_excl}'
              AND d.year_month >= fp.cohort_month
              AND fo.is_canceled = false
            GROUP BY fp.cohort_month, d.year_month
        )
        SELECT 
            ma.cohort_month,
            ma.year_month,
            CAST(SUBSTRING(ma.year_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.year_month, 6, 2) AS INTEGER) -
            (CAST(SUBSTRING(ma.cohort_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.cohort_month, 6, 2) AS INTEGER)) AS months_since_cohort,
            cs.customers_in_cohort,
            ma.customers_active,
            ma.total_orders,
            ma.total_gmv
        FROM monthly_activity ma
        JOIN cohort_size cs ON ma.cohort_month = cs.cohort_month
        WHERE CAST(SUBSTRING(ma.year_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.year_month, 6, 2) AS INTEGER) -
              (CAST(SUBSTRING(ma.cohort_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.cohort_month, 6, 2) AS INTEGER)) >= 0
          AND CAST(SUBSTRING(ma.year_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.year_month, 6, 2) AS INTEGER) -
              (CAST(SUBSTRING(ma.cohort_month, 1, 4) AS INTEGER) * 12 + CAST(SUBSTRING(ma.cohort_month, 6, 2) AS INTEGER)) <= 24
        ORDER BY ma.cohort_month, months_since_cohort
        LIMIT 10000
        """
        df_coh = run_sql(sql_cohort, SCHEMA_GD)
        if not df_coh.empty:
            # Ensure months_since_cohort is integer
            df_coh["months_since_cohort"] = df_coh["months_since_cohort"].astype(int)
            
            # Use customers_in_cohort from query (already calculated)
            if "customers_in_cohort" not in df_coh.columns:
                # Fallback: calculate from month 0
                cohort_0 = df_coh[df_coh["months_since_cohort"] == 0].set_index("cohort_month")["customers_active"]
                df_coh["cohort_size"] = df_coh["cohort_month"].map(cohort_0).fillna(0)
            else:
                df_coh["cohort_size"] = df_coh["customers_in_cohort"]
            
            if df_coh["cohort_size"].sum() == 0:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho th√°ng ƒë·∫ßu ti√™n c·ªßa cohort. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu.")
                st.dataframe(df_coh.head(20))
            else:
                df_coh = df_coh.copy()
                
                # Calculate retention: customers_active / cohort_size
                # Handle division by zero
                df_coh["retention"] = df_coh.apply(
                    lambda row: row["customers_active"] / row["cohort_size"] if row["cohort_size"] > 0 else 0.0,
                    axis=1
                )
                
                # Filter out rows with cohort_size = 0 for display
                df_coh_display = df_coh[df_coh["cohort_size"] > 0].copy()
                
                if df_coh_display.empty:
                    st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã sau khi l·ªçc.")
                    st.dataframe(df_coh.head(20))
                else:
                    # Retention Matrix
                    if len(df_coh_display) > 0:
                        mat = df_coh_display.pivot_table(
                            index="cohort_month", 
                            columns="months_since_cohort", 
                            values="retention", 
                            fill_value=0.0,
                            aggfunc='mean'
                        )
                        
                        if not mat.empty:
                            st.markdown("#### Retention Matrix (cohort √ó months_since_cohort)")
                            safe_plot(px.imshow, mat, aspect="auto", title="Customer Retention Heatmap",
                                     labels=dict(x="Months Since Cohort", y="Cohort Month", color="Retention"), 
                                     height=400, color_continuous_scale="Blues")
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o retention matrix.")
                        
                        # Orders trend
                        if len(df_coh_display) > 0:
                            fig_orders = px.line(df_coh_display, x="year_month", y="total_orders", color="cohort_month",
                                               title="Orders by Cohort over Time",
                                               labels={"total_orders": "Orders", "year_month": "Month"})
                            fig_orders.update_layout(height=350, template="plotly_dark",
                                                   plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
                            st.plotly_chart(fig_orders, use_container_width=True)
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì orders.")
                    
                    # Display data table
                    display_cols = ["cohort_month", "year_month", "months_since_cohort", "cohort_size", "customers_active", "retention", "total_orders"]
                    # Rename for display
                    df_display = df_coh_display[display_cols].copy()
                    df_display = df_display.rename(columns={"cohort_size": "customers_in_cohort"})
                    st.dataframe(
                        df_display.style.format({"retention": "{:.2%}"}), 
                        use_container_width=True
                    )
        else:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu cohort.")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Customer: {e}")

# =============
# Tab 8: Finance
# =============
with tabs[7]:
    st.markdown("### Finance & Payment Mix")
    
    # Get payment mix stats for dynamic conclusion
    try:
        sql_p = f"""
        SELECT 
            payment_type,
            SUM(payment_total) payment_total,
            AVG(installments) avg_installments
        FROM {SCHEMA_PL}.dm_payment_mix
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        GROUP BY payment_type
        ORDER BY payment_total DESC
        LIMIT 5
        """
        df_p = run_sql(sql_p, SCHEMA_PL)
        if not df_p.empty:
            credit_card_rows = df_p[df_p['payment_type'] == 'credit_card']
            credit_card_total = float(credit_card_rows['payment_total'].sum()) if not credit_card_rows.empty else 0
            total_payment = float(df_p['payment_total'].sum())
            credit_card_pct = (credit_card_total / total_payment * 100) if total_payment > 0 else 0
            avg_installments = float(credit_card_rows['avg_installments'].iloc[0]) if not credit_card_rows.empty and not pd.isna(credit_card_rows['avg_installments'].iloc[0]) else 0
        else:
            credit_card_pct, avg_installments = 0, 0
    except:
        credit_card_pct, avg_installments = 0, 0
    
    st.info(f"""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **credit_card** chi·∫øm t·ª∑ tr·ªçng l·ªõn (~{credit_card_pct:.1f}%) v√† **tƒÉng m·∫°nh cu·ªëi nƒÉm**; **installments ~{avg_installments:.1f}** ‚Üí kh√°ch s·∫µn s√†ng tr·∫£ g√≥p ng·∫Øn.
    * boleto/voucher t·ª∑ tr·ªçng nh·ªè, dao ƒë·ªông theo chi·∫øn d·ªãch.
    
    **üí° H√†m √Ω**: Payment mix nghi√™ng v·ªÅ th·∫ª ‚Üí ·∫£nh h∆∞·ªüng ph√≠ MDR v√† d√≤ng ti·ªÅn.
    
    **üéØ H√†nh ƒë·ªông**: ƒê√†m ph√°n ph√≠ v·ªõi PSP; A/B **∆∞u ƒë√£i installments** ·ªü ng√†nh h√†ng gi√° cao (computers/furniture).
    """)

    try:
        sql_mix = f"""
        SELECT year_month, payment_type, SUM(orders) orders, 
               SUM(unique_customers) unique_customers, SUM(payment_total) payment_total
        FROM {SCHEMA_PL}.dm_payment_mix
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        GROUP BY 1,2
        ORDER BY 1,2
        LIMIT 1000
        """
        df_mix = run_sql(sql_mix, SCHEMA_PL)
        if not df_mix.empty:
            fig_mix = px.area(df_mix, x="year_month", y="orders", color="payment_type",
                            title="Orders Share by Payment Type",
                            labels={"orders": "Orders", "year_month": "Th√°ng"})
            fig_mix.update_layout(height=380, template="plotly_dark",
                                plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_mix, use_container_width=True)

            # Installments
            sql_inst = f"""
            SELECT d.year_month, AVG(fp.payment_installments) avg_installments, 
                   COUNT(DISTINCT fp.order_id) orders
            FROM {SCHEMA_GD}.fact_payment fp
            JOIN {SCHEMA_GD}.fact_order fo ON fp.order_id=fo.order_id
            JOIN {SCHEMA_GD}.dim_date d ON fo.full_date=d.full_date
            WHERE fp.payment_type='credit_card'
              AND d.year_month >= '{ym_start}' AND d.year_month < '{ym_end_excl}'
            GROUP BY d.year_month
            ORDER BY d.year_month
            LIMIT 100
            """
            df_inst = run_sql(sql_inst, SCHEMA_GD)
            if not df_inst.empty:
                fig_inst = px.line(df_inst, x="year_month", y="avg_installments", markers=True,
                                 title="Avg Installments (credit_card)",
                                 labels={"avg_installments": "Avg Installments", "year_month": "Th√°ng"})
                fig_inst.update_layout(template="plotly_dark",
                                     plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
                st.plotly_chart(fig_inst, use_container_width=True)
            st.dataframe(df_mix, use_container_width=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Finance: {e}")

# ==============
# Tab 9: Forecast
# ==============
with tabs[8]:
    st.markdown("### Forecast & Planning")
    st.info("""
    D·ª± b√°o nhu c·∫ßu 14‚Äì28 ng√†y theo danh m·ª•c/v√πng; hi·ªÉn th·ªã **actual vs forecast** v√† **d·∫£i tin c·∫≠y**. 
    D√πng ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch t·ªìn kho v√† ng√¢n s√°ch.
    
    **üìä D·ªØ li·ªáu d·ª± b√°o ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang Forecast Explorer** - vui l√≤ng s·ª≠ d·ª•ng trang **Forecast Explorer** trong menu b√™n tr√°i.
    """)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **üìà Forecast Explorer cung c·∫•p:**
        - üîÆ D·ªØ li·ªáu d·ª± b√°o chi ti·∫øt
        - üìä Monitoring metrics (sMAPE, MAE)
        - üß™ MLflow experiment tracking
        - ‚öôÔ∏è Pipeline management qua Dagster
        """)
    
    with col2:
        st.markdown("""
        **üöÄ ƒê·ªÉ ch·∫°y forecast pipeline:**
        1. M·ªü **Forecast Explorer** (menu tr√°i)
        2. Ho·∫∑c m·ªü Dagster UI tr·ª±c ti·∫øp
        3. Jobs ‚Üí `forecast_job`
        4. Launch Run
        """)
    
    st.markdown("---")
    
    # Link to Forecast Explorer
    st.markdown("### üéØ Truy c·∫≠p Forecast Explorer")
    if st.button("üìä M·ªü Forecast Explorer", use_container_width=True, type="primary"):
        st.switch_page("pages/3_üìà_Forecast_Explorer.py")
    
    st.caption("üí° Ho·∫∑c click v√†o 'Forecast Explorer' trong menu b√™n tr√°i ƒë·ªÉ xem d·ªØ li·ªáu d·ª± b√°o chi ti·∫øt.")

# =================
# Tab 10: DQ & Ops
# =================
with tabs[9]:
    st.markdown("### Data Quality & Reliability")
    st.info("""
    **üìä K·∫øt lu·∫≠n nhanh**
    * **Pass rate 96‚Äì100%** ·ªü c√°c suite demo: pipeline ·ªïn ƒë·ªãnh, s·ªë li·ªáu ƒë√°ng tin.
    
    **üí° H√†m √Ω**: C√≥ th·ªÉ d·ª±a v√†o dashboard ƒë·ªÉ ra quy·∫øt ƒë·ªãnh; v·∫´n c·∫ßn canh drift/schema-change.
    
    **üéØ H√†nh ƒë·ªông**: N√¢ng DQ t·ª´ demo ‚Üí **rule v·∫≠n h√†nh** (row_count delta, domain 1..5 cho review, FK integrity, freshness); hi·ªÉn th·ªã **DQ badge** tr√™n t·ª´ng tab.
    """)

    try:
        # Demo data
        sql_counts = """
        SELECT 'bronze->silver->gold (demo)' AS suite, 98 AS pass_pct, 2 AS fail_cnt
        UNION ALL SELECT 'null/domain (demo)', 96, 4
        UNION ALL SELECT 'orphan FK (demo)', 100, 0
        """
        df_dq = run_sql(sql_counts, SCHEMA_GD)
        c1, c2 = st.columns(2)
        with c1:
            fig_dq = px.bar(df_dq, x="suite", y="pass_pct", title="% DQ pass (demo)",
                          labels={"pass_pct": "% Pass", "suite": "Test Suite"})
            fig_dq.update_layout(height=380, template="plotly_dark",
                               plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig_dq, use_container_width=True)
        with c2:
            st.dataframe(df_dq, use_container_width=True)
    except Exception as e:
        st.info(f"Ch∆∞a c√≥ d·ªØ li·ªáu DQ ho·∫∑c l·ªói: {e}")

# =================
# Tab 11: Insights & Recommendations
# =================
with tabs[10]:
    st.markdown("### üìä K·∫øt lu·∫≠n & Ki·∫øn ngh·ªã")
    st.info("""
    **Ph√¢n t√≠ch t·ªïng h·ª£p v√† ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông** d·ª±a tr√™n d·ªØ li·ªáu hi·ªán t·∫°i c·ªßa Executive Analytics Suite.
    """)
    
    # Get summary stats from Executive tab
    try:
        sql_summary = f"""
        SELECT 
            SUM(gmv) AS total_gmv,
            SUM(orders) AS total_orders,
            SUM(units) AS total_units,
            CASE WHEN SUM(orders)=0 THEN 0 ELSE ROUND(SUM(gmv)*1.0/SUM(orders),2) END AS avg_aov
        FROM {SCHEMA_PL}.dm_sales_monthly_category
        WHERE year_month >= '{ym_start}' AND year_month < '{ym_end_excl}'
        LIMIT 1
        """
        df_summary = run_sql(sql_summary, SCHEMA_PL)
        
        if not df_summary.empty:
            total_gmv = float(df_summary.iloc[0]['total_gmv'])
            total_orders = int(df_summary.iloc[0]['total_orders'])
            total_units = int(df_summary.iloc[0]['total_units'])
            avg_aov = float(df_summary.iloc[0]['avg_aov'])
        else:
            total_gmv = 0
            total_orders = 0
            total_units = 0
            avg_aov = 0
    except:
        total_gmv = 0
        total_orders = 0
        total_units = 0
        avg_aov = 0
    
    # Executive Summary
    st.markdown("---")
    st.markdown("## üìà K·∫øt lu·∫≠n t·ªïng quan (Executive Summary)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        ### Quy m√¥ & hi·ªáu qu·∫£
        
        * To√†n k·ª≥ hi·ªÉn th·ªã: **GMV ‚âà {total_gmv/1e6:.2f}M BRL**, **{total_orders:,} orders**, **{total_units:,} units**, **AOV ‚âà {avg_aov:.2f} BRL**.
        * **ƒê·ªânh m√πa v·ª• r∆°i v√†o cu·ªëi nƒÉm (Nov-2017)**; n·ª≠a ƒë·∫ßu nƒÉm tƒÉng ƒë·ªÅu, c√≥ dao ƒë·ªông nh·∫π gi·ªØa May‚ÄìJul. 
          ƒê√¢y l√† m√¥ h√¨nh tƒÉng tr∆∞·ªüng t·ª± nhi√™n c·ªßa TMƒêT (sale cu·ªëi nƒÉm k√©o AOV l√™n).
        
        ### ƒê·ªông l·ª±c tƒÉng tr∆∞·ªüng
        
        * Doanh thu t·∫≠p trung ·ªü m·ªôt s·ªë **category "h·∫°t nh√¢n"** (bi·ªÉu ƒë·ªì Pareto): nh√≥m 20% danh m·ª•c ƒë√≥ng g√≥p ~80% GMV. 
          C√°c nh√≥m n·ªïi b·∫≠t: *bed_bath_table*, *watches_gifts*, *health_beauty*, *sports_leisure*, *computers_accessories*‚Ä¶
        
        ### ƒê·ªãa l√Ω
        
        * **SP** d·∫´n ƒë·∫ßu GMV (m·ªôt m√¨nh >2M BRL), theo sau l√† **RJ**, **MG**. 
          ƒê√¢y l√† c√°c v√πng th·ªã tr∆∞·ªùng tr·ªçng ƒëi·ªÉm ƒë·ªÉ t·ªëi ∆∞u t·ªìn kho, v·∫≠n chuy·ªÉn v√† chi·∫øn d·ªãch qu·∫£ng c√°o.
        """)
    
    with col2:
        st.markdown("""
        ### V·∫≠n h√†nh & SLA
        
        * **On-time delivery** trung b√¨nh ~**92‚Äì94%** (tu·ª≥ tab Basis), **delivery days avg** quanh **12‚Äì15 ng√†y**, 
          nh∆∞ng **m·ªôt s·ªë bang c√≥ outlier 20‚Äì30 ng√†y** ‚Üí ƒëi·ªÉm ngh·∫Ωn logistics theo v√πng.
        
        ### Nh√† b√°n (Seller)
        
        * **ƒêi·ªÉm review TB ‚âà 4.09**; **cancel rate r·∫•t th·∫•p (~0.01%)**; ƒëa ph·∫ßn nh√† b√°n c√≥ **on-time 0.90‚Äì0.96**. 
          M·ªôt s·ªë outlier review th·∫•p/on-time th·∫•p c·∫ßn gi√°m s√°t.
        
        ### Thanh to√°n
        
        * **credit_card** chi·∫øm t·ª∑ tr·ªçng cao v√† **tƒÉng m·∫°nh d·ªãp cu·ªëi nƒÉm**; **installments ~3.4‚Äì4.1** cho th·∫•y 
          h√†nh vi tr·∫£ g√≥p hi·ªán di·ªán ƒë√°ng k·ªÉ (·∫£nh h∆∞·ªüng chi ph√≠ t√†i ch√≠nh/thu h·ªìi ti·ªÅn).
        
        ### Data Quality
        
        * B·ªô ki·ªÉm th·ª≠ DQ **pass ~96‚Äì100%** ·ªü c√°c suite demo ‚Üí d·ªØ li·ªáu ƒë·ªß tin c·∫≠y ƒë·ªÉ ra quy·∫øt ƒë·ªãnh; 
          v·∫´n c·∫ßn theo d√µi ƒë·ªãnh k·ª≥ ƒë·ªÉ ph√°t hi·ªán drift/sai l·ªách.
        """)
    
    st.markdown("---")
    st.markdown("## üìã K·∫øt lu·∫≠n theo t·ª´ng dashboard")
    
    # Dashboard-specific conclusions
    st.markdown("""
    ### 1) Executive Overview
    
    * **Doanh thu tƒÉng theo m√πa v·ª•**, ƒë·ªânh cu·ªëi nƒÉm; **AOV tƒÉng nh·∫π** th·ªùi ƒëi·ªÉm peak ‚Üí b√°n nhi·ªÅu m·∫∑t h√†ng gi√° cao/gi·ªè h√†ng l·ªõn h∆°n.
    * **Top categories** t·∫°o ph·∫ßn l·ªõn GMV; ph√¢n b·ªï ng√¢n s√°ch marketing/t·ªìn kho n√™n **∆∞u ti√™n nh√≥m h·∫°t nh√¢n** ƒë·ªÉ t·ªëi ƒëa ROI.
    
    **Ki·∫øn ngh·ªã:**
    * L·∫≠p **ng√¢n s√°ch Q4** (marketing + fulfillment) s·ªõm; t·∫°o **bundle/upsell** ·ªü nh√≥m category ch·ªß l·ª±c ƒë·ªÉ t·∫≠n d·ª•ng AOV cao.
    
    ---
    
    ### 2) Growth & Revenue
    
    * **MoM** c√≥ bi·∫øn ƒë·ªông theo m√πa (m√†u l·ªánh c·∫£nh b√°o MoM -26.5% l√† do so s√°nh 2 m·ªëc c·ª• th·ªÉ; c·∫ßn ƒë·ªçc k√®m seasonality).
    * **YoY 0%** ·ªü m·ªôt s·ªë th√°ng cu·ªëi do coverage ch∆∞a tr·ªçn v·∫πn nƒÉm tr∆∞·ªõc (logic ƒë√∫ng).
    
    **Ki·∫øn ngh·ªã:**
    * Chu·∫©n h√≥a c·ª≠a s·ªï so s√°nh (ƒë·ªß 12 th√°ng), b·ªï sung **moving average** 3M ƒë·ªÉ m∆∞·ª£t xu h∆∞·ªõng.
    * Ch·∫°y **ABC/Pareto theo th√°ng** ƒë·ªÉ ph√°t hi·ªán danh m·ª•c m·ªõi n·ªïi (rising stars) v√† danh m·ª•c suy gi·∫£m.
    
    ---
    
    ### 3) Category & Product Performance
    
    * **Heatmap** th·ªÉ hi·ªán m√πa v·ª• r√µ theo ng√†nh h√†ng; v√≠ d·ª• *gifts/beauty* s√°ng l√™n cu·ªëi nƒÉm.
    * **Top s·∫£n ph·∫©m**: nhi·ªÅu SKU thu·ªôc *computers, bed_bath_table, cool_stuff* chi·∫øm GMV l·ªõn.
    
    **Ki·∫øn ngh·ªã:**
    * ƒê·ªãnh tuy·∫øn **ngu·ªìn h√†ng & t·ªìn kho** cho SKU top (theo bang), gi·ªØ **service level** ·ªïn ƒë·ªãnh tr∆∞·ªõc Q4.
    * V·ªõi danh m·ª•c c√≥ m√πa v·ª•, **ƒë·∫∑t m·ª•c ti√™u GMV theo th√°ng** thay v√¨ tuy·∫øn t√≠nh nƒÉm; d√πng **price test** (A/B) cho SKU ƒë·∫ßu b·∫£ng.
    
    ---
    
    ### 4) Geography & Market Expansion
    
    * **SP, RJ, MG** l√† **core markets**; m·ªôt s·ªë bang **on-time t·ªët nh∆∞ng GMV th·∫•p** ‚Üí d∆∞ ƒë·ªãa m·ªü r·ªông.
    * **Outlier delivery days** ·ªü m·ªôt v√†i bang (RO/AM ‚Ä¶) cho th·∫•y **last-mile d√†i** ho·∫∑c **thi·∫øu ƒë·ªëi t√°c 3PL ph√π h·ª£p**.
    
    **Ki·∫øn ngh·ªã:**
    * Tri·ªÉn khai **SLA playbook theo v√πng**: chu·∫©n tuy·∫øn/ƒë·ªëi t√°c 3PL, SLA cam k·∫øt, v√† **buffer time** theo m√πa.
    * V·ªõi bang GMV th·∫•p/on-time t·ªët ‚Üí ch·∫°y **chi·∫øn d·ªãch ƒë·ªãa ph∆∞∆°ng** (voucher ph√≠ ship, promise "giao nhanh" ƒë·ªÉ k√©o conversion).
    
    ---
    
    ### 5) Seller Performance & Compliance
    
    * Nh√¨n chung **tu√¢n th·ªß t·ªët** (on-time TB ~92%, cancel ~0.01%), **review > 4.0**.
    * C√≥ m·ªôt s·ªë **seller outlier** (review < 3.8 ho·∫∑c on-time < 0.90) v·ªõi **GMV t∆∞∆°ng ƒë·ªëi l·ªõn** ‚Üí r·ªßi ro tr·∫£i nghi·ªám.
    
    **Ki·∫øn ngh·ªã:**
    * Thi·∫øt l·∫≠p **c·∫£nh b√°o t·ª± ƒë·ªông**: `on_time_rate < 92%` HO·∫∂C `avg_review_score < 4.0` v·ªõi GMV > ng∆∞·ª°ng (v√≠ d·ª• 20k).
    * √Åp d·ª•ng **penalty/bonus SLA** & **coaching** cho seller y·∫øu, ∆∞u ti√™n hi·ªÉn th·ªã (search ranking) cho seller t·ªët.
    
    ---
    
    ### 6) Operations / Delivery SLA
    
    * **On-time** ·ªïn ƒë·ªãnh quanh **94%** ·ªü tab Basis=Delivery; **delivery days** th∆∞·ªùng **11‚Äì15 ng√†y**, nh∆∞ng **m·ªôt s·ªë th√°ng tƒÉng** tr√πng th·ªùi gian sale.
    * **Late orders** (n·∫øu b·∫≠t) t·∫≠p trung ·ªü bang c√≥ tuy·∫øn xa.
    
    **Ki·∫øn ngh·ªã:**
    * Tr∆∞·ªõc m√πa cao ƒëi·ªÉm, **n√¢ng nƒÉng l·ª±c fulfillment** (cut-off time, line-haul) t·∫°i c√°c hub tr·ªçng ƒëi·ªÉm; ƒë√°nh gi√° **SLA theo partner**.
    * C√¥ng b·ªë **delivery promise theo bang** (kh√¥ng one-size-fits-all) ƒë·ªÉ qu·∫£n k·ª≥ v·ªçng kh√°ch.
    
    ---
    
    ### 7) Customer / Cohort & Retention
    
    * **Tr·∫°ng th√°i hi·ªán t·∫°i**: Heatmap ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªÉ hi·ªÉn th·ªã retention ƒë√∫ng; **retention(k)** gi·∫£m d·∫ßn theo th√°ng.
    * D√πng th√™m ph√¢n r√£ **Returning vs New** ƒë·ªÉ b√≥c t√°ch ƒë·ªông l·ª±c GMV.
    
    **Ki·∫øn ngh·ªã:**
    * ƒê·∫∑t **OKR retention** cho k=1,3,6; ch·∫°y **remarketing** cho cohort suy gi·∫£m m·∫°nh; √°p d·ª•ng **ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m** theo category l·∫ßn mua ƒë·∫ßu.
    
    ---
    
    ### 8) Finance & Payment Mix
    
    * **credit_card** chi·∫øm t·ª∑ tr·ªçng cao & **tƒÉng m·∫°nh cu·ªëi nƒÉm**; **avg installments ~3.4‚Äì4.1** ‚Üí kh√°ch s·∫µn s√†ng tr·∫£ g√≥p ng·∫Øn.
    * **boleto/voucher** duy tr√¨ t·ª∑ tr·ªçng nh·ªè, c√≥ dao ƒë·ªông theo chi·∫øn d·ªãch.
    
    **Ki·∫øn ngh·ªã:**
    * ƒê√†m ph√°n **ph√≠ MDR** & **k·ª≥ h·∫°n thu ti·ªÅn** v·ªõi PSP do volume credit_card cao; ki·ªÉm so√°t **r·ªßi ro n·ª£** v·ªõi k·ª≥ h·∫°n tr·∫£ g√≥p.
    * A/B **∆∞u ƒë√£i installments** ·ªü ng√†nh h√†ng gi√° cao (computers/furniture) ƒë·ªÉ t·ªëi ∆∞u conversion m√† kh√¥ng ƒë·ªôi chi ph√≠ qu√° m·ª©c.
    
    ---
    
    ### 9) Data Quality & Reliability
    
    * **Pass rate cao (‚âà96‚Äì100%)** cho th·∫•y pipeline ·ªïn ƒë·ªãnh.
    * R·ªßi ro ch√≠nh: **schema drift** ho·∫∑c **dirty data** t·ª´ raw.
    
    **Ki·∫øn ngh·ªã:**
    * N√¢ng c·∫•p DQ t·ª´ "demo" ‚Üí **rules c·ª• th·ªÉ**: `row_count delta`, `domain check (review in 1..5)`, **referential integrity** (FK fact ‚Üí dim), **freshness** (max lag gi·ªù/ng√†y).
    * Hi·ªÉn th·ªã **DQ badge** tr√™n m·ªói tab (Green/Amber/Red) cho l√£nh ƒë·∫°o.
    """)
    
    st.markdown("---")
    st.markdown("## üéØ ∆Øu ti√™n h√†nh ƒë·ªông (90 ng√†y)")
    
    st.markdown("""
    1. **SLA theo v√πng tr∆∞·ªõc Q4**
       * Chu·∫©n h√≥a ƒë·ªëi t√°c 3PL, tuy·∫øn, v√† **delivery promise** theo bang; gi·∫£m outlier >20 ng√†y.
    
    2. **T·∫≠p trung danh m·ª•c h·∫°t nh√¢n**
       * K·∫ø ho·∫°ch t·ªìn kho + chi·∫øn d·ªãch cho Top-Pareto category; A/B pricing/upsell.
    
    3. **Gi√°m s√°t seller outlier**
       * Thi·∫øt l·∫≠p c·∫£nh b√°o & c∆° ch·∫ø th∆∞·ªüng/ph·∫°t SLA; x·∫øp h·∫°ng hi·ªÉn th·ªã theo hi·ªáu su·∫•t.
    
    4. **Ho√†n thi·ªán Cohort/Retention**
       * S·ª≠a truy v·∫•n; ƒë·∫∑t m·ª•c ti√™u **k=1, k=3, k=6**; g·∫Øn chi·∫øn d·ªãch gi·ªØ ch√¢n (email/app push).
    
    5. **T·ªëi ∆∞u payment mix**
       * ƒê√†m ph√°n ph√≠ + qu·∫£n tr·ªã installments; theo d√µi r·ªßi ro chargeback/ch·∫≠m thanh to√°n.
    
    6. **N√¢ng chu·∫©n Data Quality**
       * Chuy·ªÉn c√°c DQ check t·ª´ demo sang **rule v·∫≠n h√†nh**, log & alert trong Dagster.
    """)
    
    st.markdown("---")
    st.markdown("## ‚ö†Ô∏è R·ªßi ro & ƒëi·ªÉm c·∫ßn theo d√µi")
    
    st.markdown("""
    * **Seasonality**: kh√¥ng so s√°nh th√¥ MoM ·ªü th·ªùi ƒëi·ªÉm sale; lu√¥n ƒë·ªëi chi·∫øu **YoY** ho·∫∑c **MA 3M**.
    * **Coverage th·ªùi gian**: m·ªôt s·ªë tab c√≥ YoY=0% khi thi·∫øu d·ªØ li·ªáu nƒÉm tr∆∞·ªõc; c·∫ßn note r√µ c·ª≠a s·ªï d·ªØ li·ªáu.
    * **Delivery outliers**: v√†i bang c√≥ **delivery days** cao b·∫•t th∆∞·ªùng ‚Üí c·∫ßn kh·∫Øc ph·ª•c ƒë·ªÉ tr√°nh **ƒëi·ªÉm review gi·∫£m**.
    * **Cohort**: ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªÉ hi·ªÉn th·ªã retention ƒë√∫ng; c·∫ßn theo d√µi ƒë·ªãnh k·ª≥ ƒë·ªÉ c·∫≠p nh·∫≠t **ch·ªâ s·ªë retention** v√†o Executive.
    """)
    
    st.markdown("---")
    st.markdown("## üìä T√°c ƒë·ªông k·ª≥ v·ªçng (n·∫øu tri·ªÉn khai ki·∫øn ngh·ªã)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        * **GMV**: tƒÉng 5‚Äì10% nh·ªù t·∫≠p trung category h·∫°t nh√¢n + conversion t·ª´ delivery promise r√µ r√†ng.
        * **SLA**: gi·∫£m 10‚Äì20% s·ªë bang outlier >20 ng√†y; **on-time** tƒÉng 1‚Äì2 ƒëi·ªÉm %.
        * **AOV**: tƒÉng 2‚Äì4% nh·ªù bundle/upsell.
        """)
    
    with col2:
        st.markdown("""
        * **LTV/Retention**: c·∫£i thi·ªán 2‚Äì3 ƒëi·ªÉm % ·ªü k=3 nh·ªù remarketing ƒë√∫ng l√∫c.
        * **Chi ph√≠ t√†i ch√≠nh**: t·ªëi ∆∞u 0.1‚Äì0.3 ƒëi·ªÉm % MDR nh·ªù leverage volume credit_card.
        """)

# Footer
st.markdown("---")
st.caption(f"¬© Executive Analytics Suite ‚Ä¢ Coverage: {COVER_MIN} ‚Üí {COVER_MAX}")

2025-10-23 17:24:47 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - LOGS_CAPTURED - Started capturing logs in process (pid: 13390).
2025-10-23 17:24:47 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_START - Started execution of step "platinum__dmcustomerlifecycle__dm_customer_lifecycle".
/usr/local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
Warning: Ignoring non-Spark config property: hive.metastore.uris
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-10-23 17:24:52 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - (SparkIOManager) Loading table: gold.dim_customer from s3a://lakehouse/gold/dim_customer
[Stage 0:>                                                          (0 + 0) / 1][Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1][Stage 3:>                                                         (0 + 8) / 50][Stage 3:=========>                                                (8 + 8) / 50][Stage 3:==================>                                      (16 + 8) / 50][Stage 3:====================>                                    (18 + 8) / 50][Stage 3:==============================>                          (27 + 8) / 50][Stage 3:==========================================>              (37 + 8) / 50]                                                                                2025-10-23 17:25:35 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - Successfully loaded 99441 rows from s3a://lakehouse/gold/dim_customer
2025-10-23 17:25:35 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - LOADED_INPUT - Loaded input "dim_customer" using input manager "spark_io_manager"
2025-10-23 17:25:35 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - (SparkIOManager) Loading table: gold.dim_date from s3a://lakehouse/gold/dim_date
[Stage 10:====================================>                   (33 + 8) / 50]                                                                                2025-10-23 17:25:36 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - Successfully loaded 634 rows from s3a://lakehouse/gold/dim_date
2025-10-23 17:25:36 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - LOADED_INPUT - Loaded input "dim_date" using input manager "spark_io_manager"
2025-10-23 17:25:36 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - (SparkIOManager) Loading table: gold.fact_order_item from s3a://lakehouse/gold/fact_order_item
[Stage 17:=================================>                      (30 + 8) / 50][Stage 17:================================================>       (43 + 7) / 50]                                                                                2025-10-23 17:25:38 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - Successfully loaded 112650 rows from s3a://lakehouse/gold/fact_order_item
2025-10-23 17:25:38 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - LOADED_INPUT - Loaded input "fact_order_item" using input manager "spark_io_manager"
2025-10-23 17:25:38 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_INPUT - Got input "dim_customer" of type "Any". (Type check passed).
2025-10-23 17:25:38 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_INPUT - Got input "dim_date" of type "Any". (Type check passed).
2025-10-23 17:25:38 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_INPUT - Got input "fact_order_item" of type "Any". (Type check passed).
[Stage 22:===================================>                    (32 + 8) / 50]                                                                                [Stage 34:>   (0 + 8) / 8][Stage 35:>   (0 + 0) / 1][Stage 36:>   (0 + 0) / 8][Stage 35:>                 (0 + 1) / 1][Stage 36:>                 (0 + 7) / 8]                                                                                2025-10-23 17:25:43 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - dm_customer_lifecycle rows=96462 cols=6
2025-10-23 17:25:43 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_OUTPUT - Yielded output "result" of type "Any". (Type check passed).
2025-10-23 17:25:43 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - (SparkIOManager) Saving table: platinum.dm_customer_lifecycle -> s3a://lakehouse/platinum/dm_customer_lifecycle
[Stage 75:>                                                         (0 + 8) / 8][Stage 75:==================================================>       (7 + 1) / 8][Stage 77:>                                                         (0 + 4) / 4]                                                                                [Stage 89:>                                                         (0 + 7) / 7]                                                                                [Stage 93:====================================>                   (33 + 8) / 50]                                                                                2025-10-23 17:25:53 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - Successfully wrote 96462 rows to s3a://lakehouse/platinum/dm_customer_lifecycle
2025-10-23 17:25:54 +0000 - dagster - INFO - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - Successfully registered platinum.dm_customer_lifecycle in Hive Metastore with s3:// location
2025-10-23 17:25:54 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - ASSET_MATERIALIZATION - Materialized value platinum dmcustomerlifecycle dm_customer_lifecycle.
2025-10-23 17:25:54 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - HANDLED_OUTPUT - Handled output "result" using IO manager "spark_io_manager"
2025-10-23 17:25:54 +0000 - dagster - DEBUG - __ASSET_JOB - 0cfe6302-aef4-415b-9477-2e5b000f81f2 - 13390 - platinum__dmcustomerlifecycle__dm_customer_lifecycle - STEP_SUCCESS - Finished execution of step "platinum__dmcustomerlifecycle__dm_customer_lifecycle" in 1m7s.

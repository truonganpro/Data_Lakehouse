# THÃ”NG TIN BÃO CÃO CHÆ¯Æ NG 4 - DATA LAKEHOUSE PROJECT
# MÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u & Pipeline Medallion

================================================================================
ğŸ“Œ 4.1. Táº¦NG BRONZE â†’ SILVER: CHUáº¨N HÃ“A & LIÃŠN Káº¾T
================================================================================

FILES: 
   - etl_pipeline/etl_pipeline/assets/bronze.py
   - etl_pipeline/etl_pipeline/assets/silver.py

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š BRONZE LAYER (Raw Data Ingestion):

Purpose: Load raw data tá»« MySQL khÃ´ng cÃ³ transformation
Implementation: JDBC connector vá»›i Spark SQL

Assets (9 tables):
   1. bronze_customer: Load tá»« MySQL.customers
   2. bronze_seller: Load tá»« MySQL.sellers
   3. bronze_product: Load tá»« MySQL.products
   4. bronze_order: Load tá»« MySQL.orders
   5. bronze_order_item: Load tá»« MySQL.order_items
   6. bronze_payment: Load tá»« MySQL.order_payments
   7. bronze_order_review: Load tá»« MySQL.order_reviews
   8. bronze_geolocation: Load tá»« MySQL.geolocation
   9. bronze_product_category: Load tá»« MySQL.product_category_name_translation

JDBC Configuration:
   â€¢ URL: jdbc:mysql://de_mysql:3306/brazillian_ecommerce
   â€¢ Driver: com.mysql.cj.jdbc.Driver
   â€¢ Options: zeroDateTimeBehavior=CONVERT_TO_NULL, UTC timezone
   â€¢ No transformations, no validations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ SILVER LAYER (Cleaned & Normalized):

Purpose: Chuáº©n hÃ³a, cleaning, type casting, deduplication
Output: Clean data ready cho Star Schema

Transformations Applied:

1. SILVER_CUSTOMER:
   â€¢ dropDuplicates(["customer_id"])
   â€¢ filter(customer_id IS NOT NULL)
   â†’ Loáº¡i bá»: duplicate, NULL customer_id

2. SILVER_SELLER:
   â€¢ dropDuplicates(["seller_id"])
   â€¢ na.fill("")
   â†’ Loáº¡i bá»: duplicate
   â†’ Äiá»n: NULL â†’ empty string

3. SILVER_PRODUCT:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â€¢ Rename: "product_name_lenght" â†’ "product_name_length"
   â€¢ Rename: "product_description_lenght" â†’ "product_description_length"
   â€¢ Cast: product_length_cm, height_cm, width_cm â†’ INT
   â†’ Loáº¡i bá»: duplicate, NULL
   â†’ Fix typo tá»« Olist dataset
   â†’ Chuáº©n hÃ³a data types

4. SILVER_ORDER:
   â€¢ dropDuplicates(["order_id"])
   â€¢ na.drop()
   â€¢ Cast: order_purchase_timestamp â†’ TIMESTAMP
   â†’ Loáº¡i bá»: duplicate, NULL
   â†’ Chuáº©n hÃ³a timestamps

5. SILVER_ORDER_ITEM:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â€¢ Round: price, freight_value â†’ 2 decimals
   â€¢ Cast: price, freight_value â†’ DOUBLE
   â†’ Loáº¡i bá»: duplicate, NULL
   â†’ Chuáº©n hÃ³a numeric precision

6. SILVER_PAYMENT:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â€¢ Round: payment_value â†’ 2 decimals
   â€¢ Cast: payment_value â†’ DOUBLE, payment_installments â†’ INT
   â†’ Loáº¡i bá»: duplicate, NULL

7. SILVER_ORDER_REVIEW:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â€¢ drop("review_comment_title")
   â†’ Loáº¡i bá»: duplicate, NULL, cá»™t khÃ´ng cáº§n

8. SILVER_PRODUCT_CATEGORY:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â†’ Loáº¡i bá»: duplicate, NULL

9. SILVER_GEOæ˜¯å…¨å›½:
   â€¢ dropDuplicates()
   â€¢ na.drop()
   â€¢ Filter: Latitude [5.27438888, -33.75116944], Longitude [-73.98283055, -34.79314722]
   â†’ Loáº¡i bá»: duplicate, NULL, outliers ngoÃ i Brazil

10. SILVER_DATE (Generated):
    â€¢ Extract tá»« order_purchase_timestamp
    â€¢ full_date, year, month, day, weekday
    â€¢ dropDuplicates(["full_date"])
    â†’ Date dimension Ä‘á»ƒ join vá»›i facts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ FILES LIÃŠN QUAN:
   - etl_pipeline/etl_pipeline/assets/bronze.py: Bronze assets
   - etl_pipeline/etl_pipeline/assets/silver.py: Silver transformations
   - etl_pipeline/etl_pipeline/resources/spark_io_manager.py: Spark IO


================================================================================
ğŸ“Œ 4.2. Táº¦NG GOLD: STAR SCHEMA
================================================================================

FILE: etl_pipeline/etl_pipeline/assets/gold.py

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.2.1. DIMENSIONS (6 Dimensions):

1. DIM_CUSTOMER:
   Attributes:
      - customer_id (PK)
      - customer_unique_id
      - customer_zip_code_prefix
      - customer_city
      - customer_state
      - city_state (computed: city, state)
   
   Transformation:
      â€¢ dropDuplicates(["customer_id"])
      â€¢ concat_ws(", ", city, state) â†’ city_state
   
   Grain: 1 row per customer

2. DIM_SELLER:
   Attributes:
      - seller_id (PK)
      - seller_zip_code_prefix
      - seller_city
      - seller_state
      - city_state (computed: city, state)
   
   Transformation:
      â€¢ dropDuplicates(["seller_id"])
      â€¢ concat_ws(", ", city, state) â†’ city_state
   
   Grain: 1 row per seller

3. DIM_PRODUCT:
   Attributes:
      - product_id (PK)
      - product_category_name
      - product_name_length
      - product_description_length
      - product_photos_qty
      - product_weight_g
      - product_length_cm
      - product_height_cm
      - product_width_cm
   
   Transformation:
      â€¢ dropDuplicates(["product_id"])
      â€¢ Inherit tá»« silver_product (Ä‘Ã£ cleaned)
   
   Grain: 1 row per product

4. DIM_PRODUCT_CATEGORY:
   Attributes:
      - product_category_name (PK)
      - product_category_name_english
   
   Transformation:
      â€¢ dropDuplicates(["product_category_name"])
      â€¢ Portuguese â†’ English mapping
   
   Grain: 1 row per category

5. DIM_DATE:
   Attributes:
      - full_date (PK)
      - year
      - month
      - day
      - weekday
      - year_month (computed: yyyy-MM)
      - quarter
      - week_of_year
   
   Transformation:
      â€¢ dropDuplicates(["full_date"])
      â€¢ Extract: year, month, day, quarter, weekofyear
      â€¢ Format: year_month = "yyyy-MM"
   
   Grain: 1 row per date

6. DIM_GEOå…¨å›½:
   Attributes:
      - geolocation_zip_code_prefix (PK)
      - geolocation_lat
      - geolocation_lng
      - geolocation_city
      - geolocation_state
      - city_state (computed: city, state)
   
   Transformation:
      â€¢ dropDuplicates(["geolocation_zip_code_prefix"])
      â€¢ concat_ws(", ", city, state) â†’ city_state
   
   Grain: 1 row per zip code

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.2.2. FACTS (4 Fact Tables):

1. FACT_ORDER_ITEM:
   Grain: 1 row per order_id + order_item_id
   
   Dependencies: silver_order, silver_order_item
   
   Attributes:
      - order_id (FK)
      - order_item_id
      - product_id (FK)
      - seller_id (FK)
      - customer_id (FK)
      - full_date (FK)
      - price
      - freight_value
      - shipping_limit_date
      - order_status
   
   Transformations:
      â€¢ JOIN silver_order vá»›i silver_order_item
      â€¢ Extract full_date tá»« order_purchase_timestamp
   
   Measures (Analytics):
      â€¢ price: Item price
      â€¢ freight_value: Shipping cost
      â€¢ SUM(price): GMV
      â€¢ COUNT(order_item_id): Units sold
      â€¢ COUNT(DISTINCT order_id): Orders
      â€¢ AVG(price): Average item price

2. FACT_ORDER:
   Grain: 1 row per order_id
   
   Dependencies: silver_order, silver_payment, fact_order_item
   
   Attributes:
      - order_id (PK)
      - customer_id (FK)
      - full_date (FK)
      - items_count
      - sum_price
      - sum_freight
      - payment_total
      - payment_installments_max
      - primary_payment_type
      - delivered_days
      - delivered_on_time (computed)
      - is_canceled (computed)
   
   Transformations:
      â€¢ Aggregate: fact_order_item â†’ items_count, sum_price, sum_freight
      â€¢ Aggregate: silver_payment â†’ payment_total, max_installments, primary_type
      â€¢ Compute: delivered_days = datediff(delivery, purchase)
      â€¢ Compute: delivered_on_time = delivery <= estimated
      â€¢ Compute: is_canceled = status == "canceled"
   
   Measures (Analytics):
      â€¢ SUM(sum_price): Total GMV
      â€¢ AVG(items_count): Average items per order
      â€¢ AVG(delivered_days): Average delivery time
      â€¢ AVG(delivered_on_time): On-time delivery rate
      â€¢ AVG(is_canceled): Cancel rate
      â€¢ COUNT(DISTINCT customer_id): Unique customers
      â€¢ COUNT(*): Total orders

3. FACT_PAYMENT:
   Grain: 1 row per order_id + payment_sequential
   
   Dependencies: silver_payment
   
   Attributes:
      - order_id (FK)
      - payment_sequential
      - payment_type
      - payment_installments
      - payment_value
   
   Transformation: Direct select tá»« silver_payment
   
   Measures (Analytics):
      â€¢ SUM(payment_value): Total payment
      â€¢ AVG(payment_installments): Average installments
      â€¢ COUNT(*) GROUP BY payment_type: Payment mix

4. FACT_REVIEW:
   Grain: 1 row per review_id
   
   Dependencies: silver_order_review
   
   Attributes:
      - review_id (PK)
      - order_id (FK)
      - review_score
      - review_creation_date
      - review_answer_timestamp
   
   Transformation: Direct select tá»« silver_order_review
   
   Measures (Analytics):
      â€¢ AVG(review_score): Average rating
      â€¢ COUNT(*) GROUP BY review_score: Rating distribution
      â€¢ COUNT(*): Total reviews

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ FILES LIÃŠN QUAN:
   - etl_pipeline/etl_pipeline/assets/gold.py: Star schema implementation


================================================================================
ğŸ“Œ 4.3. Táº¦NG PLATINUM: DATAMARTS
================================================================================

FILE: etl_pipeline/etl_pipeline/assets/platinum.py

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.3.1. DM_SALES_MONTHLY_CATEGORY:

Purpose: Monthly sales aggregation by product category

Dependencies: fact_order_item, dim_product, dim_product_category, dim_date

Grain: 1 row per year_month + product_category_name_english

Transformations:
   â€¢ JOIN fact_order_item â†’ dim_product (product_id)
   â€¢ JOIN dim_product â†’ dim_product_category (category_name)
   â€¢ JOIN fact_order_item â†’ dim_date (full_date)
   â€¢ GROUP BY year_month, product_category_name_english
   â€¢ Aggregate measures

Measures:
   â€¢ GMV: SUM(price)
   â€¢ Orders: COUNT(DISTINCT order_id)
   â€¢ Units: COUNT(*)
   â€¢ AOV: GMV / Orders

Use Cases:
   â€¢ Sales trend analysis
   â€¢ Category performance ranking
   â€¢ Monthly revenue tracking

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.3.2. DM_SELLER_KPI:

Purpose: Comprehensive seller performance metrics

Dependencies: fact_order_item, fact_order, fact_review, dim_seller

Grain: 1 row per seller_id

Transformations:
   1. Seller Orders:
      â€¢ GROUP BY seller_id
      â€¢ SUM(price) â†’ gmv
      â€¢ COUNT(DISTINCT order_id) â†’ orders
      â€¢ COUNT(*) â†’ units
   
   2. Seller Reviews:
      â€¢ JOIN fact_review â†’ fact_order_item (order_id)
      â€¢ GROUP BY seller_id
      â€¢ AVG(review_score) â†’ avg_review_score
   
   3. Seller Delivery:
      â€¢ JOIN fact_order â†’ fact_order_item (order_id)
      â€¢ GROUP BY seller_id
      â€¢ AVG(delivered_on_time) â†’ on_time_rate
      â€¢ AVG(is_canceled) â†’ cancel_rate
   
   4. Final JOIN:
      â€¢ dim_seller LEFT JOIN all metrics
      â€¢ ORDER BY gmv DESC

Measures:
   â€¢ GMV: Total sales value
   â€¢ Orders: Order count
   â€¢ Units: Item count
   â€¢ avg_review_score: Customer satisfaction
   â€¢ on_time_rate: Delivery performance
   â€¢ cancel_rate: Order cancellation rate

Use Cases:
   â€¢ Seller ranking & benchmarking
   â€¢ Commission calculation
   â€¢ Quality control
   â€¢ Performance improvement

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.3.3. DM_CUSTOMER_COHORT (dm_customer_lifecycle):

Purpose: Customer lifecycle analysis vá»›i cohort retention

Dependencies: fact_order_item, dim_customer, dim_date

Grain: 1 row per customer_id + year_month

Transformations:
   1. First Purchase:
      â€¢ GROUP BY customer_id
      â€¢ MIN(full_date) â†’ first_purchase_date
      â€¢ Format: first_purchase_month = "yyyy-MM"
   
   2. Monthly Activity:
      â€¢ JOIN fact_order_item â†’ dim_date (full_date)
      â€¢ GROUP BY customer_id, year_month
      â€¢ COUNT(DISTINCT order_id) â†’ orders
      â€¢ SUM(price) â†’ gmv
   
   3. Final:
      â€¢ JOIN monthly_activity â†’ first_purchase (customer_id)
      â€¢ JOIN dim_customer (customer_id)
      â€¢ cohort_month = first_purchase_month

Attributes:
   â€¢ customer_id
   â€¢ customer_unique_id
   â€¢ year_month
   â€¢ cohort_month
   â€¢ orders
   â€¢ gmv

Use Cases:
   â€¢ Cohort retention analysis
   â€¢ Customer LTV calculation
   â€¢ Churn prediction
   â€¢ Segmentation

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š 4.3.4. DM_PAYMENT_MIX:

Purpose: Payment method distribution over time

Dependencies: fact_payment, fact_order, dim_date

Grain: 1 row per year_month + payment_type

Transformations:
   â€¢ JOIN fact_payment â†’ fact_order (order_id)
   â€¢ JOIN fact_order â†’ dim_date (full_date)
   â€¢ GROUP BY year_month, payment_type
   â€¢ Aggregate measures

Measures:
   â€¢ Orders: COUNT(DISTINCT order_id)
   â€¢ Unique Customers: COUNT(DISTINCT customer_id)
   â€¢ Payment Total: SUM(payment_value)

Use Cases:
   â€¢ Payment trends
   â€¢ Method popularity analysis
   â€¢ Financial planning

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ADDITIONAL PLATINUM DATAMARTS:

4. DM_LOGISTICS_SLA:
   Purpose: Delivery performance by region
   Dependencies: fact_order, dim_customer, dim_geolocation, dim_date
   Grain: year_month + geolocation_state
   Measures: avg_delivered_days, on_time_rate, late_orders

5. DM_PRODUCT_BESTSELLERS:
   Purpose: Product ranking within categories
   Dependencies: fact_order_item, fact_review, dim_product, dim_product_category
   Grain: product_id + product_category_name_english
   Measures: gmv, units, orders, avg_review_score, rank_in_category

6. DM_CATEGORY_PRICE_BANDS:
   Purpose: Sales distribution across price ranges
   Dependencies: fact_order_item, dim_product, dim_product_category
   Grain: product_category_name_english + price_band
   Measures: order_items, orders, total_gmv, avg_price

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ FILES LIÃŠN QUAN:
   - etl_pipeline/etl_pipeline/assets/platinum.py: Datamarts implementation


================================================================================
ğŸ“Œ 4.4. ORCHESTRATION Vá»šI DAGSTER: ASSETS, JOBS, SCHEDULES, LINEAGE, RETRIES
================================================================================

FILES:
   - etl_pipeline/etl_pipeline/__init__.py
   - etl_pipeline/etl_pipeline/job/__init__.py
   - etl_pipeline/etl_pipeline/schedule/__init__.py
   - etl_pipeline/etl_pipeline/resources/spark_io_manager.py

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ ASSETS (36 Total):

Layer Distribution:
   â€¢ Bronze: 9 assets (raw data)
   â€¢ Silver: 10 assets (cleaned data)
   â€¢ Gold: 10 assets (star schema)
   â€¢ Platinum: 7 assets (datamarts)

Asset Properties:
   â€¢ key_prefix: [layer, table] (e.g., ["bronze", "customer"])
   â€¢ group_name: Layer name for organization
   â€¢ compute_kind: "SparkSQL" (for lineage)
   â€¢ io_manager_key: "spark_io_manager"
   â€¢ ins: Asset dependencies (AssetIn)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”„ JOBS (2 Jobs):

1. RELOAD_DATA:
   Selection: bronze_selection (9 assets)
   Purpose: Load raw data tá»« MySQL â†’ Bronze
   Use: Initial load, refresh raw data
   
2. FULL_PIPELINE_JOB:
   Selection: AssetSelection.all() (36 assets)
   Purpose: Complete ETL pipeline (Bronze â†’ Silver â†’ Gold â†’ Platinum)
   Use: Full transform from source to datamarts

Job Configuration:
   â€¢ Automatic dependency resolution
   â€¢ Parallel execution where possible
   â€¢ Sequential execution when dependencies exist

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â° SCHEDULES (1 Schedule + optional):

1. RELOAD_DATA_SCHEDULE:
   Job: reload_data
   Cron: "0 0 * * *" (Daily at 00:00)
   Timezone: Asia/Ho_Chi_Minh
   Purpose: Fresh data load every day

2. DAILY_FORECAST_SCHEDULE (optional):
   Job: forecast_job (if ML enabled)
   Cron: "0 3 * * *" (Daily at 03:00)
   Purpose: Generate daily forecasts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”— LINEAGE TRACKING:

Dagster automatically tracks:
   â€¢ Asset dependencies (ins parameter)
   â€¢ Data flow direction (upstream â†’ downstream)
   â€¢ Compute kind (SparkSQL)
   â€¢ Asset groups (Bronze, Silver, Gold, Platinum)

Visual Lineage (Dagster UI):
   â€¢ Graph view: Asset relationships
   â€¢ Layer view: Medallion architecture
   â€¢ Execution view: Job runs
   â€¢ Materialization history

Example Lineage:
   MySQL.customers
      â†“
   bronze.customer
      â†“
   silver.customer
      â†“
   gold.dimcustomer
      â†“
   platinum.dmsellerkpi, platinum.dmcustomerlifecycle

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”„ RETRY & ERROR HANDLING:

Configuration (dagster.yaml):
   â€¢ max_concurrent_runs: 3
   â€¢ max_catchup_runs: 5
   â€¢ QueuedRunCoordinator

SparkIOManager Retries:
   â€¢ JAR validation before Spark session creation
   â€¢ Fallback table registration if primary fails
   â€¢ Comprehensive error logging
   â€¢ Metadata output on success

Dagster Built-in Features:
   â€¢ Automatic retries on failure
   â€¢ Partial re-execution (re-run only failed assets)
   â€¢ Skip downstream on upstream failure
   â€¢ Manual re-run via UI

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ FILES LIÃŠN QUAN:
   - etl_pipeline/etl_pipeline/__init__.py: Assets, jobs, schedules
   - etl_pipeline/etl_pipeline/job/__init__.py: Job definitions
   - etl_pipeline/etl_pipeline/schedule/__init__.py: Schedule definitions
   - dagster_home/dagster.yaml: Dagster configuration


================================================================================
ğŸ“Œ 4.5. Tá»I Æ¯U & KIá»‚M THá»¬ CHáº¤T LÆ¯á»¢NG Dá»® LIá»†U (PARTITIONING, CHECKS)
================================================================================

FILES:
   - etl_pipeline/etl_pipeline/resources/spark_io_manager.py
   - etl_pipeline/etl_pipeline/assets/silver.py (quality checks)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ DELTA LAKE WRITE OPTIMIZATION:

SparkIOManager Implementation:
   1. Physical Write (s3a://):
      â€¢ obj.write.format("delta")
      â€¢ .mode("overwrite")
      â€¢ .save(path_s3a)
      â€¢ Optimized Parquet format
   
   2. Metadata Registration (s3://):
      â€¢ CREATE DATABASE IF NOT EXISTS {layer}
      â€¢ DROP TABLE IF EXISTS {layer}.{table}
      â€¢ CREATE TABLE {layer}.{table} USING DELTA LOCATION '{path_s3}'
      â€¢ Trino-compatible catalog

Write Modes:
   â€¢ overwrite: Replace entire table
   â€¢ append: Add new data (for incremental)
   â€¢ Schema evolution: overwriteSchema=true

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š DATA QUALITY CHECKS:

Silver Layer Quality:
   1. Deduplication:
      â€¢ dropDuplicates() on primary keys
      â€¢ Prevents duplicate records
   
   2. NULL Handling:
      â€¢ na.drop(): Remove rows with NULLs
      â€¢ na.fill(""): Replace NULL with empty string
      â€¢ isNotNull(): Filter specific columns
   
   3. Type Casting:
      â€¢ Ensure correct data types
      â€¢ Cast string â†’ INT, DOUBLE, TIMESTAMP
   
   4. Precision Control:
      â€¢ Round(2) for monetary values
      â€¢ Avoid floating point errors
   
   5. Data Validation:
      â€¢ Geographic bounds for geolocation
      â€¢ Timestamp conversion for dates
      â€¢ Column rename for typo fixes

Gold Layer Quality:
   1. Referential Integrity:
      â€¢ JOIN ensures FK relationships
      â€¢ LEFT JOIN prevents data loss
   
   2. Aggregate Validation:
      â€¢ SUM, COUNT, AVG calculations
      â€¢ No NULL in computed fields
   
   3. Business Logic:
      â€¢ delivered_on_time boolean computation
      â€¢ is_canceled flag derivation
      â€¢ Primary payment type selection

Platinum Layer Quality:
   1. Aggregation Accuracy:
      â€¢ GROUP BY correctness
      â€¢ DISTINCT counts
      â€¢ Window functions
   
   2. Measure Calculations:
      â€¢ AOV = GMV / Orders
      â€¢ Rate calculations (avg, sum, count)
      â€¢ Ranking with row_number()

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš¡ PERFORMANCE OPTIMIZATION:

Spark Configuration:
   â€¢ spark.driver.memory: 4g
   â€¢ spark.executor.memory: 4g
   â€¢ spark.executor.cores: 2
   â€¢ spark.default.parallelism: 4

S3/MinIO Optimization:
   â€¢ Connection pool: 50 max
   â€¢ Multipart upload: 100MB threshold
   â€¢ Timeout: 5-10s
   â€¢ Path-style access for MinIO

Delta Lake Features:
   â€¢ ACID transactions
   â€¢ Schema enforcement
   â€¢ Time travel
   â€¢ Delta logs for metadata

Query Optimization:
   â€¢ Trino partition pruning
   â€¢ Delta Lake statistics
   â€¢ Columnar storage (Parquet)
   â€¢ Z-ordering for co-location

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š LOGGING & METADATA:

SparkIOManager Logging:
   â€¢ Asset name logging
   â€¢ Row count after write
   â€¢ Column list metadata
   â€¢ Path information (s3a://, s3://)
   â€¢ Error logging with stack trace

Dagster Metadata:
   â€¢ Execution logs
   â€¢ Asset materialization history
   â€¢ Run duration tracking
   â€¢ Success/failure status
   â€¢ Output metadata (rows, columns)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ FILES LIÃŠN QUAN:
   - etl_pipeline/etl_pipeline/resources/spark_io_manager.py: Write logic
   - docker_image/spark/conf/spark-defaults.conf: Spark optimization
   - etl_pipeline/etl_pipeline/assets/silver.py: Quality checks


================================================================================
ğŸ“Œ 4.6. TIá»‚U Káº¾T CHÆ¯Æ NG
================================================================================

ğŸ“ ÄIá»‚M CHÃNH Cáº¦N TÃ“M Táº®T:

âœ… MEDALLION ARCHITECTURE:
   â€¢ Bronze â†’ Silver â†’ Gold â†’ Platinum (4 layers)
   â€¢ Progressive data refinement
   â€¢ 36 assets total
   â€¢ 10 dimensions + 4 facts + 7 datamarts

âœ… BRONZE â†’ SILVER:
   â€¢ Raw data ingestion tá»« MySQL
   â€¢ Cleaning: deduplication, NULL handling
   â€¢ Type casting, precision control
   â€¢ Geographic filtering, typo fixes

âœ… GOLD STAR SCHEMA:
   â€¢ 6 dimensions: customer, seller, product, category, date, geolocation
   â€¢ 4 facts: order, order_item, payment, review
   â€¢ Proper grain definition
   â€¢ Calculated measures

âœ… PLATINUM DATAMARTS:
   â€¢ 7 business datamarts
   â€¢ Pre-aggregated metrics
   â€¢ Optimized for BI queries
   â€¢ GMV, Orders, AOV, KPIs

âœ… DAGSTER ORCHESTRATION:
   â€¢ 2 jobs: reload_data, full_pipeline_job
   â€¢ 1 schedule: Daily 00:00
   â€¢ Automatic lineage tracking
   â€¢ Retry & error handling

âœ… DATA QUALITY & OPTIMIZATION:
   â€¢ Delta Lake ACID transactions
   â€¢ Spark performance tuning
   â€¢ S3/MinIO optimization
   â€¢ Comprehensive logging

ğŸ¯ Káº¾T QUáº¢:
   Production-ready Medallion pipeline
   â€¢ Automated ETL tá»« source â†’ datamarts
   â€¢ High-quality data vá»›i validation
   â€¢ Scalable architecture vá»›i Dagster
   â€¢ Optimized performance vá»›i Spark

ğŸ“Š THá»NG KÃŠ:
   36 assets Ã— 4 layers
   6 dimensions + 4 facts + 7 datamarts
   2 jobs + 1 schedule
   1 command deployment

================================================================================
ğŸ“ DANH SÃCH FILE Cáº¦N Äá»ŒC Äá»‚ VIáº¾T BÃO CÃO
================================================================================

MUST READ:
   1. etl_pipeline/etl_pipeline/assets/bronze.py (9 assets)
   2. etl_pipeline/etl_pipeline/assets/silver.py (10 assets)
   3. etl_pipeline/etl_pipeline/assets/gold.py (10 assets)
   4. etl_pipeline/etl_pipeline/assets/platinum.py (7 assets)
   5. etl_pipeline/etl_pipeline/__init__.py (Definitions)
   6. etl_pipeline/etl_pipeline/job/__init__.py (Jobs)
   7. etl_pipeline/etl_pipeline/schedule/__init__.py (Schedules)
   8. etl_pipeline/etl_pipeline/resources/spark_io_manager.py (IO)

NICE TO HAVE:
   9. PROJECT_OVERVIEW.md (Architecture overview)
   10. docker_image/spark/conf/spark-defaults.conf (Config)

================================================================================
EOF



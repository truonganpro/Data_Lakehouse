â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CHAT SERVICE - Táº¤T Cáº¢ CÃC FILE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Generated: 2025-11-03

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

app/pages/2_ğŸ’¬_Chat.py

"""
Chat Page - SQL + RAG Chatbot
Interactive chat interface for querying the data lakehouse
"""
import streamlit as st
import requests
import uuid
import pandas as pd
from datetime import datetime


# ============================================================================
# Configuration
# ============================================================================

CHAT_SERVICE_URL = "http://chat_service:8001"

# Enhanced CSS
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');

:root{
  --bg:#0b1220; --bg2:#10192b; --card:#0f172a; --line:#1f2a44;
  --text:#e2e8f0; --muted:#94a3b8; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444; --pri:#22d3ee;
}

html, body, [class*=css] { font-family: 'Inter', sans-serif; }
.main .block-container{max-width:1280px;padding-top:1rem;padding-bottom:3rem}
h1,h2,h3{letter-spacing:.2px}
hr{border-color:var(--line);opacity:.4;margin:1rem 0}

.card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:16px;transition:border-color 0.2s}
.card:hover{border-color:#294166}
.badge{display:inline-flex;gap:6px;align-items:center;padding:4px 10px;border-radius:999px;
  background:rgba(34,211,238,.12);border:1px solid rgba(34,211,238,.25);font-size:12px}
.muted{color:var(--muted)}

.stButton>button{border-radius:14px;padding:.8rem 1.1rem;font-weight:700;font-size:15px}
.section-title{display:flex;align-items:center;gap:10px;margin:1.5rem 0 1rem}
.section-title h3{margin:0}
.section-title:after{content:"";flex:1;height:1px;background:linear-gradient(90deg,transparent, var(--line))}
</style>
""", unsafe_allow_html=True)

# ============================================================================
# Session State
# ============================================================================

if "session_id" not in st.session_state:
    st.session_state.session_id = uuid.uuid4().hex[:16]

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "last_sql" not in st.session_state:
    st.session_state.last_sql = None

if "last_preview" not in st.session_state:
    st.session_state.last_preview = None

if "last_citations" not in st.session_state:
    st.session_state.last_citations = None

if "execution_time" not in st.session_state:
    st.session_state.execution_time = None


# ============================================================================
# Helper Functions
# ============================================================================

def get_example_questions():
    """Get example questions from API"""
    try:
        response = requests.get(f"{CHAT_SERVICE_URL}/examples", timeout=5)
        if response.ok:
            return response.json().get("examples", [])
    except:
        pass
    
    # Fallback examples
    return [
        "Doanh thu theo thÃ¡ng gáº§n Ä‘Ã¢y?",
        "Top 10 sáº£n pháº©m bÃ¡n cháº¡y nháº¥t?",
        "PhÃ¢n bá»‘ Ä‘Æ¡n hÃ ng theo vÃ¹ng miá»n?",
        "PhÆ°Æ¡ng thá»©c thanh toÃ¡n nÃ o phá»• biáº¿n nháº¥t?",
    ]


def send_question(question: str):
    """Send question to chat service"""
    try:
        response = requests.post(
            f"{CHAT_SERVICE_URL}/ask",
            json={
                "session_id": st.session_state.session_id,
                "question": question,
                "prefer_sql": True
            },
            timeout=60
        )
        
        if response.ok:
            return response.json()
        else:
            st.error(f"âŒ Lá»—i API: {response.text}")
            return None
            
    except requests.exceptions.Timeout:
        st.error("â° Timeout: Query took too long to execute")
        return None
    except Exception as e:
        st.error(f"âŒ Lá»—i káº¿t ná»‘i: {str(e)}")
        return None


# ============================================================================
# UI
# ============================================================================

st.title("ğŸ’¬ Chat vá»›i Dá»¯ liá»‡u")
st.caption("Há»i Ä‘Ã¡p dá»¯ liá»‡u Brazilian E-commerce báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn (SQL + RAG)")

# Sidebar - Examples & Info
with st.sidebar:
    st.header("ğŸ“š CÃ¢u há»i máº«u")
    
    examples = get_example_questions()
    
    for example in examples:
        if st.button(example, key=f"ex_{hash(example)}", use_container_width=True):
            st.session_state.selected_example = example
    
    st.divider()
    
    st.header("â„¹ï¸ ThÃ´ng tin")
    st.info("""
    **Há»‡ thá»‘ng cÃ³ thá»ƒ tráº£ lá»i:**
    - ğŸ“Š Truy váº¥n dá»¯ liá»‡u (SQL)
    - ğŸ“š TÃ i liá»‡u tham kháº£o (RAG)
    - ğŸ’¡ Gá»£i Ã½ phÃ¢n tÃ­ch
    
    **An toÃ n:**
    - âœ… Chá»‰ cho phÃ©p SELECT (read-only)
    - âœ… Giá»›i háº¡n sá»‘ dÃ²ng tráº£ vá»
    - âœ… Timeout tá»± Ä‘á»™ng
    - âœ… Log Ä‘áº§y Ä‘á»§
    """)
    
    if st.button("ğŸ”„ Reset Chat", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.session_id = uuid.uuid4().hex[:16]
        st.session_state.last_sql = None
        st.session_state.last_preview = None
        st.session_state.last_citations = None
        st.session_state.execution_time = None
        st.rerun()

# Main chat interface
st.divider()

# Welcome message if no history
if not st.session_state.chat_history:
    st.info("""
    ğŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ phÃ¢n tÃ­ch dá»¯ liá»‡u Brazilian E-commerce.**
    
    ğŸ’¡ Báº¡n cÃ³ thá»ƒ há»i tÃ´i vá»:
    - Doanh thu, sáº£n pháº©m, Ä‘Æ¡n hÃ ng
    - PhÃ¢n tÃ­ch theo khu vá»±c, danh má»¥c
    - PhÆ°Æ¡ng thá»©c thanh toÃ¡n, Ä‘Ã¡nh giÃ¡ khÃ¡ch hÃ ng
    
    ğŸ“Œ Chá»n cÃ¢u há»i máº«u bÃªn trÃ¡i hoáº·c nháº­p cÃ¢u há»i cá»§a báº¡n!
    """)
    
    # Show suggestion cards
    st.markdown("### ğŸ¯ CÃ¢u há»i phá»• biáº¿n:")
    cols = st.columns(2)
    examples = get_example_questions()
    for i, example in enumerate(examples[:6]):
        col_idx = i % 2
        with cols[col_idx]:
            if st.button(f"ğŸ’¬ {example}", key=f"welcome_{i}", use_container_width=True):
                st.session_state.selected_example = example
                st.rerun()

# Display chat history
for role, message in st.session_state.chat_history:
    with st.chat_message(role):
        st.markdown(message)
        
        # If assistant message contains suggestions, show as buttons
        if role == "assistant" and "Gá»£i Ã½ cÃ¢u há»i phá»• biáº¿n:" in message:
            st.markdown("---")
            st.markdown("**ğŸ‘‡ Click Ä‘á»ƒ há»i:**")
            
            # Extract suggestions from message
            examples = get_example_questions()
            cols = st.columns(2)
            for i, example in enumerate(examples[:6]):
                col_idx = i % 2
                with cols[col_idx]:
                    if st.button(example, key=f"suggest_{hash(message)}_{i}", use_container_width=True):
                        st.session_state.selected_example = example
                        st.rerun()

# Chat input
question = st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n...", key="chat_input")

# Handle example selection
if "selected_example" in st.session_state:
    question = st.session_state.selected_example
    del st.session_state.selected_example

# Process question
if question:
    # Add user message to history
    st.session_state.chat_history.append(("user", question))
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(question)
    
    # Send to API
    with st.spinner("ğŸ¤” Äang suy nghÄ©..."):
        result = send_question(question)
    
    if result:
        # Store results
        st.session_state.last_sql = result.get("sql")
        st.session_state.last_preview = result.get("rows_preview")
        st.session_state.last_citations = result.get("citations")
        st.session_state.execution_time = result.get("execution_time_ms")
        
        # Add assistant response to history
        answer = result.get("answer", "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i")
        st.session_state.chat_history.append(("assistant", answer))
        
        # Display assistant message
        with st.chat_message("assistant"):
            st.markdown(answer)

# Display SQL & Results
if st.session_state.last_sql or st.session_state.last_preview or st.session_state.last_citations:
    st.divider()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.session_state.execution_time:
            st.metric("â±ï¸ Thá»i gian thá»±c thi", f"{st.session_state.execution_time}ms")
    
    with col2:
        if st.session_state.last_preview:
            st.metric("ğŸ“Š Sá»‘ dÃ²ng", len(st.session_state.last_preview))
    
    with col3:
        if st.session_state.last_citations:
            st.metric("ğŸ“š TÃ i liá»‡u tham kháº£o", len(st.session_state.last_citations))
    
    # SQL Query
    if st.session_state.last_sql:
        with st.expander("ğŸ” SQL Query", expanded=False):
            st.code(st.session_state.last_sql, language="sql")
            
            # Copy button
            if st.button("ğŸ“‹ Copy SQL"):
                st.toast("SQL copied to clipboard!")
    
    # Data Preview
    if st.session_state.last_preview:
        with st.expander("ğŸ“Š Káº¿t quáº£ (Preview 50 dÃ²ng Ä‘áº§u)", expanded=True):
            df = pd.DataFrame(st.session_state.last_preview)
            
            # Display dataframe
            st.dataframe(
                df,
                use_container_width=True,
                height=400
            )
            
            # Export buttons
            col1, col2 = st.columns(2)
            
            with col1:
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ Download CSV",
                    data=csv,
                    file_name=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                )
            
            with col2:
                # Basic statistics
                if st.button("ğŸ“ˆ Show Statistics"):
                    st.write(df.describe())
    
    # Citations
    if st.session_state.last_citations:
        with st.expander("ğŸ“š TÃ i liá»‡u tham kháº£o", expanded=False):
            for i, citation in enumerate(st.session_state.last_citations, 1):
                st.markdown(f"""
                **{i}. {citation.get('source', 'Unknown')}**  
                Äá»™ liÃªn quan: `{citation.get('score', 0):.2f}`
                
                > {citation.get('text', 'No preview available')[:300]}...
                """)
                st.divider()

# Footer
st.divider()
st.caption(f"Session ID: `{st.session_state.session_id}` | Service: `{CHAT_SERVICE_URL}`")


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

chat_service/main.py

"""
Chat Service API
FastAPI service for SQL + RAG chatbot
"""
import os
import re
import time
import uuid
from typing import Optional, List
from datetime import datetime

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import trino
from trino.dbapi import connect
from qdrant_client import QdrantClient
from sqlalchemy import create_engine, text

from sql_templates import intent_to_sql, get_safe_schemas, get_example_questions
from embeddings import embed_query
from llm_sql import gen_sql_with_gemini
from llm_summarize import format_answer
from router import get_router


# ============================================================================
# Configuration
# ============================================================================

TRINO_HOST = os.getenv("TRINO_HOST", "trino")
TRINO_PORT = int(os.getenv("TRINO_PORT", "8080"))
TRINO_CATALOG = os.getenv("TRINO_CATALOG", "lakehouse")
TRINO_DEFAULT_SCHEMA = os.getenv("TRINO_DEFAULT_SCHEMA", "gold")
TRINO_USER = os.getenv("TRINO_USER", "chatbot")
TRINO_PASSWORD = os.getenv("TRINO_PASSWORD", "")

QDRANT_HOST = os.getenv("QDRANT_HOST", "qdrant")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", "6333"))

SQL_WHITELIST_SCHEMAS = set(os.getenv("SQL_WHITELIST_SCHEMAS", "gold,platinum").split(","))
SQL_DEFAULT_LIMIT = int(os.getenv("SQL_DEFAULT_LIMIT", "200"))
SQL_MAX_ROWS = int(os.getenv("SQL_MAX_ROWS", "5000"))
SQL_TIMEOUT_SECS = int(os.getenv("SQL_TIMEOUT_SECS", "45"))

LOG_DB_URI = os.getenv("LOG_DB_URI", "")

# Initialize clients
qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)

# Initialize logging engine if configured
log_engine = None
if LOG_DB_URI:
    try:
        log_engine = create_engine(LOG_DB_URI, pool_pre_ping=True)
    except Exception as e:
        print(f"âš ï¸  Could not initialize log database: {e}")


# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(
    title="Lakehouse Chat Service",
    description="SQL + RAG Chatbot for Brazilian E-commerce Data Lakehouse",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# Models
# ============================================================================

class AskRequest(BaseModel):
    session_id: Optional[str] = None
    question: str
    prefer_sql: Optional[bool] = True


class AskResponse(BaseModel):
    session_id: str
    answer: str
    sql: Optional[str] = None
    rows_preview: Optional[List[dict]] = None
    citations: Optional[List[dict]] = None
    execution_time_ms: Optional[int] = None


# ============================================================================
# SQL Safety & Execution
# ============================================================================

READONLY_PATTERN = re.compile(r"^\s*(SELECT|WITH)\b", re.IGNORECASE)


def enforce_sql_safety(sql: str) -> str:
    """
    Enforce SQL safety constraints
    
    Raises:
        HTTPException if SQL is unsafe
        
    Returns:
        Modified SQL with safety constraints
    """
    if not sql or not sql.strip():
        raise HTTPException(status_code=400, detail="SQL query is empty")
    
    # Must be SELECT or WITH (read-only)
    if not READONLY_PATTERN.match(sql):
        raise HTTPException(
            status_code=400,
            detail="Only SELECT and WITH queries are allowed (read-only)"
        )
    
    # Check for dangerous keywords
    dangerous_keywords = ["DELETE", "DROP", "TRUNCATE", "ALTER", "CREATE", "INSERT", "UPDATE"]
    sql_upper = sql.upper()
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            raise HTTPException(
                status_code=400,
                detail=f"Dangerous keyword '{keyword}' not allowed"
            )
    
    # Enforce LIMIT if not present
    if "LIMIT" not in sql_upper:
        sql = f"{sql.rstrip(';')} LIMIT {SQL_DEFAULT_LIMIT}"
    
    # Check whitelist schemas
    sql_lower = sql.lower()
    has_safe_schema = False
    for schema in SQL_WHITELIST_SCHEMAS:
        if f".{schema}." in sql_lower:
            has_safe_schema = True
            break
    
    if not has_safe_schema:
        raise HTTPException(
            status_code=400,
            detail=f"Query must use one of these schemas: {', '.join(SQL_WHITELIST_SCHEMAS)}"
        )
    
    return sql


def run_sql(sql: str, schema: str = TRINO_DEFAULT_SCHEMA) -> tuple:
    """
    Execute SQL query on Trino
    
    Args:
        sql: SQL query string
        schema: Default schema
        
    Returns:
        Tuple of (rows, execution_time_ms)
    """
    sql = enforce_sql_safety(sql)
    
    start_time = time.time()
    
    try:
        with connect(
            host=TRINO_HOST,
            port=TRINO_PORT,
            user=TRINO_USER,
            catalog=TRINO_CATALOG,
            schema=schema,
            http_scheme="http",
        ) as conn:
            cur = conn.cursor()
            
            # Set query timeout
            cur.execute(f"SET SESSION query_max_run_time = '{SQL_TIMEOUT_SECS}s'")
            
            # Execute query
            cur.execute(sql)
            
            # Fetch results
            rows = cur.fetchmany(SQL_MAX_ROWS + 1)
            columns = [desc[0] for desc in cur.description]
            
            # Check if we hit the limit
            if len(rows) > SQL_MAX_ROWS:
                rows = rows[:SQL_MAX_ROWS]
            
            # Convert to list of dicts
            result = [dict(zip(columns, row)) for row in rows]
            
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"SQL execution error: {str(e)}"
        )
    
    execution_time = int((time.time() - start_time) * 1000)
    
    return result, execution_time


# ============================================================================
# SQL Generation (Template + Gemini)
# ============================================================================

def build_sql(question: str) -> str | None:
    """
    Build SQL query using multi-tier approach:
    1. Check HELP mode
    2. Try old templates (backward compatibility)
    3. Try router + skills (NEW)
    4. Fallback to Gemini LLM
    
    Args:
        question: User's question
        
    Returns:
        SQL query string, empty string (HELP mode), or None
    """
    # 1. Check HELP MODE first
    sql = intent_to_sql(question)
    if sql == "":
        print(f"ğŸ’¡ HELP MODE triggered for: {question}")
        return ""
    
    # 2. Try old templates (for backward compatibility)
    if sql:
        print(f"âœ… Using legacy template SQL for: {question}")
        return sql
    
    # 3. NEW: Try router + skills system
    try:
        router = get_router()
        sql, metadata = router.generate_sql(question, threshold=0.6)
        
        if sql:
            skill_name = metadata.get('skill_name', 'unknown')
            confidence = metadata.get('confidence', 0)
            print(f"âœ… Using skill '{skill_name}' (confidence: {confidence:.2f})")
            return sql
    except Exception as e:
        print(f"âš ï¸  Router error: {e}")
    
    # 4. Fallback to Gemini LLM (for complex queries)
    if os.getenv("LLM_PROVIDER", "none").lower() == "gemini":
        print(f"ğŸ¤– Falling back to Gemini for: {question}")
        sql = gen_sql_with_gemini(question)
        if sql:
            return sql
    
    # 5. No SQL generated
    return None


# ============================================================================
# RAG (Retrieval-Augmented Generation)
# ============================================================================

def rag_search(question: str, k: int = 4) -> List[dict]:
    """
    Search for relevant documents using RAG
    
    Args:
        question: User's question
        k: Number of results to return
        
    Returns:
        List of relevant document chunks
    """
    try:
        vector = embed_query(question)
        
        hits = qdrant_client.search(
            collection_name="knowledge_base",
            query_vector=vector,
            limit=k
        )
        
        return [
            {
                "doc_id": hit.id,
                "score": hit.score,
                "text": hit.payload.get("text", "")[:500],
                "source": hit.payload.get("source", "unknown"),
            }
            for hit in hits
        ]
    except Exception as e:
        print(f"âš ï¸  RAG search error: {e}")
        return []


# ============================================================================
# Logging
# ============================================================================

def log_conversation(session_id: str, role: str, content: str):
    """Log conversation message"""
    if not log_engine:
        return
    
    try:
        with log_engine.connect() as conn:
            conn.execute(
                text("INSERT INTO messages (session_id, role, content) VALUES (:sid, :role, :content)"),
                {"sid": session_id, "role": role, "content": content}
            )
            conn.commit()
    except Exception as e:
        print(f"âš ï¸  Logging error: {e}")


def log_sql_execution(session_id: str, sql: str, rowcount: int, duration_ms: int, error: str = None):
    """Log SQL execution"""
    if not log_engine:
        return
    
    try:
        with log_engine.connect() as conn:
            conn.execute(
                text("""
                    INSERT INTO sql_audit 
                    (session_id, generated_sql, executed_sql, is_readonly, rowcount, duration_ms, error, created_at)
                    VALUES (:sid, :sql, :sql, 1, :rows, :dur, :err, NOW())
                """),
                {
                    "sid": session_id,
                    "sql": sql,
                    "rows": rowcount,
                    "dur": duration_ms,
                    "err": error
                }
            )
            conn.commit()
    except Exception as e:
        print(f"âš ï¸  SQL logging error: {e}")


# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "services": {
            "trino": f"{TRINO_HOST}:{TRINO_PORT}",
            "qdrant": f"{QDRANT_HOST}:{QDRANT_PORT}",
        }
    }


@app.get("/examples")
def get_examples():
    """Get example questions"""
    return {
        "examples": get_example_questions()
    }


@app.post("/ask", response_model=AskResponse)
def ask(request: AskRequest):
    """
    Main chat endpoint with Gemini integration + HELP MODE
    
    Flow:
    1. Check for HELP intent (general questions)
    2. Generate SQL (template â†’ Gemini fallback)
    3. Execute SQL on Trino (with guardrails)
    4. Search RAG citations
    5. Summarize with Gemini (if enabled)
    """
    # Generate session ID if not provided
    session_id = request.session_id or uuid.uuid4().hex[:16]
    question = request.question.strip()
    
    if not question:
        raise HTTPException(status_code=400, detail="Question cannot be empty")
    
    # Log user question
    log_conversation(session_id, "user", question)
    
    sql_query = None
    rows_preview = None
    citations = None
    total_execution_time = 0
    error_msg = None
    
    # 1. Generate SQL
    if request.prefer_sql:
        sql_query = build_sql(question)
        
        # 1a. HELP MODE - return suggestions instead of error
        if sql_query == "":
            examples = get_example_questions()
            answer_parts = [
                "ğŸ‘‹ **MÃ¬nh cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?**\n",
                "ğŸ’¡ **Kháº£ nÄƒng:**",
                "  â€¢ Truy váº¥n sá»‘ liá»‡u (SQL) trÃªn lakehouse.gold & platinum",
                "  â€¢ PhÃ¢n tÃ­ch doanh thu, sáº£n pháº©m, Ä‘Æ¡n hÃ ng, thanh toÃ¡n",
                "  â€¢ Giáº£i thÃ­ch Ä‘á»‹nh nghÄ©a KPI tá»« tÃ i liá»‡u\n",
                "ğŸ“Š **Gá»£i Ã½ cÃ¢u há»i phá»• biáº¿n:**"
            ]
            
            for i, example in enumerate(examples[:7], 1):
                answer_parts.append(f"  {i}. {example}")
            
            answer_parts.append("\nğŸ’¬ HÃ£y chá»n má»™t cÃ¢u há»i hoáº·c nháº­p cÃ¢u há»i cá»§a báº¡n!")
            
            answer = "\n".join(answer_parts)
            log_conversation(session_id, "assistant", answer)
            
            return AskResponse(
                session_id=session_id,
                answer=answer,
                sql=None,
                rows_preview=None,
                citations=None,
                execution_time_ms=0
            )
        
        # 1b. SQL generated - execute it
        if sql_query:
            try:
                rows, exec_time = run_sql(sql_query)
                total_execution_time += exec_time
                rows_preview = rows[:50]  # Preview first 50 rows
                
                # Log SQL execution
                log_sql_execution(session_id, sql_query, len(rows), exec_time)
                
            except HTTPException as e:
                error_msg = f"Lá»—i SQL: {e.detail}"
                log_sql_execution(session_id, sql_query, 0, 0, str(e.detail))
            except Exception as e:
                error_msg = f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}"
                log_sql_execution(session_id, sql_query, 0, 0, str(e))
        
        # 1c. No SQL generated - suggest examples
        else:
            examples = get_example_questions()
            error_msg = "MÃ¬nh chÆ°a sinh Ä‘Æ°á»£c SQL an toÃ n cho cÃ¢u há»i nÃ y.\n\nğŸ’¡ Báº¡n thá»­ má»™t trong cÃ¡c cÃ¢u há»i sau:\n"
            for i, example in enumerate(examples[:5], 1):
                error_msg += f"  {i}. {example}\n"
    
    # 2. RAG search (always run for context)
    citations = rag_search(question, k=4)
    
    # 3. Format answer with optional Gemini summarization
    answer = format_answer(
        question=question,
        sql_query=sql_query,
        rows_preview=rows_preview,
        citations=citations,
        execution_time_ms=total_execution_time,
        error=error_msg
    )
    
    # Log assistant response
    log_conversation(session_id, "assistant", answer)
    
    return AskResponse(
        session_id=session_id,
        answer=answer,
        sql=sql_query,
        rows_preview=rows_preview,
        citations=citations,
        execution_time_ms=total_execution_time
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[Note: Due to file length limits, continuing with remaining files in next segments...]


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

load_dataset_into_mysql/02_init_chatlogs.sql

-- Initialize chatlogs database for Chat Service
-- This database stores conversation history and SQL audit logs

CREATE DATABASE IF NOT EXISTS chatlogs CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

USE chatlogs;

-- Conversations table (session metadata)
CREATE TABLE IF NOT EXISTS conversations (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    session_id VARCHAR(64) NOT NULL,
    user_id VARCHAR(64) NULL,
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_session (session_id),
    INDEX idx_user (user_id),
    INDEX idx_started (started_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- Messages table (conversation history)
CREATE TABLE IF NOT EXISTS messages (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    session_id VARCHAR(64) NOT NULL,
    role ENUM('user','assistant','system') NOT NULL,
    content MEDIUMTEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_session (session_id),
    INDEX idx_created (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- SQL audit table (SQL execution logs)
CREATE TABLE IF NOT EXISTS sql_audit (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    session_id VARCHAR(64) NOT NULL,
    generated_sql MEDIUMTEXT,
    executed_sql MEDIUMTEXT,
    is_readonly TINYINT(1) DEFAULT 1,
    catalog VARCHAR(64),
    schema_name VARCHAR(64),
    tables TEXT,
    has_limit TINYINT(1),
    rowcount INT DEFAULT 0,
    duration_ms INT DEFAULT 0,
    error TEXT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_session (session_id),
    INDEX idx_created (created_at),
    INDEX idx_error (error(100))
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- RAG citations table (document references)
CREATE TABLE IF NOT EXISTS rag_citations (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    session_id VARCHAR(64) NOT NULL,
    doc_id VARCHAR(128),
    score DOUBLE,
    chunk_preview TEXT,
    source_file VARCHAR(512),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_session (session_id),
    INDEX idx_doc (doc_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- Insert initial test message
INSERT INTO conversations (session_id, user_id, started_at)
VALUES ('test_session', 'system', NOW());

INSERT INTO messages (session_id, role, content)
VALUES ('test_session', 'system', 'Chat service initialized successfully');

SELECT 'Chatlogs database initialized successfully' AS status;

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

chat_service/Dockerfile

FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python packages
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8001/health')" || exit 1

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001", "--reload"]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

chat_service/requirements.txt

# FastAPI & Server
fastapi==0.115.0
uvicorn[standard]==0.30.6
python-multipart==0.0.9

# Database & Storage
trino==0.328
qdrant-client==1.9.1
pymysql==1.1.0
SQLAlchemy==2.0.25

# ML & Embeddings
sentence-transformers==3.0.1
openai>=1.40.0
google-generativeai>=0.7.0

# Utils
numpy==1.24.3
pandas==2.0.3
python-dotenv==1.0.0
requests==2.31.0
pydantic==2.5.3

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Tá»”NG Káº¾T
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Tá»”NG Sá» FILE: 26

ğŸ“‚ Cáº¤U TRÃšC:

1. Streamlit UI (1 file)
   - app/pages/2_ğŸ’¬_Chat.py

2. Chat Service Core (8 files)
   - main.py (FastAPI application)
   - router.py (Intent router + skills system)
   - sql_templates.py (Legacy intent-based templates)
   - embeddings.py (Multi-provider embeddings)
   - llm_sql.py (Gemini SQL generation)
   - llm_summarize.py (Gemini result summarization)
   - schema_tools.py (Trino schema introspection)
   - ingest_docs.py (RAG document ingestion)

3. NLP Utilities (4 files)
   - nlp/vi_time.py (Vietnamese time parser)
   - nlp/vi_numbers.py (Vietnamese number parser)
   - nlp/synonyms.py (Synonym mapping & entity extraction)
   - nlp/__init__.py

4. Skills System (12 files)
   - skills/base.py (Base skill class)
   - skills/revenue_timeseries.py
   - skills/top_products.py
   - skills/distribution_region.py
   - skills/payment_mix.py
   - skills/category_revenue.py
   - skills/ontime_rate.py
   - skills/mom_yoy.py
   - skills/market_share.py
   - skills/aov_analysis.py
   - skills/recent_orders.py
   - skills/top_sellers_sla.py
   - skills/__init__.py

5. Infrastructure (3 files)
   - Dockerfile (Chat Service container)
   - requirements.txt (Python dependencies)
   - 02_init_chatlogs.sql (MySQL schema for logs)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Tá»”NG Sá» DÃ’NG CODE: ~3,141 dÃ²ng

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

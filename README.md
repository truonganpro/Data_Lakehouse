# ğŸ—ï¸ Modern Data Stack - Data Lakehouse Project

> **á»¨ng dá»¥ng Modern Data Stack (MDS) Ä‘á»ƒ xÃ¢y dá»±ng Data Lakehouse há»— trá»£ phÃ¢n tÃ­ch dá»¯ liá»‡u bÃ¡n hÃ ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­**

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![Trino](https://img.shields.io/badge/Trino-FF6900?style=for-the-badge&logo=trino&logoColor=white)](https://trino.io/)
[![Dagster](https://img.shields.io/badge/Dagster-000000?style=for-the-badge&logo=dagster&logoColor=white)](https://dagster.io/)
[![Metabase](https://img.shields.io/badge/Metabase-509EE3?style=for-the-badge&logo=metabase&logoColor=white)](https://www.metabase.com/)

---

## ğŸ“‹ Má»¥c lá»¥c

- [ğŸ¯ Tá»•ng quan dá»± Ã¡n](#-tá»•ng-quan-dá»±-Ã¡n)
- [ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng](#ï¸-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng](#ï¸-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y](#-cÃ i-Ä‘áº·t-vÃ -cháº¡y)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸ“ˆ Data Layers](#-data-layers)
- [ğŸ¨ Dashboard vÃ  BI](#-dashboard-vÃ -bi)
- [ğŸ§ª Testing](#-testing)
- [ğŸ“š TÃ i liá»‡u tham kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Tá»•ng quan dá»± Ã¡n

### Má»¥c tiÃªu

XÃ¢y dá»±ng má»™t há»‡ thá»‘ng **Data Lakehouse** hoÃ n chá»‰nh sá»­ dá»¥ng **Modern Data Stack** Ä‘á»ƒ:

- âœ… **Thu tháº­p vÃ  xá»­ lÃ½** dá»¯ liá»‡u thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Brazilian E-commerce
- âœ… **Tá»• chá»©c dá»¯ liá»‡u** theo mÃ´ hÃ¬nh **Medallion Architecture** (Bronze â†’ Silver â†’ Gold â†’ Platinum)
- âœ… **PhÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a** dá»¯ liá»‡u qua BI dashboard
- âœ… **Triá»ƒn khai container hÃ³a** vá»›i Docker Compose

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
MySQL (Brazilian E-commerce Data)
    â†“
Bronze Layer â†’ MinIO (lakehouse/bronze/)
    â†“
Silver Layer â†’ MinIO (lakehouse/silver/)
    â†“
Gold Layer â†’ MinIO (lakehouse/gold/)
    â†“
Platinum Layer â†’ MinIO (lakehouse/platinum/)
    â†“
Trino (catalog: minio, schema: platinum)
    â†“
Metabase (http://localhost:3000)
```

### Medallion Architecture

| Layer | MÃ´ táº£ | Sá»‘ báº£ng |
|-------|-------|---------|
| **Bronze** | Raw data tá»« MySQL | 9 tables |
| **Silver** | Cleaned & normalized data | 10 tables |
| **Gold** | Star schema (Facts + Dimensions) | 10 tables |
| **Platinum** | Business datamarts cho BI | 7 datamarts |

---

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

| **ThÃ nh pháº§n** | **CÃ´ng nghá»‡** | **Vai trÃ²** |
|----------------|---------------|-------------|
| **Storage** | MinIO (S3-compatible) | LÆ°u trá»¯ dá»¯ liá»‡u theo zone |
| **Metadata** | Hive Metastore + MySQL | Quáº£n lÃ½ schema vÃ  metadata |
| **Compute** | Apache Spark 3.3.2 | Xá»­ lÃ½ dá»¯ liá»‡u (ETL) |
| **Lakehouse** | Delta Lake 2.3.0 | ACID transactions, versioning |
| **Query Engine** | Trino 414 | SQL query trÃªn Delta tables |
| **Orchestration** | Dagster | Workflow management |
| **BI/Visualization** | Metabase + Streamlit | Dashboard vÃ  bÃ¡o cÃ¡o |
| **Containerization** | Docker Compose | Triá»ƒn khai vÃ  quáº£n lÃ½ |

---

## ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y

### YÃªu cáº§u há»‡ thá»‘ng

- Docker & Docker Compose
- 8GB RAM trá»Ÿ lÃªn
- 20GB dung lÆ°á»£ng trá»‘ng

### Quick Start (Automated Setup)

**Recommended for first-time setup:**

```bash
# 1. Clone repository
git clone <repository-url>
cd Data_Warehouse_Fresh

# 2. Run automated setup script
chmod +x setup.sh
./setup.sh
```

Script sáº½ tá»± Ä‘á»™ng:
- âœ… Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng (Docker, disk space, RAM)
- âœ… Táº¡o file `.env` tá»« `env.example`
- âœ… Download JAR dependencies
- âœ… Build Docker images
- âœ… Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
- âœ… Táº£i dataset (náº¿u cÃ³)
- âœ… Cháº¡y ETL pipeline
- âœ… Kiá»ƒm tra health cá»§a services

### Alternative Setup Methods

**Option 1: Using full_setup.sh**
```bash
chmod +x full_setup.sh
./full_setup.sh --fresh    # Fresh install (remove volumes, rebuild all)
```

**Option 2: Manual setup**
```bash
# 1. Download JAR dependencies
chmod +x download_jars.sh
./download_jars.sh

# 2. Create .env file
cp env.example .env

# 3. Start all services
docker-compose up -d
```

**Note:** Cáº§n chá»‰nh sá»­a `.env` file trÆ°á»›c khi cháº¡y Ä‘á»ƒ thÃªm Google API Key náº¿u muá»‘n sá»­ dá»¥ng Chat Service.

### Kiá»ƒm tra tráº¡ng thÃ¡i

```bash
# Kiá»ƒm tra containers
docker-compose ps

# Xem logs
docker-compose logs -f [service_name]
```

### Truy cáº­p cÃ¡c giao diá»‡n

| Service | URL | Credentials / Notes |
|---------|-----|---------------------|
| **ğŸš€ Streamlit App** | http://localhost:8501 | Main dashboard & UI |
| **ğŸ“Š Metabase BI** | http://localhost:3000 | Setup on first access |
| **ğŸ¯ Dagster UI** | http://localhost:3001 | ETL orchestration |
| **âš¡ Spark Master** | http://localhost:8080 | Spark cluster UI |
| **ğŸª£ MinIO Console** | http://localhost:9001 | minio/minio123 |
| **ğŸ” Trino** | http://localhost:8082 | SQL query engine |
| **ğŸ’¬ Chat Service** | http://localhost:8001 | AI Chatbot API |

---

## ğŸ“Š Dataset

### Brazilian E-commerce Dataset

- **Nguá»“n**: [Kaggle - Brazilian E-commerce Public Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- **KÃ­ch thÆ°á»›c**: ~100K Ä‘Æ¡n hÃ ng, 32K sáº£n pháº©m, 9K ngÆ°á»i bÃ¡n
- **Thá»i gian**: 2016-2018

### Download Dataset

```bash
# Táº¡o thÆ° má»¥c dataset
mkdir -p brazilian-ecommerce

# Download tá»« Kaggle (cáº§n Kaggle API)
kaggle datasets download -d olistbr/brazilian-ecommerce -p brazilian-ecommerce/
unzip brazilian-ecommerce/brazilian-ecommerce.zip -d brazilian-ecommerce/
```

### Schema

| Table | Description | Key Fields |
|-------|-------------|------------|
| `customers` | Customer information | customer_id, customer_zip_code_prefix |
| `orders` | Order details | order_id, customer_id, order_status |
| `order_items` | Order line items | order_id, product_id, seller_id, price |
| `products` | Product catalog | product_id, product_category_name |
| `sellers` | Seller information | seller_id, seller_zip_code_prefix |
| `geolocation` | Geographic data | geolocation_zip_code_prefix, city, state |
| `order_payments` | Payment information | order_id, payment_type, payment_value |
| `order_reviews` | Customer reviews | review_id, order_id, review_score |

---

## ğŸ“ˆ Data Layers

### Platinum Layer Datamarts

| Datamart | Records | MÃ´ Táº£ |
|----------|---------|-------|
| `dm_sales_monthly_category` | 1,326 | Doanh sá»‘ theo thÃ¡ng vÃ  danh má»¥c sáº£n pháº©m |
| `dm_seller_kpi` | 3,095 | KPI vÃ  hiá»‡u suáº¥t cá»§a ngÆ°á»i bÃ¡n |
| `dm_customer_lifecycle` | 96,462 | VÃ²ng Ä‘á»i vÃ  hÃ nh vi khÃ¡ch hÃ ng |
| `dm_payment_mix` | 90 | PhÃ¢n tÃ­ch phÆ°Æ¡ng thá»©c thanh toÃ¡n |
| `dm_logistics_sla` | 574 | SLA vÃ  hiá»‡u suáº¥t giao hÃ ng |
| `dm_product_bestsellers` | 32,951 | Sáº£n pháº©m bÃ¡n cháº¡y nháº¥t |
| `dm_category_price_bands` | 326 | PhÃ¢n khÃºc giÃ¡ theo danh má»¥c |
| **Tá»”NG** | **134,824** | **Tá»•ng records trong Platinum Layer** |

### ETL Pipeline

1. **Bronze Layer**: Extract raw data tá»« MySQL â†’ MinIO (Delta format)
2. **Silver Layer**: Data cleaning, normalization, type casting
3. **Gold Layer**: Star schema transformation (Facts + Dimensions)
4. **Platinum Layer**: Business aggregations vÃ  datamarts cho BI

---

## ğŸ¨ Dashboard vÃ  BI

### Metabase Setup

1. Truy cáº­p Metabase: http://localhost:3000
2. Setup admin account (láº§n Ä‘áº§u tiÃªn)
3. Add Database:
   - Database Type: **Trino**
   - Host: `trino`
   - Port: `8080`
   - JDBC String: `catalog=minio&schema=platinum`
   - Username: `metabase`
   - SSL: **OFF**

### Sample Queries

#### Monthly Revenue Trend
```sql
SELECT 
    year_month,
    SUM(gmv) as total_revenue,
    SUM(orders) as total_orders,
    ROUND(SUM(gmv) / SUM(orders), 2) as aov
FROM minio.platinum.dm_sales_monthly_category
GROUP BY year_month
ORDER BY year_month
```

#### Top 10 Categories
```sql
SELECT 
    product_category_name_english as category,
    SUM(gmv) as revenue,
    SUM(orders) as orders,
    SUM(units) as units
FROM mino.platinum.dm_sales_monthly_category
WHERE product_category_name_english IS NOT NULL
GROUP BY product_category_name_english
ORDER BY revenue DESC
LIMIT 10
```

#### Payment Mix
```sql
SELECT 
    payment_type,
    SUM(orders) as total_orders,
    SUM(payment_total) as total_value,
    ROUND(SUM(orders) * 100.0 / SUM(SUM(orders)) OVER(), 2) as pct_orders
FROM minio.platinum.dm_payment_mix
WHERE payment_type IS NOT NULL
GROUP BY payment_type
ORDER BY total_orders DESC
```

### Recommended Dashboards

1. **Executive Summary**: Total GMV, Orders, AOV, Revenue trend
2. **Sales Deep Dive**: Category performance, Geographic distribution
3. **Customer Analytics**: Lifecycle funnel, Segmentation, Cohort analysis
4. **Operations**: Logistics SLA, Delivery metrics, Payment distribution
5. **Product Intelligence**: Bestsellers, Price bands, Category analysis

Xem chi tiáº¿t trong file `METABASE_SETUP_GUIDE.md` vÃ  `VISUALIZATION_RESULTS.md`.

---

## ğŸ§ª Testing

### Test Spark â†” MinIO Connection

```bash
python test_spark_minio_connection.py

# Hoáº·c qua Docker
docker exec spark-master python3 /opt/bitnami/spark/test_spark_minio_connection.py
```

### Test Trino Connection

```bash
chmod +x test_trino_connection.sh
./test_trino_connection.sh
```

### Test SQL Queries

```sql
-- Qua Trino CLI
docker exec trino trino

-- Trong Trino CLI:
SHOW CATALOGS;
USE minio.platinum;
SHOW TABLES;
SELECT * FROM dm_sales_monthly_category LIMIT 10;
```

---

## ğŸ”§ Configuration

### Environment Variables

File `.env` Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng tá»« `env.example` khi khá»Ÿi Ä‘á»™ng. CÃ¡c biáº¿n quan trá»ng:

```bash
# MySQL
MYSQL_ROOT_PASSWORD=root123
MYSQL_DATABASE=metastore
MYSQL_USER=hive
MYSQL_PASSWORD=hive

# Dagster MySQL
DAGSTER_MYSQL_HOSTNAME=de_mysql
DAGSTER_MYSQL_DB=dagster
DAGSTER_MYSQL_USERNAME=dagster
DAGSTER_MYSQL_PASSWORD=dagster123

# MinIO
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123
```

### Spark Configuration

Key settings trong `docker_image/spark/conf/spark-defaults.conf`:

```properties
# Delta Lake
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# S3/MinIO
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=minio
spark.hadoop.fs.s3a.secret.key=minio123
spark.hadoop.fs.s3a.path.style.access=true

# Lakehouse Storage
spark.sql.warehouse.dir=s3a://lakehouse/
```

### Trino Configuration

Catalog `minio.properties`:

```properties
connector.name=delta_lake
hive.metastore.uri=thrift://hive-metastore:9083
hive.s3.endpoint=http://minio:9000
hive.s3.aws-access-key=minio
hive.s3.aws-secret-key=minio123
hive.s3.path-style-access=true
hive.s3.ssl.enabled=false
delta.register-table-procedure.enabled=true
```

---

## ğŸ”„ Dagster Jobs

### Run ETL Pipeline

```bash
# Access Dagster UI
http://localhost:3001

# Materialize assets by layer:
# - Bronze Layer: Extract from MySQL
# - Silver Layer: Clean and normalize
# - Gold Layer: Create star schema
# - Platinum Layer: Create datamarts

# Hoáº·c run via CLI
docker exec de_dagster_daemon dagster job execute -j full_pipeline_job
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

### CÃ´ng nghá»‡ chÃ­nh

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Delta Lake Documentation](https://docs.delta.io/)
- [Trino Documentation](https://trino.io/docs/)
- [Dagster Documentation](https://docs.dagster.io/)
- [Metabase Documentation](https://www.metabase.com/docs/)
- [MinIO Documentation](https://min.io/docs/minio/linux/index.html)

### Modern Data Stack

- [What is a Data Lakehouse?](https://www.databricks.com/discover/data-lakehouse)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Data Engineering Best Practices](https://github.com/datastacktv/data-engineer-roadmap)

### Dataset

- [Brazilian E-commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

---

## ğŸ› Troubleshooting

### Services khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Kiá»ƒm tra logs
docker-compose logs [service_name]

# Restart services
docker-compose restart [service_name]

# Rebuild náº¿u cáº§n
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### MinIO connection errors

```bash
# Kiá»ƒm tra MinIO
docker exec minio mc ls minio/

# Test tá»« Spark
docker exec spark-master python3 /opt/bitnami/spark/test_spark_minio_connection.py
```

### Dagster job failures

```bash
# Check Dagster logs
docker-compose logs de_dagster_daemon

# Check ETL pipeline logs
docker-compose logs etl_pipeline
```

---

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

---

## ğŸ“„ License

Distributed under the MIT License.

---

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

**Truong An** - *Modern Data Stack Engineer*

---

## ğŸ™ Acknowledgments

- [Olist](https://olist.com/) for providing the Brazilian E-commerce dataset
- [Apache Software Foundation](https://apache.org/) for open-source tools
- [Modern Data Stack community](https://github.com/modern-data-stack) for inspiration

---

â­ **Náº¿u dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho má»™t star!** â­

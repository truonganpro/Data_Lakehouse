# üèóÔ∏è Modern Data Stack - Data Lakehouse Project

> **·ª®ng d·ª•ng Modern Data Stack (MDS) ƒë·ªÉ x√¢y d·ª±ng Data Lakehouse h·ªó tr·ª£ ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠**

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![Trino](https://img.shields.io/badge/Trino-FF6900?style=for-the-badge&logo=trino&logoColor=white)](https://trino.io/)
[![Dagster](https://img.shields.io/badge/Dagster-000000?style=for-the-badge&logo=dagster&logoColor=white)](https://dagster.io/)
[![Metabase](https://img.shields.io/badge/Metabase-509EE3?style=for-the-badge&logo=metabase&logoColor=white)](https://www.metabase.com/)

---

## üìã M·ª•c l·ª•c

- [üéØ T·ªïng quan d·ª± √°n](#-t·ªïng-quan-d·ª±-√°n)
- [üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng](#Ô∏è-ki·∫øn-tr√∫c-h·ªá-th·ªëng)
- [üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng](#Ô∏è-c√¥ng-ngh·ªá-s·ª≠-d·ª•ng)
- [üöÄ C√†i ƒë·∫∑t v√† ch·∫°y](#-c√†i-ƒë·∫∑t-v√†-ch·∫°y)
- [üìä Dataset](#-dataset)
- [üìà Data Layers](#-data-layers)
- [üé® Dashboard v√† BI](#-dashboard-v√†-bi)
- [üß™ Testing](#-testing)
- [üìö T√†i li·ªáu tham kh·∫£o](#-t√†i-li·ªáu-tham-kh·∫£o)

---

## üéØ T·ªïng quan d·ª± √°n

### M·ª•c ti√™u

X√¢y d·ª±ng m·ªôt h·ªá th·ªëng **Data Lakehouse** ho√†n ch·ªânh s·ª≠ d·ª•ng **Modern Data Stack** ƒë·ªÉ:

- ‚úÖ **Thu th·∫≠p v√† x·ª≠ l√Ω** d·ªØ li·ªáu th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Brazilian E-commerce
- ‚úÖ **T·ªï ch·ª©c d·ªØ li·ªáu** theo m√¥ h√¨nh **Medallion Architecture** (Bronze ‚Üí Silver ‚Üí Gold ‚Üí Platinum)
- ‚úÖ **Ph√¢n t√≠ch v√† tr·ª±c quan h√≥a** d·ªØ li·ªáu qua BI dashboard
- ‚úÖ **Tri·ªÉn khai container h√≥a** v·ªõi Docker Compose

---

## üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng

```
MySQL (Brazilian E-commerce Data)
    ‚Üì
Bronze Layer ‚Üí MinIO (lakehouse/bronze/)
    ‚Üì
Silver Layer ‚Üí MinIO (lakehouse/silver/)
    ‚Üì
Gold Layer ‚Üí MinIO (lakehouse/gold/)
    ‚Üì
Platinum Layer ‚Üí MinIO (lakehouse/platinum/)
    ‚Üì
Trino (catalog: minio, schema: platinum)
    ‚Üì
Metabase (http://localhost:3000)
```

### Medallion Architecture

| Layer | M√¥ t·∫£ | S·ªë b·∫£ng |
|-------|-------|---------|
| **Bronze** | Raw data t·ª´ MySQL | 9 tables |
| **Silver** | Cleaned & normalized data | 10 tables |
| **Gold** | Star schema (Facts + Dimensions) | 10 tables |
| **Platinum** | Business datamarts cho BI | 7 datamarts |

---

## üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

| **Th√†nh ph·∫ßn** | **C√¥ng ngh·ªá** | **Vai tr√≤** |
|----------------|---------------|-------------|
| **Storage** | MinIO (S3-compatible) | L∆∞u tr·ªØ d·ªØ li·ªáu theo zone |
| **Metadata** | Hive Metastore + MySQL | Qu·∫£n l√Ω schema v√† metadata |
| **Compute** | Apache Spark 3.3.2 | X·ª≠ l√Ω d·ªØ li·ªáu (ETL) |
| **Lakehouse** | Delta Lake 2.3.0 | ACID transactions, versioning |
| **Query Engine** | Trino 414 | SQL query tr√™n Delta tables |
| **Orchestration** | Dagster | Workflow management |
| **BI/Visualization** | Metabase + Streamlit | Dashboard v√† b√°o c√°o |
| **Containerization** | Docker Compose | Tri·ªÉn khai v√† qu·∫£n l√Ω |

---

## üöÄ C√†i ƒë·∫∑t v√† ch·∫°y

### Y√™u c·∫ßu h·ªá th·ªëng

- Docker & Docker Compose
- 8GB RAM tr·ªü l√™n
- 20GB dung l∆∞·ª£ng tr·ªëng

### Quick Start

```bash
# 1. Clone repository
git clone <repository-url>
cd Data_Warehouse_Fresh

# 2. Download JAR dependencies
chmod +x download_jars.sh
./download_jars.sh

# 3. Kh·ªüi ƒë·ªông h·ªá th·ªëng (t·ª± ƒë·ªông t·∫°o .env n·∫øu ch∆∞a c√≥)
chmod +x start_and_test.sh
./start_and_test.sh

# Ho·∫∑c s·ª≠ d·ª•ng docker-compose tr·ª±c ti·∫øp
docker-compose up -d
```

### Ki·ªÉm tra tr·∫°ng th√°i

```bash
# Ki·ªÉm tra containers
docker-compose ps

# Xem logs
docker-compose logs -f [service_name]
```

### Truy c·∫≠p c√°c giao di·ªán

| Service | URL | Credentials |
|---------|-----|-------------|
| **Spark Master UI** | http://localhost:8080 | - |
| **MinIO Console** | http://localhost:9001 | minio/minio123 |
| **Metabase** | http://localhost:3000 | Setup on first access |
| **Trino** | http://localhost:8082 | - |
| **Dagster** | http://localhost:3001 | - |
| **Streamlit** | http://localhost:8501 | - |
| **Jupyter Notebook** | http://localhost:8888 | - |

---

## üìä Dataset

### Brazilian E-commerce Dataset

- **Ngu·ªìn**: [Kaggle - Brazilian E-commerce Public Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- **K√≠ch th∆∞·ªõc**: ~100K ƒë∆°n h√†ng, 32K s·∫£n ph·∫©m, 9K ng∆∞·ªùi b√°n
- **Th·ªùi gian**: 2016-2018

### Download Dataset

```bash
# T·∫°o th∆∞ m·ª•c dataset
mkdir -p brazilian-ecommerce

# Download t·ª´ Kaggle (c·∫ßn Kaggle API)
kaggle datasets download -d olistbr/brazilian-ecommerce -p brazilian-ecommerce/
unzip brazilian-ecommerce/brazilian-ecommerce.zip -d brazilian-ecommerce/
```

### Schema

| Table | Description | Key Fields |
|-------|-------------|------------|
| `customers` | Customer information | customer_id, customer_zip_code_prefix |
| `orders` | Order details | order_id, customer_id, order_status |
| `order_items` | Order line items | order_id, product_id, seller_id, price |
| `products` | Product catalog | product_id, product_category_name |
| `sellers` | Seller information | seller_id, seller_zip_code_prefix |
| `geolocation` | Geographic data | geolocation_zip_code_prefix, city, state |
| `order_payments` | Payment information | order_id, payment_type, payment_value |
| `order_reviews` | Customer reviews | review_id, order_id, review_score |

---

## üìà Data Layers

### Platinum Layer Datamarts

| Datamart | Records | M√¥ T·∫£ |
|----------|---------|-------|
| `dm_sales_monthly_category` | 1,326 | Doanh s·ªë theo th√°ng v√† danh m·ª•c s·∫£n ph·∫©m |
| `dm_seller_kpi` | 3,095 | KPI v√† hi·ªáu su·∫•t c·ªßa ng∆∞·ªùi b√°n |
| `dm_customer_lifecycle` | 96,462 | V√≤ng ƒë·ªùi v√† h√†nh vi kh√°ch h√†ng |
| `dm_payment_mix` | 90 | Ph√¢n t√≠ch ph∆∞∆°ng th·ª©c thanh to√°n |
| `dm_logistics_sla` | 574 | SLA v√† hi·ªáu su·∫•t giao h√†ng |
| `dm_product_bestsellers` | 32,951 | S·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t |
| `dm_category_price_bands` | 326 | Ph√¢n kh√∫c gi√° theo danh m·ª•c |
| **T·ªîNG** | **134,824** | **T·ªïng records trong Platinum Layer** |

### ETL Pipeline

1. **Bronze Layer**: Extract raw data t·ª´ MySQL ‚Üí MinIO (Delta format)
2. **Silver Layer**: Data cleaning, normalization, type casting
3. **Gold Layer**: Star schema transformation (Facts + Dimensions)
4. **Platinum Layer**: Business aggregations v√† datamarts cho BI

---

## üé® Dashboard v√† BI

### Metabase Setup

1. Truy c·∫≠p Metabase: http://localhost:3000
2. Setup admin account (l·∫ßn ƒë·∫ßu ti√™n)
3. Add Database:
   - Database Type: **Trino**
   - Host: `trino`
   - Port: `8080`
   - JDBC String: `catalog=minio&schema=platinum`
   - Username: `metabase`
   - SSL: **OFF**

### Sample Queries

#### Monthly Revenue Trend
```sql
SELECT 
    year_month,
    SUM(gmv) as total_revenue,
    SUM(orders) as total_orders,
    ROUND(SUM(gmv) / SUM(orders), 2) as aov
FROM minio.platinum.dm_sales_monthly_category
GROUP BY year_month
ORDER BY year_month
```

#### Top 10 Categories
```sql
SELECT 
    product_category_name_english as category,
    SUM(gmv) as revenue,
    SUM(orders) as orders,
    SUM(units) as units
FROM mino.platinum.dm_sales_monthly_category
WHERE product_category_name_english IS NOT NULL
GROUP BY product_category_name_english
ORDER BY revenue DESC
LIMIT 10
```

#### Payment Mix
```sql
SELECT 
    payment_type,
    SUM(orders) as total_orders,
    SUM(payment_total) as total_value,
    ROUND(SUM(orders) * 100.0 / SUM(SUM(orders)) OVER(), 2) as pct_orders
FROM minio.platinum.dm_payment_mix
WHERE payment_type IS NOT NULL
GROUP BY payment_type
ORDER BY total_orders DESC
```

### Recommended Dashboards

1. **Executive Summary**: Total GMV, Orders, AOV, Revenue trend
2. **Sales Deep Dive**: Category performance, Geographic distribution
3. **Customer Analytics**: Lifecycle funnel, Segmentation, Cohort analysis
4. **Operations**: Logistics SLA, Delivery metrics, Payment distribution
5. **Product Intelligence**: Bestsellers, Price bands, Category analysis

Xem chi ti·∫øt trong file `METABASE_SETUP_GUIDE.md` v√† `VISUALIZATION_RESULTS.md`.

---

## üß™ Testing

### Test Spark ‚Üî MinIO Connection

```bash
python test_spark_minio_connection.py

# Ho·∫∑c qua Docker
docker exec spark-master python3 /opt/bitnami/spark/test_spark_minio_connection.py
```

### Test Trino Connection

```bash
chmod +x test_trino_connection.sh
./test_trino_connection.sh
```

### Test SQL Queries

```sql
-- Qua Trino CLI
docker exec trino trino

-- Trong Trino CLI:
SHOW CATALOGS;
USE minio.platinum;
SHOW TABLES;
SELECT * FROM dm_sales_monthly_category LIMIT 10;
```

---

## üîß Configuration

### Environment Variables

File `.env` ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ `env.example` khi kh·ªüi ƒë·ªông. C√°c bi·∫øn quan tr·ªçng:

```bash
# MySQL
MYSQL_ROOT_PASSWORD=root123
MYSQL_DATABASE=metastore
MYSQL_USER=hive
MYSQL_PASSWORD=hive

# Dagster MySQL
DAGSTER_MYSQL_HOSTNAME=de_mysql
DAGSTER_MYSQL_DB=dagster
DAGSTER_MYSQL_USERNAME=dagster
DAGSTER_MYSQL_PASSWORD=dagster123

# MinIO
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123
```

### Spark Configuration

Key settings trong `docker_image/spark/conf/spark-defaults.conf`:

```properties
# Delta Lake
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# S3/MinIO
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=minio
spark.hadoop.fs.s3a.secret.key=minio123
spark.hadoop.fs.s3a.path.style.access=true

# Warehouse
spark.sql.warehouse.dir=s3a://lakehouse/
```

### Trino Configuration

Catalog `minio.properties`:

```properties
connector.name=delta_lake
hive.metastore.uri=thrift://hive-metastore:9083
hive.s3.endpoint=http://minio:9000
hive.s3.aws-access-key=minio
hive.s3.aws-secret-key=minio123
hive.s3.path-style-access=true
hive.s3.ssl.enabled=false
delta.register-table-procedure.enabled=true
```

---

## üîÑ Dagster Jobs

### Run ETL Pipeline

```bash
# Access Dagster UI
http://localhost:3001

# Materialize assets by layer:
# - Bronze Layer: Extract from MySQL
# - Silver Layer: Clean and normalize
# - Gold Layer: Create star schema
# - Platinum Layer: Create datamarts

# Ho·∫∑c run via CLI
docker exec de_dagster_daemon dagster job execute -j full_pipeline_job
```

---

## üìö T√†i li·ªáu tham kh·∫£o

### C√¥ng ngh·ªá ch√≠nh

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Delta Lake Documentation](https://docs.delta.io/)
- [Trino Documentation](https://trino.io/docs/)
- [Dagster Documentation](https://docs.dagster.io/)
- [Metabase Documentation](https://www.metabase.com/docs/)
- [MinIO Documentation](https://min.io/docs/minio/linux/index.html)

### Modern Data Stack

- [What is a Data Lakehouse?](https://www.databricks.com/discover/data-lakehouse)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Data Engineering Best Practices](https://github.com/datastacktv/data-engineer-roadmap)

### Dataset

- [Brazilian E-commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

---

## üêõ Troubleshooting

### Services kh√¥ng kh·ªüi ƒë·ªông

```bash
# Ki·ªÉm tra logs
docker-compose logs [service_name]

# Restart services
docker-compose restart [service_name]

# Rebuild n·∫øu c·∫ßn
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### MinIO connection errors

```bash
# Ki·ªÉm tra MinIO
docker exec minio mc ls minio/

# Test t·ª´ Spark
docker exec spark-master python3 /opt/bitnami/spark/test_spark_minio_connection.py
```

### Dagster job failures

```bash
# Check Dagster logs
docker-compose logs de_dagster_daemon

# Check ETL pipeline logs
docker-compose logs etl_pipeline
```

---

## ü§ù ƒê√≥ng g√≥p

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. T·∫°o Pull Request

---

## üìÑ License

Distributed under the MIT License.

---

## üë®‚Äçüíª T√°c gi·∫£

**Truong An** - *Modern Data Stack Engineer*

---

## üôè Acknowledgments

- [Olist](https://olist.com/) for providing the Brazilian E-commerce dataset
- [Apache Software Foundation](https://apache.org/) for open-source tools
- [Modern Data Stack community](https://github.com/modern-data-stack) for inspiration

---

‚≠ê **N·∫øu d·ª± √°n n√†y h·ªØu √≠ch, h√£y cho m·ªôt star!** ‚≠ê
